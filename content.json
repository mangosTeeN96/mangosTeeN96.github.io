{"meta":{"title":"MangosTeen","subtitle":null,"description":"想养一只猫","author":"MangosTeen","url":"http://mangosTeeN96.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-08-19T05:33:22.000Z","updated":"2019-08-19T05:34:22.599Z","comments":true,"path":"categories/index.html","permalink":"http://mangosTeeN96.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-06-28T05:09:08.017Z","updated":"2019-06-27T03:19:17.750Z","comments":true,"path":"links/index.html","permalink":"http://mangosTeeN96.github.io/links/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-08-19T05:28:46.000Z","updated":"2019-08-19T05:29:59.602Z","comments":true,"path":"tags/index.html","permalink":"http://mangosTeeN96.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"SQL分析电商用户行为","slug":"SQL分析电商用户行为","date":"2020-03-29T06:04:27.000Z","updated":"2020-08-10T06:20:58.013Z","comments":true,"path":"2020/03/29/SQL分析电商用户行为/","link":"","permalink":"http://mangosTeeN96.github.io/2020/03/29/SQL分析电商用户行为/","excerpt":"","text":"一、项目背景及目的1.1 项目背景移动互联网企业从粗放式到精细化运营管理过程中，需要结合市场、渠道、用户行为等数据分析，对用户开展有针对性的运营活动，提供个性化、差异化的运营策略，以实现运营业务指标。 本项目利用sql对淘宝用户行为数据进行分析，通过用户行为分析业务问题，提供针对性的运营策略。 1.2 项目目的本次分析的目的是想通过对淘宝用户行为数据分析，为以下问题提供解释和改进建议： （常见指标）分析用户使用APP过程中的常见电商分析指标，建立用户行为转化漏斗模型，确定各个环节的流失率，找到需要改进的环节 （时间维度）研究用户在不同时间尺度下的行为规律，找到用户在不同时间周期下的活跃规律，在用户活跃时间点推出相应营销策略 （商品维度）找到用户对不同种类商品的偏好，找到针对不同商品的营销策略 （用户维度）找出最具价值的核心付费用户群，对这部分用户的行为进行分析 1.3 数据集来源与介绍 数据集来自阿里云天池：数据链接 本数据集包含了2017年11月25日至2017年12月3日之间，有行为的约一百万随机用户的所有行为（行为包括点击、购买、加购、喜欢）。数据集的组织形式和MovieLens-20M类似，即数据集的每一行表示一条用户行为，由用户ID、商品ID、商品类目ID、行为类型和时间戳组成，并以逗号分隔。关于数据集中每一列的详细描述如下： 列名称 说明 用户ID 整数类型，序列化后的用户ID 商品ID 整数类型，序列化后的商品ID 商品类目ID 整数类型，序列化后的商品所属类目ID 行为类型 字符串，枚举类型，包括(‘pv’, ‘buy’, ‘cart’, ‘fav’) 时间戳 行为发生的时间戳 注意到，用户行为类型共有四种，它们分别是 行为类型 说明 pv 商品详情页pv，等价于点击 buy 商品购买 cart 将商品加入购物车 fav 收藏商品 关于数据集大小的一些说明如下 维度 数量 用户数量 987,994 商品数量 4,162,024 商品类目数量 9,439 所有行为数量 100,150,807 二、数据导入两种导入方式： 1、使用图形界面工具导入，例如Navicat（操作简单） 2、cmd中以系统命令行导入（速度更快) 123456789101112131415create database taobao charset=utf8;use taobao;create table user( user_id int NOT NULL, item int, category int, behavior varchar(20), time int); load data infile \"/Users/tiansaijun/UserBehavior.csv\" into table user fields terminated by \",\" lines terminated by \"\\n\"; 导入时报错，解决办法： ERROR 3948 (42000) Mac mysql8.0版本添加配置文件my.cnf 数据有100150807条，选取1000000进行实验 1create table userbehavior(select * from user limit 1000000); 三、数据清洗3.1 删除重复值12345-- 统计重复值SELECT *FROM userbehaviorGROUP BY user_id,item,category,timeHAVING count(user_id)&gt;1; Empty set 从查询结果可知，数据中不存在重复记录。 3.2 查看缺失值123-- 统计缺失值SELECT count(user_id),count(item),count(category),count(behavior),count(time)FROM userbehavior; 12345+----------------+-------------+-----------------+-----------------+-------------+| count(user_id) | count(item) | count(category) | count(behavior) | count(time) |+----------------+-------------+-----------------+-----------------+-------------+| 1000000 | 1000000 | 1000000 | 1000000 | 1000000 |+----------------+-------------+-----------------+-----------------+------------ 从查询结果来看，不存在缺失值，数据质量高。 3.3 时间格式转换12345678-- 新增date、hour时间字段ALTER TABLE userbehaviorADD date VARCHAR(20),ADD hour VARCHAR(20); -- 时间格式转换(此处time存储值是时间戳)UPDATE userbehavior SET date = FROM_UNIXTIME(time,\"%Y-%m-%d\");UPDATE userbehavior SET hour = FROM_UNIXTIME(time,\"%H\");UPDATE userbehavior SET time = FROM_UNIXTIME(time); 最后一句报错，因为创建表的时候time为int，超出长度了，改为bigint，再转换 12ALTER TABLE `taobao`.`userbehavior` MODIFY COLUMN `time` bigint(0) NULL DEFAULT NULL AFTER `behavior`; 12345-- 调整一下time字段数据的样式ALTER TABLE `taobao`.`userbehavior` MODIFY COLUMN `time` varchar(20) NULL DEFAULT NULL AFTER `behavior`;UPDATE userbehavior SET time = DATE_FORMAT(time,\"%Y-%m-%d %H:%i:%s\"); 3.4 过滤异常值由于数据集时间范围为2017-11-25至2017-12-3，因此需要对不在该时间范围内的异常数据进行过滤。 1234567# 筛选异常数据SELECT * FROM userbehaviorWHERE date &lt; '2017-11-25' or date &gt; '2017-12-03';# 过滤异常数据DELETE FROM userbehaviorWHERE date &lt; '2017-11-25' or date &gt; '2017-12-03'; 过滤掉470条数据 四、数据分析 分析框架 4.1 基于用户行为转化漏斗模型分析用户行为4.1.1 常见电商指标分析UV、PV、PV/UV1234567-- UV、PV、UV/PV指标统计SELECT count(DISTINCT user_id) as UV, sum(case when behavior='pv' then 1 else 0 end) as PV, sum(case when behavior='pv' then 1 else 0 end)/count(DISTINCT user_id) as 'PV/UV'FROM userbehavior;SELECT behavior,COUNT(*) FROM userbehavior GROUP BY behavior; 访问用户总数（UV，user view）：9739页面总访问量（PV，page view）：8956369天时间内平均每人页面访问量（PV/UV）：约为92次 复购率 复购率定义：在某时间窗口内重复消费用户（消费两次及以上的用户）在总消费用户中占比 重复消费用户的定义，又分为两种： （1）按天非去重，即一个用户一天产生多笔付款交易，则算重复消费用户。 （2）按天去重，即一个用户一天产生多笔交易付款，只算一次消费，除非在统计周期内另外一天也有消费，才算重复消费用户。 按天非去重，是目前b2c网站统计数据常用计算方法，相对计算出来的重复购买率要高于第二种 复购率与回购率不同 回购率定义：是某一个时间窗口内消费的用户，在下一个时间窗口仍旧消费的占比。 12345678910-- 复购率，先计算每个用户的购买次数buy_amount，所有人为购买总人数，buy_amount&gt;1的是复购人数SELECTSUM(case when buy_amount &gt; 1 then 1 else 0 end) as '复购总人数',COUNT(user_id) as '消费人数',SUM(case when buy_amount &gt; 1 then 1 else 0 end)/COUNT(user_id) as '复购率'FROM(SELECT user_id,behavior,COUNT(behavior) as buy_amountFROM userbehaviorWHERE behavior = 'buy'GROUP BY user_id) a; 从结果来看，复购率高达66.21%，反映淘宝的用户忠诚度较高。 跳失率 跳失率定义：仅仅访问了单个页面的用户占全部访问用户的百分比，或者指从首页离开网站的用户占所有访问用户的百分比。 跳出率可以反映用户对APP/网站内容的认可程度，或者说网站/APP是否对用户有吸引力。网站/APP的内容是否能够对用户有所帮助留住用户也直接可以在跳出率中看出来，所以跳出率是衡量网站/APP内容质量的重要标准。 12345678-- 跳出率SELECT COUNT(*) as \"仅访问页面一次的人数\"FROM(SELECT user_id,COUNT(behavior)FROM userbehaviorGROUP BY user_idHAVING COUNT(behavior)=1) a; 结果为0 统计结果表明，9天时间内，没有一名用户仅浏览一次页面就离开淘宝，跳失率为0。反映出商品或者商品详情页的内容对于用户具有足够的吸引力，让用户在淘宝驻留。 4.1.2 用户行为转化漏斗模型分析漏斗分析模型已经广泛应用于各行业的数据分析工作中，用以评估总体转化率、各个环节的转化率，以科学评估促销专题活动效果等，通过与其他数据分析模型结合进行深度用户行为分析，从而找到用户流失的原因，以提升用户量、活跃度、留存率，并提升数据分析与决策的科学性等。 AARRR模型（海盗模型、漏斗模型）：Acquisition(获取)、Activation(活跃)、Retention(留存)、Revenue(收益)、Refer(传播) 电商行业转化率算法 电商行业转化率算法 利润=销售额 X净利润率 =购买人数 X客单价 X净利润率 =进店人数 X购买转化率X客单价 X净利润率 =广告展现X广告转化率X购买转化率X客单价 X净利润率 =推广展现X推广转化率X购买转化率X客单价 X净利润率 =搜索展现X搜索转化率X购买转化率X客单价 X净利润率 =*X*转化率 X购买转化率X客单价 X净利润率 常用漏斗模型：首页—商品详情页—加入购物车—提交订单—支付订单 本数据集只包含商品详情页（pv）、加入购物车（cart）、支付订单（buy）数据，因此将漏斗模型简化为：商品详情页—加入购物车—支付订单。 用户总行为（PV）的转化漏斗 12345-- 用户总行为漏斗SELECT behavior,COUNT(*)FROM userbehaviorGROUP BY behaviororder by behavior desc; 用户总行为转化漏斗图： 独立访客（UV）的转化漏斗 12345-- 独立访客转化漏斗SELECT behavior,count(DISTINCT user_id)FROM userbehaviorGROUP BY behaviorORDER BY behavior DESC; 综合用户总行为转化漏斗图与独立访客转化漏斗图，可以发现： （1）从浏览商品详情页PV到有购买意向只有6.19%的转化率，但从浏览商品详情页UV到有购买意向有75.46%的转化率，说明用户在购买商品前会大量的去点击浏览商品详情页（pv/buy=895636/20359=44次）进行对比筛选，这一环节是指标提升的重点环节，尽量做到精准推荐，减少用户寻找信息的成本。 （2）支付订单用户数占浏览商品详情页用户数的68.92%，反映淘宝APP用户购买转化率较高，即淘宝APP上的商品能满足绝大部分用户的购买需求。 针对上述环节改善转化率的建议： （1）优化电商平台的搜索匹配度和推荐策略，主动根据用户喜好推荐相关的商品，优化商品搜索的准确度和聚合能力，对搜索结果排序优先级进行优化。 （2）在商品详情页的展示上突出用户关注的重点信息，精简信息流的呈现方式，减少用户寻找信息的成本。 4.2 从时间维度分析用户行为4.2.1 每天的用户行为分析12345678910-- 每天的用户行为分析SELECT date, count(DISTINCT user_id) as '每日用户数', sum(case when behavior='pv' then 1 else 0 end) as '浏览数', sum(case when behavior='cart' then 1 else 0 end) as '加购数', sum(case when behavior='fav' then 1 else 0 end) as '收藏数', sum(case when behavior='buy' then 1 else 0 end) as '购买数'FROM userbehaviorGROUP BY date; 每日用户行为数据变化： 在2017年11月25日-2017年12月3日统计窗口内，11月25-26日与12月2-3日为周末。 通过每日用户行为数据变化曲线可以分析：11月25日至12月1日，数据波动变化范围很小，在12月2-3日（周末），各项数据指标明显上涨，高于前7天的各项数据指标。由于在上一个周末（11月25-26日）的各项数据指标并未存在明显涨幅，因此推测在12月2-3日数据指标上涨可能与淘宝双12预热活动相关。 4.2.2 每时的用户行为分析12345678910-- 每时的用户行为分析SELECT hour, count(DISTINCT user_id) as '每时用户数', sum(case when behavior='pv' then 1 else 0 end) as '浏览数', sum(case when behavior='cart' then 1 else 0 end) as '加购数', sum(case when behavior='fav' then 1 else 0 end) as '收藏数', sum(case when behavior='buy' then 1 else 0 end) as '购买数'FROM userbehaviorGROUP BY hour; 每时用户行为数据变化： 结果显示：在凌晨2-5点左右，各项数据指标进入低谷期；在9-18点之间，数据呈现一个小高峰，波动变化较小；在20-23点间，各数据指标呈现一个大高峰，并且在21点左右达到每日数据最大峰值，数据的变化趋势比较符合正常用户的作息规律。在制定运营策略时，可以利用这个规律来进行创收，选择在每天用户最活跃的时间段推出各种网店直播、直播带货等互动营销手段。 4.3 从商品维度分析用户行为关于“受欢迎”的商品，可以从销量与浏览量两个维度（用户行为）去分析。但有的浏览量高的商品可能是因为被页面或广告等吸引而来，或者只是感兴趣，用户并不一定会购买；而销量高的产品有可能是用户真正需要的，搜索和点击购买的目标也比较明确。因此需要同时结合销量与浏览量两个维度去进行分析。 4.3.1 商品排行榜分析商品销量排行榜前10123456789-- 商品销量排行榜前10SELECTitem,count(behavior) as '销量'FROM userbehaviorWHERE behavior='buy'GROUP BY itemORDER BY 销量 descLIMIT 10; 从商品销量排行榜可以发现，在被下单的17565件商品中，单个商品销量最多不超过17次，且仅有5件商品销量超过10次，反映出在分析的数据集中，并没有出现卖的比较火爆的商品。 商品浏览量排行榜前101234567-- 商品浏览量排行榜前10SELECT item, count(behavior) as '浏览次数'FROM userbehaviorWHERE behavior='pv'GROUP BY item ORDER BY count(behavior) DESClimit 10; 对销量前10与浏览量前10的商品进行表连接： 12345678910111213141516171819202122-- 商品销量top10CREATE VIEW a ASSELECTitem,count(behavior) as '销量'FROM userbehaviorWHERE behavior='buy'GROUP BY itemORDER BY 销量 descLIMIT 10;-- 商品浏览量排行榜前10CREATE VIEW b ASSELECT item, count(behavior) as '浏览次数'FROM userbehaviorWHERE behavior='pv'GROUP BY item ORDER BY count(behavior) DESClimit 10;SELECT a.item,a.销量,b.浏览次数 FROM a LEFT JOIN b ON a.item=b.item;-- 这里用的视图，不使用直接子查询也是可以的 结果显示：商品销量榜单与商品浏览量榜单之间对应性差（仅有2件商品销量与浏览量同时进入前20榜单），反映浏览量高的商品其销量不一定高，销量高的商品其浏览量不一定高，因此需要同时结合销量与浏览量两个维度去进行分析。下面将以商品浏览量和销量两个维度指标来对商品进行四象限划分，分析不同类型商品对应的用户行为，并提出相应的改进措施。 4.3.2 商品四象限划分商品销量与浏览量两个维度的界限值分别选取3、20（需要根据实际业务场景来确定界限值），将商品按照销量与浏览量划分为四个象限： 第Ⅰ象限： 商品浏览量与销量都高，说明商品购买转化率高，属于受用户欢迎的商品。 改进措施：由于该象限内的商品有对应的市场，电商平台应该重点进行推送，并且可以多做活动，吸引更多的潜在用户。 第Ⅱ象限： 商品的销量高，但是浏览量较低。产生这种现象可能有以下两种原因（B端与C端两个角度）：一是 该象限内的商品可能属于某类特定群体的刚需产品，这类特定群体搜索和浏览的目标比较明确；二是 该象限内的商品受众广，但是引流入口数量少。 改进措施：收集目前购买与浏览该象限内商品的用户信息，分析用户画像，并结合商品的特点，核实产品是否存在某类特征明显的消费群体。如果存在，则电商平台可以集中向该类特征消费用户进行定向推送、精准推送；如果不存在，则可以对该象限内商品的多做推广，提高曝光率，并增加引流入口，流量上来了，销量可能会有提升。 第Ⅲ象限： 商品的浏览量低，销量也低。原因主要需要从B端进行分析：一是 该象限内商品的引流入口数量；二是 该象限内商品是否符合用户的需求？对用户的吸引力如何？ 改进措施：需要根据具体原因对症下药。 第Ⅳ象限： 商品的浏览量高，但是销量偏低，商品购买转化率低。其原因也可以分为B/C端进行分析：在B端方面，是否是广告的投放人群或者商品的推送目标有问题，并没有获取到对应商品的目标用户；是否是商品的定价与定位的原因，价格太贵且不符合主流消费群体的胃口；是否是商品详情页的图片、描述以及商品的评价较差；是否是客服的服务不到位、APP操作更新流程复杂等因素。在C端方面，用户的消费能力可能会对商品的销量有影响。 改进措施：需要根据具体原因对症下药。 4.3.4 “二八定律”or“长尾理论”分析知识点： （1）所谓的长尾商业模式，指的就是企业只要储备和营销渠道足够强大，那么那些销量不佳或需求不旺盛的产品所占据的市场份额，完全可以和大家眼中所认为的热卖品所占据的市场份额相媲美，甚至可以远远超越后者。这一商业模式的提出，同时也对传统的“二八定律”这一企业市场营销分析的理论造成了重大的冲击。 在传统企业的营销理念中，“二八定律”曾长期作为“正统”的经济理论思想存在。从概念上讲，“二八定律”是指20%的客户能够占有80%的市场份额；或者也可以说是20%法品牌产品占据了80%的市场份额。因此在这一市场营销定律的指导下，人们常常认为企业80%的利润来自于20%的客户或者是20%的品牌产品。如此一来，企业的经营重点就放在了20%的客户或者是20%的品牌产品上面。 长尾商业模式是在移动互联网时代所兴起的一种新颖商业营销方式，它在打破传统营销理念的同时，也能够很好地适应当今时代消费者“个性化、多元化”的市场需求。尤其是在产品产能广泛过剩的今天，过去那种认为只有通过标准化生产就能够抓住消费者消费需求的时代已经成为了历史，谁能够在“多元化、个性化”上下足功夫，把握住这一市场发展趋势，那么谁就可以抢占市场的商业先机，从而稳中求胜，实现企业发展的良好业绩。 （2）什么是互联网长尾效应 按照商品销量对商品分类统计，即 统计不同购买次数的商品各有多少个（购买次数为1的商品有多少个、2有多少个……）： 12345678910-- 按照商品销量对商品进行分类统计SELECT 购买数,count(item) AS '商品量'FROM (SELECT item,COUNT(behavior) AS '购买数'FROM userbehaviorWHERE behavior='buy'GROUP BY item)cGROUP BY 购买数ORDER BY 商品量 DESC; 绘制不同销量对应商品量柱状图： 根据不同销量对应商品量数据，在被下单的17565件商品中，只购买一次的商品有15536件，占下单总商品的88.45%，说明在互联网环境下，以淘宝为代表的电商平台，其商品售卖主要是依靠长尾商品的累计效应，并非爆款商品的带动。 4.4 基于RFM用户分层模型分析用户行为4.4.1 基于RFM模型的用户分层RFM模型：最近购买时间、消费频次、消费金额 基于RFM模型进行用户分层分析，由于数据集中不包含订单金额，故本次分析中不考虑M维度，只分析R、F两个维度，对两个维度的指标进行分级打分,最终按照综合得分对用户分层。 R维度分析计算用户的最近消费时间间隔R值（R值越小，说明用户最后消费时间越近），并对R值进行打分。根据R值结果，将其分为三个区间[0:2]，[3:5]以及[6:8]，分别赋予R_Score值3、2、1分。 123456789101112131415161718192021222324252627-- RFM模型——R维度分析CREATE VIEW r_value asSELECT user_id, min(时间间隔) as RFROM (SELECT user_id, DATEDIFF('2017-12-03',date) as '时间间隔' FROM userbehavior WHERE behavior='buy') a GROUP BY user_id;-- 进行R维度打分SELECT user_id, R, case when R BETWEEN 0 and 2 then 3 when R BETWEEN 3 and 5 then 2 else 1 end as R_ScoreFROM r_value-- 得到user_id、R、R_Score表-- 统计各分数人数SELECT R_Score,count(user_id)FROM(SELECT user_id, R, case when R BETWEEN 0 and 2 then 3 when R BETWEEN 3 and 5 then 2 else 1 end as R_ScoreFROM r_value)dGROUP BY R_Score; 统计不同R_Score占比： 从R_Score占比中可以发现，超过半数用户会在购物当天的后两天内就再次购买，可以看出淘宝已经成为人们的日常购物习惯。 F 维度分析计算用户的消费频率F值，并对F值进行打分。根据F值结果（最大值72次），将其分为6个区间[1:9]，[10:19]，[20:29]，[30:39]，[40:49]以及[50:72]，分别赋予F_Score值1、2、3、4、5、6分。 12345678910111213141516171819202122232425262728293031-- RFM模型——F维度分析CREATE VIEW f_value asSELECT user_id, count(behavior) as FFROM userbehaviorWHERE behavior='buy' GROUP BY user_idORDER BY count(behavior) DESC;-- 进行F维度打分SELECT user_id, F, case when F BETWEEN 1 and 9 then 1 when F BETWEEN 10 and 19 then 2 when F BETWEEN 20 and 29 then 3 when F BETWEEN 30 and 39 then 4 when F BETWEEN 40 and 49 then 5 else 6 end as F_ScoreFROM f_value--统计不同F_Score占比SELECT F_Score,count(user_id)FROM(SELECT user_id, F, case when F BETWEEN 1 and 9 then 1 when F BETWEEN 10 and 19 then 2 when F BETWEEN 20 and 29 then 3 when F BETWEEN 30 and 39 then 4 when F BETWEEN 40 and 49 then 5 else 6 end as F_ScoreFROM f_value)eGROUP BY F_Score; 统计不同F_Score占比： 从R_Score占比中可以发现，在统计窗口的9天时间内，96.76%的用户在淘宝平台消费1-9次。 用户分层RF综合打分： 123456789101112131415161718192021-- 进行R维度打分CREATE VIEW r_score asSELECT user_id, R, case when R BETWEEN 0 and 2 then 3 when R BETWEEN 3 and 5 then 2 else 1 end as R_ScoreFROM r_value-- 进行F维度打分CREATE VIEW f_score asSELECT user_id, F, case when F BETWEEN 1 and 9 then 1 when F BETWEEN 10 and 19 then 2 when F BETWEEN 20 and 29 then 3 when F BETWEEN 30 and 39 then 4 when F BETWEEN 40 and 49 then 5 else 6 end as F_ScoreFROM f_value-- RF综合打分CREATE VIEW rf_score as SELECT a.user_id, a.R_Score, b.F_Score, a.R_Score+b.F_Score as RF_ScoreFROM r_score a JOIN f_score b on a.user_id=b.user_id 根据RF_Score值，对用户进行分层：划分为2-3分，4-5分，6-7分，8-9分四个等级，分别对应易流失用户、挽留用户、发展用户、忠诚用户。 12345678910111213141516171819-- 用户分层SELECT *, case when RF_Score BETWEEN 2 and 3 then '易流失用户' when RF_Score BETWEEN 4 and 5 then '挽留用户' when RF_Score BETWEEN 6 and 7 then '发展用户' else '忠诚用户' end as '用户分层'FROM rf_score-- 统计不同类型用户占比SELECT 用户分层,count(user_id)FROM(SELECT *, case when RF_Score BETWEEN 2 and 3 then '易流失用户' when RF_Score BETWEEN 4 and 5 then '挽留用户' when RF_Score BETWEEN 6 and 7 then '发展用户' else '忠诚用户' end as '用户分层'FROM rf_score)gGROUP BY 用户分层; 用户分层结果： 重点挽留用户的比例最高，而且这部分客户给平台带来的潜在价值也很大，应该对这部分用户进行定期上新提醒、价格激励、订单搭配推荐等措施，留住用户并提高其消费频次； 易流失用户占比也相对较高，这部分客户可能已经找到替代品或对该公司产品不感兴趣了，可采取价格激励、发放优惠券等方式进行流失召回； 忠诚用户占比最少，这部分用户属于平台的 高价值用户，需要制定相应的运营策略来保持用户粘性； 重点发展用户占比也较低，对这部分用户发送提醒或促销活动邮件、促进其消费频次。 用户分层效果分析： 从不同用户占比上来看，本次用户分层的效果不佳，可能有以下两个方面原因：1、两个维度的打分区间划分的不合理，并没有用户很好的分开，应该在做区间划分时提前看一下各维度的用户分布情况，结合实际业务场景需求，去确定区间界限值；2、两个维度划分的区间数不一致，且赋予的分值区间差异较大，这种操作其实相当于给两个维度赋予了不同的比重。在本次用户分层中，可能采取RF两个维度的四象限划分更简单明了，且效果会更好。 4.4.2 高价值用户行为分析以user_id为107932的用户为例，对其进行深入分析： 1234567891011-- user_id为107932用户行为分析SELECT date, sum(case when behavior='pv' then 1 else 0 end) as '浏览数', sum(case when behavior='cart' then 1 else 0 end) as '加购数', sum(case when behavior='fav' then 1 else 0 end) as '收藏数', sum(case when behavior='buy' then 1 else 0 end) as '购买数', sum(case when behavior='buy' then 1 else 0 end)/sum(case when behavior='pv' then 1 else 0 end) as '购买转化率'FROM userbehaviorWHERE user_id = 107932GROUP BY date; 结果表明：该用户几乎每天都有消费，购买转化率也很高，但从未使用过收藏功能，购物车的使用频率也极低。对于高价值用户，可以分析其常购买的商品类型，再进行相关的商品推荐。由于商品种类数据为脱敏数据，本文无法分析该用户购买的商品类型。 五、结论与建议本文从4个维度分析了淘宝用户行为数据共100万条，结论和建议如下： 1、淘宝平台的商品对用户具有足够的吸引力（跳失率），且能够满足绝大部分用户的需求（购买转化率）。淘宝用户的忠诚度较高，复购率高达66.21%。从浏览商品详情页PV到有购买意向仅有6.19%的转化率，这一环节是指标提升的重点环节，尽量做到精准推荐，减少用户寻找信息的成本。针对上述环节改善转化率的建议：（1）优化电商平台的搜索匹配度和推荐策略，主动根据用户喜好推荐相关的商品，优化商品搜索的准确度和聚合能力，对搜索结果排序优先级进行优化。（2）在商品详情页的展示上突出用户关注的重点信息，精简信息流的呈现方式，减少用户寻找信息的成本。 2、用户的各种行为数据指标在周末和工作日的差别不大，但是受双12等大型平台活动影响较大。每天晚上的20-23点间是用户活跃度最高的时间段，各数据指标呈现一个大高峰，并且在21点左右达到每日数据最大峰值。在制定运营策略时，可以利用这个规律来进行创收，选择在每天用户最活跃的时间段推出各种网店直播、直播带货等互动营销手段。 3、商品销量与商品浏览量之间相关性较差，浏览量高的商品其销量不一定高，销量高的商品其浏览量不一定高，结合商品四象限划分结果，各象限商品都可从B端与C端两个角度去分析原因，并针对性的进行改善。 4、淘宝平台商品售卖主要是依靠长尾商品的累计效应，并非爆款商品的带动。建议：长尾效应的确能带来一部分收益，但是，繁多的种类对于商家来说其实是一种经营负担，成本也较高。二八定律告诉我们，商家其实可以通过打造爆款商品来获利。打造爆款商品具体的建议是：品控上提高产品质量，宣传上增大力度（直播、微淘、引流到其他平台），展现上突出产品优势等（主图、详情页、评论）。 5、通过RFM模型对用户进行分层，找出RF评分高的作为高价值用户，并对不同类型的用户采取不用的运行策略。","categories":[{"name":"SQL","slug":"SQL","permalink":"http://mangosTeeN96.github.io/categories/SQL/"}],"tags":[{"name":"数据分析","slug":"数据分析","permalink":"http://mangosTeeN96.github.io/tags/数据分析/"}]},{"title":"天池-数据分析","slug":"天池-数据分析","date":"2020-02-15T11:51:19.000Z","updated":"2020-08-10T06:14:13.637Z","comments":true,"path":"2020/02/15/天池-数据分析/","link":"","permalink":"http://mangosTeeN96.github.io/2020/02/15/天池-数据分析/","excerpt":"","text":"天池大数据竞赛“数智教育”2019数据可视化竞赛亚军 比赛官网链接：官网链接 作品GitHub链接：代码 作品线上链接：网页 官网赛题背景与需求： 教育中大数据分析目的包括改善学生成绩，服务教务设计，优化学生服务。而学生成绩中有一系列重要的信息往往被我们常规研究所忽视。通过大数据分析和可视化展示，挖掘重要信息，改善学生服务，对于教学改进意义重大。美国教育部门构建“学习分析系统”，旨在向教育工作者提供了解学生到底是在“怎样”学习的更多、更好、更精确信息。利用大数据的学习分析能够向教育工作者提供有用的信息，从而帮助其回答这些不太好回答的现实问题。未来学生的学习行为画像、考试分数、发展潜力方向等所有重要的信息等数据价值将会持续被显现出来，大数据将掀起新的教育革命，比如革新学生的学习、教师的教学、教育政策制定的方式与方法。为了更好的优化教学大数据应用场景，比赛通过学校教育数据分析和可视化工作，探索面向学生、校园的数据分析体系，募集优秀数据分析及可视化方案，设计并形成数据分析门户，从而更好服务精细化教学管理工作。 赛题分析比赛公开效实中学的存量数据，其中包括学生的信息数据（已脱敏）、教师信息数据、学生成绩数据、学生消费数据等，需求是开发一个信息门户，通过可视化的手段来服务学校的教学管理工作。 首先，比赛的赛题和方向很具体，需求也很明确，并给出较为完善的数据，需要基于对于业务场景的理解，进行数据分析，挖掘重要信息，进而进行数据可视化服务。 我们的作品亮点主要有二： 第一，作品需要分层。根据需求，信息门户的使用人群一定有区别，不同的人群所关注的要点也不相同：学校领导层次如校长、年级主任等需要了解学校的整体情况，其并不会关系到学生层次的信息；班主任与授课教师会更加关注自己所带班级的整体水平，与其他班级的差距等；学生个人和学生家长则会更加关心学生个人或所在班级的整体水平。因此，针对不同人群需要的不同信息，对系统进行分层是十分必要的。 第二，作品需要解决具体的问题。数据分析与可视化，很大一方面的作用是结合人们的先验知识，辅助使用者进行决策，去解决一些实际的问题。因此我们开发了学生成绩提升模块、贫困生帮扶模块和高考学科七选三模块。 系统架构设计思路：从整体到局部，从分析到应用，针对不同人群 面向人群：校领导层、班主任、科任教师、家长、学生 系统架构模型： 系统分层结构基本思想：系统开发学校、班级、学生和应用四个层次的功能模块，根据使用人群不同，提供不同层次的展示效果。具体功能模块与面向人群如下： 数据分析部分笔记一、学校层面总体导图： 主要面对人群：校领导层 次要面对人群：班主任、科任教师 1.1 基本信息统计可视化页面展示： 通过对student_info数据的观察，确定需要统计展示的基本信息。对基本信息的统计，并不复杂。注意缺失值处理，以及一些文字的不同描述，对个例进行另行处理。 性别统计、民族统计、出生地统计、政治面貌统计、年龄统计、住校学生统计。 关于直接给dataframe增加一列，很方便，但会报error。(insert) 1.2 师资分配情况可视化页面展示： 观察teacher数据，根据提供的教师数据分析教师情况。 教师水平评估：处理获得各年级各科教师所教班级平均分、年级总体平均分数据。通过 将各科老师所教班级平均分 与 总体平均分进行比较，对教师水平进行评估。 师资分配:：处理获得各年级各学科教师人数数据。默认情况下，对某一学科的教师数量进行年级对比；堆叠图时，可对比各学科教师总数。可以帮助校领导层平衡学校教师的年级分配和学科分配。 教师班级关系：处理获得各学科教师与所带班级的对应关系数据。同一学科下教师的图块宽度表示该教师带班数量。通过对比教师带班数量，帮助校领导层了解教师压力，平衡教师带班数量 对数据一层层处理统计。各年级教师数量、各学科教师数量、各教师带班数量、不同年级学科教师数量、各教师带班数量。transfer to json。 1.3 成绩统计分析可视化页面展示： 顶尖毕业生历年成绩趋势：选取每年高三五校联考的第1名和第30名的成绩，观察他们的成绩数据趋势。帮助校领导层了解学校教育质量变化趋势 年级成绩箱形图: 统计各年级各科学生的整体成绩分布情况。帮助校领导层了解学校各年级成绩的分布和成绩垫底的学生的具体情况 班级成绩对比：由于每次考试的难度不同，简单对比班级最高分、最低分、平均分的变化趋势意义不大，因此选取某一次考试来对比三个年级各班的最高分、最低分、平均分数据，体现出班级的差别。帮助校领导层和科任教师了解各个班级的上限和下限，针对不同班级作出不同调整 班级排名对比：处理获得各班学生成绩，在班级排名与年级排名的对应关系数据。左上排名高，右下排名低，下降越快表示该班级学生水平差异越大，默认显示三个班级。通过比较班级曲线的下降幅度，可以了解班级学生的成绩是否两极分化严重；同时，横向比较各班级的排名曲线，也能了解班级教学质量的差异。 成绩段人数分布：统计各次考试各科目各班各成绩段的人数数据。默认为堆叠图，以对比各班级学生在各个分数段的人数；切换到平铺后，可对比班级中各个分数段的人数分布情况。通过分数段人数的对比，可以了解到班级中学生的水平分布情况，有助于班主任和科任教师根据班级的实际情况作出相应调整 班级成绩分布对比：获得各班级各科目的等地成绩数据。通过散点图与平行坐标系展示各个班级的成绩分布，组件可通过右上角圈选工具来选择数据并查看。用于观察学科之间的内在联系，以及各班级学生的考试成绩分布，帮助科任教师针对学科成绩较差的班级作出调整 为方便分析先得出学生ID-届数表，通过：1.班级名称中有高一高二高三字眼 2.参与考试名称中有高三考试才有的特定字眼。选取各届高三学生最后一次考试五校联考，获得考试成绩top30。 统计学校学生成绩时，要选取某次考试进行分析：找到考试数据最多的两次考试，观察其数据，选取2017学年度第一学期期末总评作为样本数据。 学校层面的成绩数据展示，不同学科的成绩之间比较没有意义，主要对班级之间的单科成绩、班级排名在学校排名内的分布、班级成绩分数段分布等数据进行统计对比。 1.4 考勤信息统计可视化页面展示： 统计打卡高峰期、学校每天正常到勤人数、异常考勤人数及比例数据。 考勤数据数据质量较差。先在Excel中观察，再pandas观察，对数据进行处理后，保存新的原始数据表csv进行分析。 学期栏数据缺失较多，有时间性，考虑可以将数据按时间排序，学期栏数据直接顺延使用上一个。 关于考勤类型的一些记录与推测：（1）100000 正常时间到校，上课时间为7:25。（2）100100 早晨上学迟到，在上课时间迟到一点。（3）100200 晚到，白天的时间段都有，离上学时间差距很大。（4）100300 晚自习迟到，该类型没有一例登记。（5）200000 该类型没有一例登记。（6）200100 校徽校服，预计是没有穿着校服。（7）200200 早退，也就是早退数据。（8）300000 操场默认登记数据。（9）300100 住宿生早上锻炼记录。（10）300200 课间操请假。（11）9900100 迟到登记数据，用于几年后，可能设备进行更新了。（12）9900200 校徽校服数据。（13）9900300 早退数据。（14）9900400 离校数据，推测属于正常离校数据。（15）9900500 进校数据，推测为正常进校数据。 需要进行统计展示的信息：（1）早上迟到： 100100 + 9900100 + 100200。（2）请假离校（早退）： 200200 + 9900300。（3）校徽校服问题： 200100 + 9900200。（4）课间操请假： 300200（只能统计2014年信息） 由于要展示异常考勤数据量与比例变化，而各学年登记次数不一样，考虑是否进行归一化处理或者计算比例。选择计算比例。但有些月份由于样本数量过少，导致比例数值过高，用百分比不妥，要进行处理，进行等比例缩放。 分别按照学年、学期、月份、天数对2018年数据进行划分统计。 1.5 消费信息统计可视化页面展示： 18学年按日消费人数、消费总额。消费总额、消费人数、人均金额的趋势。 按小时人均消费高峰时刻：统计各时段消费人数数据。通过钟表的形式显示学校的消费高峰。帮助校领导针对不同的时段作出相应安排，达到最大化利用学校资源。 男女生消费总额、消费人数、人均金额消费对比。 贫困生消费总览：展示贫困生的每次消费的次数与数值数据情况，通过图例可以查看不同贫困生。帮助校领导层了解每个贫困生的消费情况，针对异常情况及时干预。 消费数据日期较不规范，除了使用字符串处理之外，使用datetime时间序列进行处理更为方便。 二、班级层面总体导图： 主要面向人群：班主任、科任教师 次要面向人群：校领导层、家长、学生 2.1 班级画像可视化页面展示： 因为数据的完备性问题，选取较有代表性样例展示，后期根据应用进行拓展。 班级画像内容包括： 成绩： 整体情况： 按科目统计的整体成绩数据、成绩趋势。 按考试场次统计的各科目整体成绩、箱型图数据（边界、四分位数、中位数）。 具体情况： 按考试场次统计的各科成绩人数，总分人数。 按学年统计考查课（音体美）各科成绩人数。 统计学生文理科排名。将班级学生分为4类：文理较优、文优理劣、文劣理优、文理较劣。匹配出帮扶对应关系 消费：选取一学期每天班级消费总额、消费人数、消费最值、消费均值数据。 考勤：一学期班级所有考勤数据情况，包括离校进校、迟到、校服。 班级画像展示了：整体成绩情况、个体成绩情况、消费情况、考勤情况 三、学生层面总体导图： 主要面向人群：班主任、家长、学生 次要面向人群：校领导层、科任教师 3.1 学生画像可视化页面展示： 个人信息 统计一个学生的基本信息。统计学生的姓名、学号、性别、民族、班级名、出生日期、籍贯、政治面貌、住宿信息（寝室号、人数） 成绩 该学生每一科的排名情况，对比看学科短板 成绩趋势，包括总分成绩趋势、总分排名趋势、考查课排名趋势、各科排名趋势 考勤 查看学生考勤数据集和学生信息的数据集的耦合情况，发现耦合程度差，考勤数据中有的学生ID在学生信息数据集中也有的比例大概占76/300、33/100。 统计三个层次的考勤信息：学生、班级平均、学校平均 消费 按每个星期几、每小时统计消费次数，查看学生消费习惯 查看学生两个月的消费数据（查看选取消费数据较多的月份） 时序预测：关于学生成绩预测问题，对于学生的成绩的预测，采用ARIMA时序预测来完成。原因是认为学生的成绩有较强的时间相关性，有的学生成绩在一段时间内，成绩处于上升或下降趋势。若采用LightGBM等基于树模型的算法，需要所有学生的成绩数据来进行预测，同时成绩方面没有较多的特征，数据存量也较少，因此可能效果会不好。 若训练数据可以更新，比如每次的小型考试的成绩也进行记录，那样将会极大的丰富学生的成绩训练集，采用LGB和XGBoost等算法可能将会有更大的应用空间。 成绩回归谬误：引入成绩置信区间，解决成绩回归谬误问题。 问题背景：学生成绩分布整体服从正态分布，学生单次考试存在波动为正常现象。回归谬误未考虑统计学上随机起落的回归现象，造成不恰当的因果推论。 解决方案：设置合理波动区间，成绩处于区间中即为正常波动。 波动区间决定于前几次考试整体趋势，如趋势整体上升，则波动区间较大，反之较小。 四、应用层面学生成绩提升：采用曲线拟合、DBSCAN算法、相关性分析方法 贫困生帮扶：采用多指标交叉验证、构建贫困指数评价指标方法 高考学科七选三：采用数据清洗、数据统计的分析方法 4.1 提升学生成绩可视化页面展示： 成绩与考勤的关系（曲线拟合）根据所给数据，考虑可以分析一下考勤与成绩是否存在关系，用以帮助提升学生成绩。 展示迟到早退次数与z成绩的关系。 Z-Score：标准化的成绩，大于0高于平均分，反之低于） 展示不同迟到早退次数人群中，成绩高于班级平均分（优生）、成绩低于平均分（差生）的各自比例 不同异常考勤次数的学生群体中，mes-Z-score&gt;0（优生）比例、mes-Z-score&lt;0（差生）比例 通过散点图可以看出有一定相关性，进行二阶拟合 拟合结果看出，学生的成绩与迟到早退现象存在一定的联系。学校需要提升相应的管理能力。 成绩稳定性（DBSCAN聚类）探究学生成绩稳定性与群体 学生科目的稳定性可以通过学生该科目的标准差进行评估，对所有学生群体分析，也存在较为明显的分布模式。 做出每个学生的科目平均分与标准差的分布图，采用DBSCAN进行密度聚类，划分成绩稳定与不稳定学生群体。 DBSCAN参数（eps=1.19, min_samples=7.8） 选取其中不稳定群体，对其标准差进行数据进行输出展示。 结论：学校中有部分学生，其成绩中等偏上，但成绩极不稳定，他们有着很大的提升空间，需要班主任、科任教师和校领导高度重视 学科相关性（关联性统计）分析学生各科目成绩之间是否有关联。 先绘制散点图进行观察，使用corr计算相关系数。 对两学科成绩之间通过线性回归进行拟合。LinearRegression() 获得线性回归拟合直线y=wTx+b中的权重参数w和b。 部分学科之间存在较强的线性相关性，充分利用这一点可以有效提高学生的成绩。若某学生数学成绩优异，但物理成绩不理想，由于数学和物理关联性较强，教师如果提供针对性帮助，该生的物理成绩提升空间极大。 4.2 贫困生帮扶可视化页面展示： 贫困生群体发现 统计每个学生的消费次数与消费总额、消费次数与平均消费，帮助发现学生中的贫困群体 消除住校生与走读生的消费差距，进行归一化处理 通过阈值来筛选疑似贫困生 贫困生与非贫困生消费对比 完成贫困群体的消费规律，强调对比性，即疑似贫困生和正常消费水平的学生的消费习惯 学生消费总金额对比：统计一个月每一天的学生消费情况，选取贫困生与正常学生进行对比（强调贫困生的消费总金额很少） 学生每天消费次数对比：统计一个月每一天的学生消费次数，选取贫困生与正常学生进行对比（强调贫困生的消费次数稳定） 学生平均每次消费金额对比（强调贫困生的每次消费金额少） 对比可以探究贫困生与非贫困生的消费差异，也可帮助及时干预异常消费。 产生贫困生群体的消费习惯：选取20个贫困生代表群体，选取的原则是消费次数在300次左右，但是平均消费金额较低的学生 贫困指数综合评估 构建贫困生指标，评价贫困生群体的贫困指数，并根据指数划定贫困等级。贫困指数计算： 4.3 七选三推荐系统可视化页面展示： 学科七选三推荐 针对学生个人 统计学生的各科各次考试成绩，学科平均分、最高分、最低分、稳定性数据。学生选取高二年级学生，去除数据量过少的学生数据。学科选择七门主科。学生成绩稳定性公式如下： 根据学生成绩数据计算出推荐指数。 学科选择比例 针对所有学生群体 统计单学科学生选择比例、三学科组合选择比例、确定一门学科后双学科组合比例。 通过整体情况帮助学生对七选三做出更好的判断。 4.4 全域数据查询","categories":[{"name":"python","slug":"python","permalink":"http://mangosTeeN96.github.io/categories/python/"}],"tags":[{"name":"数据分析","slug":"数据分析","permalink":"http://mangosTeeN96.github.io/tags/数据分析/"}]},{"title":"SQL","slug":"SQL","date":"2020-02-14T06:37:55.000Z","updated":"2020-08-10T06:14:21.047Z","comments":true,"path":"2020/02/14/SQL/","link":"","permalink":"http://mangosTeeN96.github.io/2020/02/14/SQL/","excerpt":"","text":"SQL 结构化查询语言 用来操作RDBMS的数据库语言 当前关系型数据库都支持使用SQL语言进行操作（oracle、sql server、mysql、sqlite..） SQL语句主要分为： DQL：数据查询语言，用于对数据进行查询，如select DML：数据操作语言：对数据增加、修改、删除，如insert、update、delete TPL：事务处理语言 DCL：数据控制语言 DDL：数据定义语言 CCL：指针控制语言 不区分大小写 运行sql文件：在mysql命令行，source 绝对路径 多数；可写可不写，规范代码写 SQL语言书写基本规则 SQL语句本身对大小写不敏感，但通常SQL内置函数和命令一般 采用大写，例如 SELECT FROM、函数 COUNT()等;数据库内的 表名、表别名、字段名、序列等通常采用小写。 变量名命名使用英文，不能超出 30 个字符，简洁易懂 每条 SQL 命令末端使用分号(;)结尾，关键词不能跨多行或者 简写 用空格和缩进来提高语句的可读性，语句通常缩进 4 个空格。 SQL 语句内逻辑运算符(OR\\IN\\AND)、比较运算符号(=、 &lt;=、&gt;=、&gt;、&lt;、BETWEEN AND)、IN、LIKE 等使用时前 后加 1 个空格 逗号之后必须添加 1 个空格 同层次的 SQL 命令缩进应保持一致，纵向对齐。 SQL 语句可以折行操作，较长的语句可分多行编写。通常对于 SELECT/FROM/ORDER BY/GOUP BY/WHERE 等子句需要另起一 行书写。 SELECT(FROM)子句内容多于一项可分行书写，只有一项 同行书写 WHERE 子句条件有多项时每一个条件占一行，以 AND 或 OR 开头，在对应 WHERE 的基础上向右缩进 4 个空格。 SQL 语句中间不允许出现空行 引用字符串类型数据时用单引号，例如引用姓名 name ‘xiaoming’ 较为复杂的SQL语句需加上注释。单行注释采用符号 –，多行注 释采用符号 /**/ 注释单独成行，位于 SQL 命令前面，对于过长的命令语句，应按照函数实现的功能分段注释加以说明 多表连接时，使用表的别名以简化 SQL 命令，例如 sales.s 将表 sales 简化为 s 代称以进行接下来对表内数据引用 出于对 SQL 运行优化的考虑，对于数据量小的表可以使用 * 进 行全表扫描，数据量大的表应先进行索引加快数据查询 表操作创建表CREATE TABLE 语句 CREATE TABLE 语句用于创建数据库中的表。 SQL CREATE TABLE 语法 1234567CREATE TABLE 表名称(列名称1 数据类型,列名称2 数据类型,列名称3 数据类型,....) 数据类型（data_type）规定了列可容纳何种数据类型。下面的表格包含了SQL中最常用的数据类型： 数据类型 描述 integer(size)int(size)smallint(size)tinyint(size) 仅容纳整数。在括号内规定数字的最大位数。 decimal(size,d)numeric(size,d) 容纳带有小数的数字。”size” 规定数字的最大位数。”d” 规定小数点右侧的最大位数。 char(size) 容纳固定长度的字符串（可容纳字母、数字以及特殊字符）。在括号中规定字符串的长度。 varchar(size) 容纳可变长度的字符串（可容纳字母、数字以及特殊的字符）。在括号中规定字符串的最大长度。 date(yyyymmdd) 容纳日期。 SQL CREATE TABLE 实例 本例演示如何创建名为 “Person” 的表。 该表包含 5 个列，列名分别是：”Id_P”、”LastName”、”FirstName”、”Address” 以及 “City”： 12345678CREATE TABLE Persons(Id_P int,LastName varchar(255),FirstName varchar(255),Address varchar(255),City varchar(255)) Id_P 列的数据类型是 int，包含整数。其余 4 列的数据类型是 varchar，最大长度为 255 个字符。 空的 “Persons” 表类似这样： Id_P LastName FirstName Address City 可使用 INSERT INTO 语句向空表写入数据。 SQL 约束 约束用于限制加入表的数据的类型。 可以在创建表时规定约束（通过 CREATE TABLE 语句），或者在表创建之后也可以（通过 ALTER TABLE 语句）。 主要探讨以下几种约束： 约束 描述 NOT NULL 约束强制列不接受 NULL 值。NOT NULL 约束强制字段始终包含值。这意味着，如果不向字段添加值，就无法插入新记录或者更新记录。 UNIQUE 约束唯一标识数据库表中的每条记录。UNIQUE 和 PRIMARY KEY 约束均为列或列集合提供了唯一性的保证。PRIMARY KEY 拥有自动定义的 UNIQUE 约束。请注意，每个表可以有多个 UNIQUE 约束，但是每个表只能有一个 PRIMARY KEY 约束。 PRIMARY KEY 约束唯一标识数据库表中的每条记录。主键必须包含唯一的值。不能包含 NULL 值。每个表都应该有一个主键，并且每个表只能有一个主键。 FOREIGN KEY 外键，一个表中的 FOREIGN KEY 指向另一个表中的 PRIMARY KEY。 CHECK 约束用于限制列中的值的范围。如果对单个列定义 CHECK 约束，那么该列只允许特定的值。如果对一个表定义 CHECK 约束，那么此约束会在特定的列中对值进行限制。 DEFAULT 约束用于向列中插入默认值。（NULL也可以） 12345678910111213141516171819202122232425262728293031323334CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,City varchar(255),UNIQUE (Id_P))--内键、外键CREATE TABLE Orders(Id_O int NOT NULL,OrderNo int NOT NULL,Id_P int,PRIMARY KEY (Id_O),FOREIGN KEY (Id_P) REFERENCES Persons(Id_P))--命名 PRIMARY KEY 约束，以及为多个列定义 PRIMARY KEY 约束CONSTRAINT pk_PersonID PRIMARY KEY (Id_P,LastName)CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,City varchar(255),CHECK (Id_P&gt;0))CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,City varchar(255) DEFAULT 'Sandnes') 修改表ALTER TABLE 语句，用于在已有的表中添加、修改或删除列。 ALTER TABLE 语法 在表中添加列: 12ALTER TABLE table_nameADD column_name datatype 删除表中的列： 12ALTER TABLE table_name DROP COLUMN column_name 某些数据库系统不允许这种在数据库表中删除列的方式 (DROP COLUMN column_name)。 要改变表中列的数据类型： 12ALTER TABLE table_nameALTER COLUMN column_name datatype 查看表1describe table table_name SQL增删改增INSERT INTO 语句用于向表格中插入新的行。（需要一一对应） 1INSERT INTO 表名称 VALUES (值1, 值2,....) 也可以向指定的列插入数据： 1INSERT INTO table_name (列1, 列2,...) VALUES (值1, 值2,....) 改Update 语句用于修改表中的数据。（两个列名称可以不同） 1UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值 update 表名 set 列1=值1，列2=值2… where 条件； （不写条件整列都改） 删DELETE 语句用于删除表中的行。(删除列指定的行) 1DELETE FROM 表名称 WHERE 列名称 = 值 不写where全部删除，在不删除表的情况下删除所有的行。这意味着表的结构、属性和索引都是完整的 delete为物理删除 逻辑删除（用一个字段表示 这条信息已经不能使用 表示删除） alter table 表名 add is_delect bit default 0；（bit不到一个字节，看不见，只能存0、1）（改为1时可以看出来）可以在创建表的时候直接 is_delect bit default 0 SQL基础查询123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338/*查询数据 关键字SELECT SELECT column_name(s) FROM table_name SELECT * FROM table_name * 代表所有字段 */ -- /* demoSELECT * FROM orderdata;SELECT user_id, car_no, co_time FROM orderdata;-- *//*SQL 处理重复数据 有时候，数据表中会存在相同的记录。在获取表中记录时，相较于取得重复记录来说，取得唯一的记录显然更有意义。 SELECT DISTINCT column_name(s) FROM table_name */-- /*demoSELECT DISTINCT car_type FROM orderdata -- *//*排序返回结果 将查询结果排序后展示：关键字ORDER BY … [ASC/DESC] SELECT column_name(s) FROM table_name ORDER BY column_name [ASC|DESC] ASC为正序 DESC为倒序*/-- /* demoSELECT user_id, car_no, co_time, mileage FROM orderdata ORDER BY co_time DESC SELECT user_id, car_no, co_time, mileage FROM orderdata ORDER BY co_time ASC, mileage DESC SELECT * FROM student ORDER BY class_id ASC, score DESC-- *//*指定要返回的记录数量 SQL SELECT TOP, LIMIT, ROWNUM 用于指定要返回的记录数量 并不是所有的数据库系统都支持SELECT TOP子句。MySQL支持LIMIT子句来选择有限数量的记录，而Oracle使用ROWNUM。 SELECT LIMIT子句在包含数千条记录的大型表上很有用。返回大量记录会影响性能。 SELECT column_name(s) FROM table_name LIMIT NUMBER 1.想随便查看一下表中的数据； 2.一般与ORDER BY关键字配合使用，返回按某些字段排序后的前几行 */-- /* demoSELECT * FROM orderdata LIMIT 10;SELECT user_id, car_no, co_time FROM orderdata ORDER BY co_time DESC LIMIT 10 -- *//*指定要返回中间几行 返回中间几行：关键字LIMIT M OFFSET N（从第N行开始，返回M行记录） 两种写法： SELECT 字段列表 FROM 表名 LIMIT M OFFSET N; SELECT 字段列表 FROM 表名 LIMIT N,M; */-- /* demoSELECT user_id, car_no, co_time FROM orderdata ORDER BY co_time DESC LIMIT 10 OFFSET 2;SELECT user_id, car_no, co_time FROM orderdata ORDER BY co_time DESC LIMIT 2,10; -- *//*过滤数据 WHERE 子句用于过滤记录 WHERE 子句用于提取满足指定标准的记录 SELECT 字段列表 FROM 表名 WHERE 过滤条件 过滤条件一般由 要过滤的字段、操作符、限定值三部分组成 SELECT column_name(s) FROM table_name WHERE column_name operator value */-- /* demo/*常用操作符 过滤单个值 */-- /* demoSELECT user_id, car_no, car_type FROM orderdata WHERE car_type = '海马爱尚EV';-- */SELECT user_id, car_no, mileage FROM orderdata WHERE mileage &gt; 100;SELECT user_id, car_no, pu_point FROM orderdata WHERE pu_point = '天地软件园.金枫楼';SELECT user_id, car_no, co_time FROM orderdata WHERE co_time &lt;= '2019-6-2';-- *//*SQL NULL Values（空值） SQL中，NULL用于表示缺失的值。数据表中的 NULL值表示该值所处的字段为空。 具有NULL值的字段是没有值的字段。 NULL值与零值或包含空格的字段是不同的 具有NULL值的字段是在记录创建期间留空的字段 使用比较运算符（例如=，&lt;或&lt;&gt;）来测试NULL值是不可行的。 我们使用IS NULL和IS NOT NULL运算符。*/-- /* demoSELECT user_id, car_no, token FROM orderdata WHERE token IS NULL;SELECT user_id, car_no, token FROM orderdata WHERE token IS NOT NULL;-- *//*过滤集合 SQL BETWEEN运算符 BETWEEN运算符用于选取介于两个值之间的数据范围内的值。 BETWEEN运算符选择给定范围内的值。值可以是数字，文本或日期。 BETWEEN运算符是包含性的：包括开始和结束值，且开始值需小于结束值。 SELECT column_name(s) FROM table_name WHERE column_name BETWEEN value1 AND value2*/-- /*demoSELECT user_id, car_no, pay_amount FROM orderdata WHERE pay_amount BETWEEN 10 AND 15;SELECT user_id, car_no, co_time FROM orderdata WHERE co_time BETWEEN '2019-08-01 00:00:00' AND '2019-09-01 00:00:00';-- *//*过滤集合 SQL AND, OR and NOT AND操作符满足所有条件 OR操作符满足任一条件 NOT操作符不满足条件 SELECT column_name(s) FROM table_name WHERE condition AND|OR condition*/-- /*demoSELECT user_id, user_name, pu_point, car_type FROM orderdata WHERE pu_point = '天地软件园.金枫楼' AND car_type = '海马爱尚EV';SELECT user_id, user_name, pu_point, car_type FROM orderdata WHERE pu_point = '天地软件园.金枫楼' OR car_type = '海马爱尚EV';SELECT user_id, user_name, pu_point, car_type, mileage FROM orderdata WHERE NOT mileage &gt; 10;SELECT user_id, user_name, pu_point, car_type, mileage FROM orderdata WHERE NOT mileage &gt; 100 AND pu_point = '天地软件园.金枫楼' OR car_type = '海马爱尚EV';-- *//*过滤集合 SQL IN 运算符 IN运算符允许您在WHERE子句中指定多个值。 IN运算符是多个OR条件的简写。 SELECT column_name(s) FROM table_name WHERE column_name IN (value1,value2,..)*/-- /*demoSELECT user_id, car_no, pu_point FROM orderdata WHERE pu_point IN ( '天地软件园.金枫楼', 'BAC公司' );SELECT user_id, car_no, car_type FROM orderdata WHERE car_type NOT IN ( '海马爱尚EV', '一汽新特EV' );SELECT * FROM student WHERE teacher_id IN ( SELECT teacher_id FROM teacher );-- *//*过滤集合 SQL LIKE 及 通配符 问题： 我们想取出所有姓李的用户 通配符： ％ 百分号表示零个，一个或多个字符 _ 下划线表示单个字符 在WHERE子句中使用LIKE运算符来搜索列中的指定模式。 两个通配符与LIKE运算符一起使用 SELECT column_name(s) FROM table_name WHERE column_name LIKE pattern 'a%' 查找以“a”开头的任何值 '%a' 查找以“a”结尾的任何值 '%a%'在任何位置查找任何具有“a”的值 '_a%' 在第二个位置查找任何具有“a”的值 'a_%_%' 查找以“a”开头且长度至少为3个字符的值 'a%o' 找到以\"a\"开头，以\"o\"结尾的值 */-- /*demoSELECT user_id, user_name, car_type FROM orderdata WHERE user_name LIKE '李%';SELECT user_id, user_name, car_type FROM orderdata WHERE user_name LIKE '%飞';SELECT user_id, user_name, car_type FROM orderdata WHERE user_name LIKE '李_轩';-- */ distinct函数 使用SQL进行数据分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286/*SQL 子查询 两个表，主键外键 问题 1 我们想同时查出学生编号、学生姓名，和老师编号，老师姓名 问题 2 获取姓刘的老师教的年龄大于12岁的学生信息 子查询是一种嵌套在其他 SQL 查询的 WHERE 子句中的查询 子查询用于为 1 主查询返回其所需数据 （FROM） 2 对检索数据进行进一步的限制（WHERE） SELECT column_name FROM table1 (SELECT column_name FROM table2 ) WHERE column_name OPERATOR (SELECT column_name FROM table2 ) 1 子查询必须括在圆括号中 2 子查询的 SELECT 子句中只能有一个列 3 子查询不能使用 ORDER BY*/-- /*demo1 我们想同时查出学生编号、学生姓名，和老师编号，老师姓名（选择了两个表的内容）SELECT student_id, student_name, teacher_id, ( SELECT teacher_name FROM teacher WHERE teacher.teacher_id = student.teacher_id ) FROM student WHERE student.teacher_id IS NOT NULL;-- */-- /*demo2 获取姓刘的老师教的年龄大于12岁的学生信息SELECT student_id, student_name, age, teacher_id, ( SELECT teacher_name FROM teacher WHERE teacher.teacher_id = student.teacher_id ) FROM student WHERE student.age &gt;= 12 AND teacher_id IN ( SELECT teacher_id FROM teacher WHERE teacher_name LIKE '刘%' );-- */ -- /*demo3/*EXISTS子句的返回值是一个 BOOL值。 EXISTS内部有一个子查询语句 ( SELECT...FROM...)， 我将其称为 EXIST的内查询语句。其内查询语句返回一个结果集。 EXISTS子句根据其内查询语句的结果集空或者非空，返回一个布尔值。 一种通俗的可以理解为：将外查询表的每一行，代入内查询作为检验，如果内查询返回的结果取非空值，则 EXISTS子句返回TRUE，这一行行可作为外查询的结果行，否则不能作为结果。 不建议使用 */SELECTstudent_id,student_name,age,teacher_id,( SELECT teacher_name FROM teacher WHERE teacher.teacher_id = student.teacher_id ) FROM student WHERE student.age &gt;= 12 AND EXISTS ( SELECT teacher_name FROM teacher WHERE student.teacher_id = teacher.teacher_id AND teacher.teacher_name LIKE '刘%' );-- *//*组合查询 SQL UNION 子句 （两个表没什么联系，就是要拼在一起，只要列数相同、相同数据类型，就硬拼接在后面，方便报表） 问题 我们想同时查出所有的学生编号加学生姓名，学生编号和学生姓名，再加上什么老师编号和老师姓名 SQL UNION 子句用于将两个或者更多的 SELECT 语句的运算结果组合起来。 在使用 UNION 的时候，每个 SELECT 语句必须有相同数量的选中列、相同数量的列表达式、相同的数据类型，并且它们出现的次序要一致，不过长度不一定要相同。 UNION ALL合并结果集后不去除重复记录； UNION合并结果集后去除重复记录； 合并来源于不同的表的结果集，注意合并后的结果集的title与第一个结果集保持一致。待合并的结果集的字段顺序、数据类型及字段值的含义尽量保持一致。 */-- /*demo SELECT * FROM student WHERE age = 10 UNION SELECT * FROM student WHERE class_id = 'G0101' UNION ALL SELECT * FROM student WHERE gender = '男'; SELECT student_id,student_name FROM student UNION SELECT teacher_id,teacher_name FROM teacher; SELECT student_id,student_name,age FROM student UNION SELECT teacher_id,teacher_name,gender FROM teacher;-- *//*统计函数 问题 总共有多少名学生？所有学生的成绩总和？所有学生的成绩最高分？所有学生的成绩最低分？所有学生的成绩平均分？ AVG() - 返回平均值 COUNT() - 返回行数 FIRST() - 返回第一个记录的值 LAST() - 返回最后一个记录的值 MAX() - 返回最大值 MIN() - 返回最小值 SUM() - 返回总和 abs(n) 返回n的绝对值 round(n,d) 返回n的四舍五入值，保留d位小数 rand() 返回0~1之间的随机数 pow(x,y) 返回x的y次幂 mod(m,n) 返回m除以n的余数 三角函数 实现三角运算的函数。如sin,cos,tan等 DATE_FORMAT(date,format) date 参数是合法的日期。format 规定日期/时间的输出格式，比如%Y-%m-%d %H:%i:%s*/-- /*demo SELECT COUNT(*) FROM student; SELECT SUM(score) FROM student; SELECT MAX(score) FROM student; SELECT MIN(score) FROM student; SELECT COUNT(*),SUM(score),MAX(score),MIN(score),AVG(score) FROM student; SELECT rand(); SELECT pow(2,3); SELECT pay_amount,round(pay_amount,1) FROM orderdata; SELECT od_time, date_format(od_time,'%Y-%m-%d'),co_time,date_format(co_time,'%Y-%m-%d') FROM orderdata;-- *//*分组汇总统计 GROUP BY GROUP BY语句通常与集合函数（COUNT，MAX，MIN，SUM，AVG）一起使用，以按一个或多个列对结果集进行分组。 SELECT column_name, aggregate_function(column_name) FROM table_name WHERE column_name operator value GROUP BY column_name 问题 获取每一个班级的成绩的平均分 */-- /*demo1 SELECT gender,avg(score) FROM student GROUP BY gender SELECT class_id,COUNT(*) FROM student GROUP BY class_id-- *//*demo2 问题 那么如果我们想获取教授15名以上学生的老师有哪些 SQL HAVING 子句 HAVING 子句使你能够指定过滤条件，从而控制查询结果中哪些组可以出现在最终结果里面。 过滤分组，在group by后面执行 WHERE 子句对被选择的列施加条件， 过滤行，在group by前面执行*/-- /*demo SELECT teacher_id,count(*) FROM student GROUP BY teacher_id HAVING count(*) &gt; 15;/* 问题 我们这个时候有这么一个需求，就是说我们想获取每个班级的数学的平均分的时候， 我们有两个限制条件，一个是我们不要成绩在80分以下的学生，而且我们还需要过滤掉平均分在90分以下的班级 然后我们还要以平均分从高到低来排*/ SELECT class_id,avg(score) FROM student WHERE score &gt; 80 GROUP BY class_id HAVING avg(score) &gt; 90 ORDER BY avg(score) DESC;-- *//*CASE WHEN 语句CASE WHEN 语句主要是根据是否满足语句中的判断条件会落入不同的取值，对数据进行重新分类整理和命名。CASE WHEN 语句在结尾部分必须有个 END，来提示系统整个循环语句已经结束了。*/SELECT count(DISTINCT user_id) as UV, sum(case when behavior='pv' then 1 else 0 end) as PV, sum(case when behavior='buy' then 1 else 0 end) as Buy, sum(case when behavior='cart' then 1 else 0 end) as Cart, sum(case when behavior='fav' then 1 else 0 end) as Fav, sum(case when behavior='pv' then 1 else 0 end)/count(DISTINCT user_id) as 'PV/UV'FROM userbehavior;-- 可以多次判断SELECT user_id, R, case when R BETWEEN 0 and 2 then 3 when R BETWEEN 3 and 5 then 2 else 1 end as R_ScoreFROM r_value/*连接表SQL 连接（JOIN） 子句用于将数据库中两个或者两个以上表中的记录组合起来。连接通过共有值将不同表中的字段组合在一起。内连接（INNER JOIN）：当两个表中都存在匹配时，才返回行。左连接（LEFT JOIN）：返回左表中的所有行，即使右表中没有匹配的行。右连接（RIGHT JOIN）：返回右表中的所有行，即使左表中没有匹配的行。全连接（FULL JOIN）：只要某一个表存在匹配，就返回行。Oracle数据库支持full join，mysql是不支持full join的，但仍然可以同过左外连接+ union+右外连接实现*/SELECT student_id, student_name, teacher_id, ( SELECT teacher_name FROM teacher WHERE teacher.teacher_id = student.teacher_id ) FROM student-- /*demo SELECT * from student INNER JOIN teacher ON student.teacher_id = teacher.teacher_id; SELECT * from student LEFT JOIN teacher ON student.teacher_id = teacher.teacher_id; SELECT * from student RIGHT JOIN teacher ON student.teacher_id = teacher.teacher_id; -- *//*视图 不存储数据，所以不占用物理存储 来源于表及其他视图 查，不适合增、删、改 视图是一种虚拟的表，允许用户执行以下操作： 以用户或者某些类型的用户感觉自然或者直观的方式来组织数据； 限制对数据的访问，从而使得用户仅能够看到或者修改（某些情况下）他们需要的数据； 从多个表中汇总数据，以产生报表。 创建视图:使用CREATE VIEW关键字。语法如下: CREATE VIEW 视图名 AS SELECT子句; 查询视图:与查询表一样，使用SELECT子句。 */-- /*demo1查询学生信息时，同时查询出老师姓名: CREATE VIEW v_student AS SELECT a.*,b.teacher_name FROM student a LEFT JOIN teacher b ON a.teacher_id = b.teacher_id; SELECT * FROM v_student;-- */-- /*demo2视图的嵌套:查询所有考试及格的学生信息: CREATE VIEW v_student_nesting AS SELECT * FROM v_student WHERE score &gt;= 60; SELECT * FROM v_student_nesting;-- *//*常见的使用场景场景一:仅提供需要的数据; 场景二:对特定的用户仅开放特定的数据，达到保护敏感数据的目的，提升了数据安全性; 场景三:仅筛选需要的数据场景四:简化复杂的操作场景五:重新格式化出新的字段场景六:使用计算表达式生成新的字段场景七:屏蔽底层实现逻辑及频繁的变更场景八:合并多个分离的子表*/ 常见日期和时间函数 SQL窗口函数开窗函数简介:与聚合函数一样，开窗函数也是对行集组进行聚合计算，但是它不像普通聚合函数那样每组只返回一个值，开窗函数可以为每组返回多个值，因为开窗函数所执行聚合计算的行集组是窗口。 建表： 1234567891011121314151617181920212223242526272829303132CREATE TABLE T_Person (FName VARCHAR(20),FCity VARCHAR(20),FAge INT,FSalary INT)INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Tom','BeiJing',20,3000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Tim','ChengDu',21,4000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Jim','BeiJing',22,3500);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Lily','London',21,2000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('John','NewYork',22,1000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('YaoMing','BeiJing',20,3000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Swing','London',22,2000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Guo','NewYork',20,2800);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('YuQian','BeiJing',24,8000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Ketty','London',25,8500);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Kitty','ChengDu',25,3000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Merry','BeiJing',23,3500);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Smith','ChengDu',30,3000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Bill','BeiJing',25,2000);INSERT INTO T_Person(FName,FCity,FAge,FSalary)VALUES('Jerry','NewYork',24,3300); 要计算所有人员的总数，我们可以执行下面的 SQL 语句：SELECT COUNT(*) FROM T_Person 除了这种较简单的使用方式，有时需要从不在聚合函数中的行中访问这些聚合计算的值。比如我们想查询每个工资小于 5000 元的员工信息（城市以及年龄），并且在每行中都显示所有工资小于 5000 元的员工个数： 子查询 123456select fname, fcity, fsalary, (select count(*) from t_person where fsalary &lt; 5000) as 工资少于5000员工总数 from t_personwhere fsalary &lt; 5000 虽然使用子查询能够解决这个问题，但是子查询的使用非常麻烦，使用窗口函数则可以大大简化实现，下面的 SQL 语句展示了如果使用开窗函数来实现同样的效果： 123select fname, fcity, fsalary, count(*) over() as 工资小于5000员工数 from t_personwhere fsalary &lt; 5000 可以看到与聚合函数不同的是，开窗函数在聚合函数后增加了一个 OVER 关键字。 开窗函数格式： 函数名(列) OVER(选项) OVER 关键字表示把函数当成开窗函数而不是聚合函数。SQL 标准允许将所有聚合函数用做开窗函数，使用 OVER 关键字来区分这两种用法。 开窗函数 COUNT() OVER()*对于查询结果的每一行都返回所有符合条件的行的条数**。OVER 关键字后的括号中还经常添加选项用以改变进行聚合运算的窗口范围。如果 OVER 关键字后的括号中的选项为空，则开窗函数会对结果集中的所有行进行聚合运算。 PARTITION BY 子句：开窗函数的 OVER 关键字后括号中的可以使用 PARTITION BY 子句来定义行的分区来供进行聚合计算。与 GROUP BY 子句不同，PARTITION BY 子句创建的分区是独立于结果集的，创建的分区只是供进行聚合计算的，而且不同的开窗函数所创建的分区也不互相影响。下面的 SQL 语句用于显示每一个人员的信息以及所属城市的人员数： 1select fname,fcity,fage,fsalary,count(*) over(partition by fcity) as 所在城市人数 from t_person COUNT() OVER(PARTITION BY FCITY)表示对结果集按照FCITY进行*分区**，并且计算当前行所属的组的聚合计算结果。比如对于FName等于 Tom的行，它所属的城市是BeiJing，同属于BeiJing的人员一共有6个，所以对于这一列的显示结果为6。 这就不需要先对fcity分组求和，然后再和t_person表连接查询了，省事儿。 在同一个SELECT语句中可以同时使用多个开窗函数，而且这些开窗函数并不会相互干扰。比如下面的SQL语句用于显示每一个人员的信息、所属城市的人员数以及同龄人的人数： 12345678--显示每一个人员的信息、所属城市的人员数以及同龄人的人数：select fname, fcity, fage, fsalary, count(*) over(partition by fcity) as 所属城市的人个数, count(*) over(partition by fage) as 同龄人个数 from t_person ORDER BY子句：开窗函数中可以在OVER关键字后的选项中使用ORDER BY子句来指定排序规则，而且有的开窗函数还要求必须指定排序规则。使用ORDER BY子句可以对结果集按照指定的排序规则进行排序，并且在一个指定的范围内进行聚合运算。ORDER BY子句的语法为： 1ORDER BY 字段名 RANGE|ROWS BETWEEN 边界规则1 AND 边界规则2 RANGE表示按照值的范围进行范围的定义 ROWS表示按照行的范围进行范围的定义 边界规则的可取值见下表： “RANGE|ROWS BETWEEN 边界规则1 AND 边界规则2”部分用来定位聚合计算范围，这个子句又被称为定位框架。 例子程序一：查询从第一行到当前行的工资总和： 123456select fname, fcity, fage, fsalary, sum(fsalary) over(order by fsalary rows between unbounded preceding and current row) as 到当前行工资求和 from t_person 1234这里的开窗函数“SUM(FSalary) OVER(ORDER BY FSalary ROWS BETWEENUNBOUNDED PRECEDING AND CURRENT ROW)”表示先按照FSalary进行排序，然后计算从第一行（UNBOUNDED PRECEDING）到当前行（CURRENT ROW）的和，这样的计算结果就是按照工资进行排序的工资值的累积和。 “RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW”是开窗函数中最常使用的定位框架，为了简化使用，如果使用的是这种定位框架，则可以省略定位框架声明部分，也就是说上边的sql可以简化成： 123456select fname, fcity, fage, fsalary, sum(fsalary) over(order by fsalary) as 到当前行工资求和 from t_person 例子程序二：把例子程序一的row换成了range，是按照范围进行定位的 123456select fname, fcity, fage, fsalary, sum(fsalary) over(order by fsalary range between unbounded preceding and current row) as 到当前行工资求和 from t_person 区别： 这个SQL语句与例1中的SQL语句唯一不同的就是“ROWS”被替换成了“RANGE”。 “ROWS”是按照行数进行范围定位的，而“RANGE”则是按照值范围进行定位的，这两个不同的定位方式主要用来处理并列排序的情况。 比如 Lily、Swing、Bill这三个人的工资都是2000元，如果按照“ROWS”进行范围定位，则计算从第一条到当前行的累积和，而如果 如果按照 “RANGE”进行范围定位，则仍然计算从第一条到当前行的累积和，不过由于等于2000元的工资有三个人，所以计算的累积和为从第一条到2000元工资的人员结，所以对 Lily、Swing、Bill这三个人进行开窗函数聚合计算的时候得到的都是7000（ “ 1000+2000+2000+2000 ”）。 下边这的估计不常用： 例子程序三： 1234SELECT FName, FSalary, SUM(FSalary) OVER(ORDER BY FSalary ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING) as 前二后二和 FROM T_Person; 这里的开窗函数“SUM(FSalary) OVER(ORDER BY FSalary ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING)”表示按照FSalary进行排序，然后计算从当前行前两行（2PRECEDING）到当前行后两行（2 FOLLOWING）的工资和，注意对于第一条和第二条而言它们的“前两行”是不存在或者不完整的，因此计算的时候也是要按照前两行是不存在或者不完整进行计算，同样对于最后两行数据而言它们的“后两行”也不存在或者不完整的，同样要进行类似的处理。 例子程序四： 123SELECT FName, FSalary,SUM(FSalary) OVER(ORDER BY FSalary ROWS BETWEEN 1 FOLLOWING AND 3 FOLLOWING) 后面一到三之和FROM T_Person; 这里的开窗函数“SUM(FSalary) OVER(ORDER BY FSalary ROWS BETWEEN 1 FOLLOWING AND 3 FOLLOWING)”表示按照FSalary进行排序，然后计算从当前行后一行（1 FOLLOWING）到后三行（3 FOLLOWING）的工资和。注意最后一行没有后续行，其计算结果为空值NULL而非0。 例子程序五：算工资排名 123SELECT FName, FSalary,COUNT(*) OVER(ORDER BY FSalary ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as 工资排名FROM T_Person; 这里的开窗函数“COUNT(*) OVER(ORDER BY FSalary RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)”表示按照FSalary进行排序，然后计算从第一行（UNBOUNDED PRECEDING）到当前行（CURRENT ROW）的人员的个数，这个可以看作是计算人员的工资水平排名。 不再用ROWNUM 了省事了。这个over简写就会出错。 例子程序6：结合max求到目前行的最大值 123SELECT FName, FSalary,FAge,MAX(FSalary) OVER(ORDER BY FAge) as 此行之前最大值FROM T_Person; 例子程序6：over(partition by XX order by XX) partition by和order by 结合 员工信息+同龄人最高工资，按工资排序 123SELECT FName, FSalary,FAge,MAX(FSalary) OVER(PARTITION BY FAge ORDER BY fsalary rows BETWEEN unbounded preceding and unbounded following) 同龄人最高工资FROM T_Person; 此处范围要注意，已经分区，所以是第一条到最后一条记录的max，默认到目前行为止是不行的 ROW_NUMBER();rank() ,dense_rank()排名函数除了可以在开窗函数中使用COUNT()、SUM()、MIN()、MAX()、AVG()等这些聚合函数，还可以在开窗函数中使用一些高级的函数，有些函数同时被DB2和Oracle同时支持，比如RANK()、DENSE_RANK()、ROW_NUMBER()，而有些函数只被Oracle支持，比如RATIO_TO_REPORT()、NTILE()、LEAD()、LAG()、FIRST_VALUE()、LAST_VALUE()。 用法（这三个都是排序函数）： 1.rank函数：计算排序时，如果存在相同位次的记录，则会跳过之后的位次。 2.dense_rank函数：同样是计算排序，即使存在相同位次的记录，也不会跳过之后的位次。 3.row_number函数：赋予唯一的连续位次。 RANK()和DENSE_RANK()函数都可以用于计算一行的排名，不过对于并列排名的处理方式不同； ROW_NUMBER()函数计算一行在结果集中的行号，同样可以将其当成排名函数。 这三个函数的功能存在一定的差异，举例如下：工资从高到低排名： 12345SELECT FName, FSalary,FAge,RANK() OVER(ORDER BY fsalary desc) f_RANK,DENSE_RANK() OVER(ORDER BY fsalary desc) f_DENSE_RANK,ROW_NUMBER() OVER(ORDER BY fsalary desc) f_ROW_NUMBERFROM T_Person; row_number() 函数语法： 1234ROW_NUMBER()【语法】ROW_NUMBER() OVER (PARTITION BY COL1 ORDER BY COL2) 主要功能：用于取前几名，或者最后几名等 LAG()、LEAD()LAG(col,n,DEFAULT) 用于统计窗口内往上第n行值 第一个参数为列名，第二个参数为往上第n行（可选，默认为1），第三个参数为默认值（当往上第n行为NULL时候，取默认值，如不指定，则为NULL） 例子： 1234SELECT FName,FSalary,FAge,lag(FSalary,1,6666) over(PARTITION by fage ORDER BY FSalary) AS lag1,lag(FSalary,2) over(PARTITION by fage ORDER BY FSalary) AS lag2FROM T_Person; LEAD(col,n,DEFAULT) 用于统计窗口内往下第n行值 第一个参数为列名，第二个参数为往下第n行（可选，默认为1），第三个参数为默认值（当往下第n行为NULL时候，取默认值，如不指定，则为NULL） 1234SELECT FName,FSalary,FAge,lead(FSalary,1,6666) over(PARTITION by fage ORDER BY FSalary) AS lag1,lead(FSalary,2) over(PARTITION by fage ORDER BY FSalary) AS lag2FROM T_Person; FIRST_VALUE()、LAST_VALUE()FIRST_VALUE(col)：取分组内排序后，截止到当前行，第一个值 LAST_VALUE(col)：取分组内排序后，截止到当前行，最后一个值 12345SELECT FName, FSalary,FAge,ROW_NUMBER() OVER(PARTITION by fage ORDER BY fsalary desc) rn,FIRST_value(fname) over(PARTITION by fage ORDER BY fsalary desc) fv,last_value(fname) over(PARTITION by fage ORDER BY fsalary desc) lvFROM T_Person; NTILE()ntile(n)：分为n组，返回每行的组号 1234SELECT FName, FSalary,FAge,fcity,ntile(4) over(ORDER BY fsalary desc) n1,ntile(2) over(PARTITION by fcity ORDER BY fsalary desc) n2FROM T_Person; 其他函数DATEDIFF函数：获取两个日期的时间间隔DATEDIFF(date1，date2) ： 返回起始时间 date1 和结束时间 date2 之间的天数。date1 和 date2 为日期或 date-and-time 表达式。 fnull(,)IFNULL(expression_1,expression_2) 如果expression_1不为NULL，则IFNULL函数返回expression_1; 否则返回expression_2的结果。 123select ifnull((select distinct Salaryfrom Employeeorder by Salary desc limit 1,1),null) as SecondHighestSalary; set给定义的变量赋值 set N=N-1","categories":[{"name":"SQL","slug":"SQL","permalink":"http://mangosTeeN96.github.io/categories/SQL/"}],"tags":[{"name":"数据分析","slug":"数据分析","permalink":"http://mangosTeeN96.github.io/tags/数据分析/"}]},{"title":"python数据分析算法","slug":"python数据分析算法","date":"2020-01-08T02:38:45.000Z","updated":"2020-05-28T06:03:50.932Z","comments":true,"path":"2020/01/08/python数据分析算法/","link":"","permalink":"http://mangosTeeN96.github.io/2020/01/08/python数据分析算法/","excerpt":"","text":"16.决策树在现实生活中，我们会遇到各种选择，不论是选择男女朋友，还是挑选水果，都是基于以往的经验来做判断。如果把判断背后的逻辑整理成一个结构图，会发现它实际上是一个树状图，这就是决策树。 决策树的工作原理决策树基本上就是把我们以前的经验总结出来。如果我们要出门打篮球，一般会根据“天气”、“温度”、“湿度”、“刮风”这几个条件来判断，最后得到结果：去打篮球？还是不去？ 上面这个图就是一棵典型的决策树。我们在做决策树的时候，会经历两个阶段：构造和剪枝。 构造构造就是生成一棵完整的决策树。简单来说，构造的过程就是选择什么属性作为节点的过程，那么在构造过程中，会存在三种节点： 根节点：就是树的最顶端，最开始的那个节点。在上图中，“天气”就是一个根节点； 内部节点：就是树中间的那些节点，比如说“温度”、“湿度”、“刮风”； 叶节点：就是树最底部的节点，也就是决策结果。 节点之间存在父子关系。比如根节点会有子节点，子节点会有子子节点，但是到了叶节点就停止了，叶节点不存在子节点。那么在构造过程中，你要解决三个重要的问题： 选择哪个属性作为根节点； 选择哪些属性作为子节点； 什么时候停止并得到目标状态，即叶节点。 剪枝剪枝就是给决策树瘦身，这一步想实现的目标就是，不需要太多的判断，同样可以得到不错的结果。之所以这么做，是为了防止“过拟合”（Overfitting）现象的发生。 过拟合：指的是模型的训练结果“太好了”，以至于在实际应用的过程中，会存在“死板”的情况，导致分类错误。 欠拟合：指的是模型的训练结果不理想。 造成过拟合的原因： 一是因为训练集中样本量较小。如果决策树选择的属性过多，构造出来的决策树一定能够“完美”地把训练集中的样本分类，但是这样就会把训练集中一些数据的特点当成所有数据的特点，但这个特点不一定是全部数据的特点，这就使得这个决策树在真实的数据分类中出现错误，也就是模型的“泛化能力”差。 泛化能力：指的分类器是通过训练集抽象出来的分类能力，你也可以理解是举一反三的能力。如果我们太依赖于训练集的数据，那么得到的决策树容错率就会比较低，泛化能力差。因为训练集只是全部数据的抽样，并不能体现全部数据的特点。 剪枝的方法： 预剪枝：在决策树构造时就进行剪枝。方法是，在构造的过程中对节点进行评估，如果对某个节点进行划分，在验证集中不能带来准确性的提升，那么对这个节点进行划分就没有意义，这时就会把当前节点作为叶节点，不对其进行划分。 后剪枝：在生成决策树之后再进行剪枝。通常会从决策树的叶节点开始，逐层向上对每个节点进行评估。如果剪掉这个节点子树，与保留该节点子树在分类准确性上差别不大，或者剪掉该节点子树，能在验证集中带来准确性的提升，那么就可以把该节点子树进行剪枝。方法是：用这个节点子树的叶子节点来替代该节点，类标记为这个节点子树中最频繁的那个类。 实际上决策树分类器，以及决策树回归器（对应DecisionTreeRegressor类）都没有集成剪枝步骤。一般对决策树进行缩减，常用的方法是在构造DecisionTreeClassifier类时，对参数进行设置，比如maxdepth表示树的最大深度，max_leaf_nodes表示最大的叶子节点数。通过调整这两个参数，就能对决策树进行剪枝。当然也可以自己编写剪枝程序完成剪枝。 如何构造决策树 我们该如何构造一个判断是否去打篮球的决策树呢？再回顾一下决策树的构造原理，在决策过程中有三个重要的问题：将哪个属性作为根节点？选择哪些属性作为后继节点？什么时候停止并得到目标值？ 显然将哪个属性（天气、温度、湿度、刮风）作为根节点是个关键问题，在这里我们先介绍两个指标：纯度和信息熵。 纯度：你可以把决策树的构造过程理解成为寻找纯净划分的过程。数学上，我们可以用纯度来表示，纯度换一种方式来解释就是让目标变量的分歧最小。 举个例子，假设有 3 个集合： 集合 1：6 次都去打篮球； 集合 2：4 次去打篮球，2 次不去打篮球； 集合 3：3 次去打篮球，3 次不去打篮球。 按照纯度指标来说，集合 1&gt; 集合 2&gt; 集合 3。因为集合1 的分歧最小，集合 3 的分歧最大。 信息熵：表示信息的不确定度在信息论中，随机离散事件出现的概率存在着不确定性。为了衡量这种信息的不确定性，信息学之父香农引入了信息熵的概念，并给出了计算信息熵的数学公式： p(i|t) 代表了节点 t 为分类 i 的概率，其中 log2 为取以 2 为底的对数。这里我们不是来介绍公式的，而是说存在一种度量，它能帮我们反映出来这个信息的不确定度。当不确定性越大时，它所包含的信息量也就越大，信息熵也就越高。 举个例子，假设有 2 个集合： 集合 1：5 次去打篮球，1 次不去打篮球； 集合 2：3 次去打篮球，3 次不去打篮球。 在集合 1 中，有 6 次决策，其中打篮球是 5 次，不打篮球是 1 次。那么假设：类别 1 为“打篮球”，即次数为 5；类别 2 为“不打篮球”，即次数为 1。那么节点划分为类别1的概率是 5/6，为类别2的概率是1/6，带入上述信息熵公式可以计算得出： 同样，集合 2 中，也是一共 6 次决策，其中类别 1 中“打篮球”的次数是 3，类别 2“不打篮球”的次数也是 3，那么信息熵为多少呢？我们可以计算得出： 从上面的计算结果中可以看出，信息熵越大，纯度越低。当集合中的所有样本均匀混合时，信息熵最大，纯度最低。 我们在构造决策树的时候，会基于纯度来构建。而经典的 “不纯度”的指标有三种，分别是信息增益（ID3 算法）、信息增益率（C4.5 算法）以及基尼指数（Cart 算法）。 信息增益（ID3算法）：信息增益指的就是划分可以带来纯度的提高，信息熵的下降。它的计算公式，是父亲节点的信息熵减去所有子节点的信息熵。在计算的过程中，我们会计算每个子节点的归一化信息熵，即按照每个子节点在父节点中出现的概率，来计算这些子节点的信息熵。所以信息增益的公式可以表示为： 公式中 D 是父亲节点，Di 是子节点，Gain(D,a)中的 a 作为 D 节点的属性选择。 举例： 我们基于 ID3 的算法规则，完整地计算下我们的训练集，训练集中一共有 7 条数据，3 个打篮球，4 个不打篮球，所以根节点的信息熵是： 如果你将天气作为属性的划分，会有三个叶子节点 D1、D2 和D3，分别对应的是晴天、阴天和小雨。我们用 + 代表去打篮球，- 代表不去打篮球。那么第一条记录，晴天不去打篮球，可以记为 1-，于是我们可以用下面的方式来记录 D1，D2，D3： D1(天气 = 晴天)={1-,2-,6+} D2(天气 = 阴天)={3+,7-} D3(天气 = 小雨)={4+,5-} 我们先分别计算三个叶子节点的信息熵： D1 在 D（父节点）中的概率是 3/7，D2在父节点的概率是 2/7，D3 在父节点的概率是 2/7。那么作为子节点的归一化信息熵 = 3/70.918+2/71.0=0.965。 因为我们用 ID3 中的信息增益来构造决策树，所以要计算每个节点的信息增益。 天气作为属性节点的信息增益为，Gain(D , 天气)=0.985-0.965=0.020。 同理我们可以计算出其他属性作为根节点的信息增益，它们分别为： Gain(D , 温度)=0.128 Gain(D , 湿度)=0.020 Gain(D , 刮风)=0.020 我们能看出来温度作为属性的信息增益最大。因为 ID3 就是要将信息增益最大的节点作为父节点，这样可以得到纯度高的决策树，所以我们将温度作为根节点。其决策树状图分裂为下图所示： 然后我们要将上图中第一个叶节点，也就是 D1={1-,2-,3+,4+}进一步进行分裂，往下划分，计算其不同属性（天气、湿度、刮风）作为节点的信息增益，可以得到： Gain(D , 天气)=0 Gain(D , 湿度)=0 Gain(D , 刮风)=0.0615 我们能看到刮风为 D1 的节点都可以得到最大的信息增益，这里我们选取刮风作为节点。同理，我们可以按照上面的计算步骤得到完整的决策树，结果如下： 于是我们通过 ID3 算法得到了一棵决策树。ID3 的算法规则相对简单，可解释性强。同样也存在缺陷，比如我们会发现 ID3 算法倾向于选择取值比较多的属性。这样，如果我们把“编号”作为一个属性（一般情况下不会这么做，这里只是举个例子），那么“编号”将会被选为最优属性 。但实际上“编号”是无关属性的，它对“打篮球”的分类并没有太大作用。 所以 ID3 有一个缺陷就是，有些属性可能对分类任务没有太大作用，但是他们仍然可能会被选为最优属性。这种缺陷不是每次都会发生，只是存在一定的概率。在大部分情况下，ID3 都能生成不错的决策树分类。针对可能发生的缺陷，后人提出了新的算法进行改进。 在 ID3 算法上进行改进的 C4.5 算法 采用信息增益率 因为 ID3 在计算的时候，倾向于选择取值多的属性。为了避免这个问题，C4.5 采用信息增益率的方式来选择属性。信息增益率 = 信息增益 / 属性熵 当属性有很多值的时候，相当于被划分成了许多份，虽然信息增益变大了，但是对于 C4.5 来说，属性熵也会变大，所以整体的信息增益率并不大。 采用悲观剪枝 ID3 构造决策树的时候，容易产生过拟合的情况。在 C4.5中，会在决策树构造之后采用悲观剪枝（PEP），这样可以提升决策树的泛化能力。 悲观剪枝是后剪枝技术中的一种，通过递归估算每个内部节点的分类错误率，比较剪枝前后这个节点的分类错误率来决定是否对其进行剪枝。这种剪枝方法不再需要一个单独的测试数据集。 离散化处理连续属性 C4.5 可以处理连续属性的情况，对连续的属性进行离散化的处理。比如打篮球存在的“湿度”属性，不按照“高、中”划分，而是按照湿度值进行计算，那么湿度取什么值都有可能。该怎么选择这个阈值呢，C4.5 选择具有最高信息增益的划分所对应的阈值。 处理缺失值 针对数据集不完整的情况，C4.5 也可以进行处理。 假如我们得到的是如下的数据，你会发现这个数据中存在两点问题。第一个问题是，数据集中存在数值缺失的情况，如何进行属性选择？第二个问题是，假设已经做了属性划分，但是样本在这个属性上有缺失值，该如何对样本进行划分？ 我们不考虑缺失的数值，可以得到温度 D={2-,3+,4+,5-,6+,7-}。温度 = 高：D1={2-,3+,4+}；温度 = 中：D2={6+,7-}；温度 = 低：D3={5-} 。这里 + 号代表打篮球，- 号代表不打篮球。比如ID=2 时，决策是不打篮球，我们可以记录为 2-。 所以三个叶节点的信息熵可以结算为： 这三个节点的归一化信息熵为 3/60.918+2/61.0+1/6*0=0.792。 针对将属性选择为温度的信息增益率为： Gain(D′, 温度)=Ent(D′)-0.792=1.0-0.792=0.208 D′的样本个数为 6，而 D 的样本个数为 7，所以所占权重比例为 6/7，所以 Gain(D′，温度) 所占权重比例为6/7，所以： Gain(D, 温度)=6/7*0.208=0.178 这样即使在温度属性的数值有缺失的情况下，我们依然可以计算信息增益，并对属性进行选择。 小结： 首先 ID3 算法的优点是方法简单，缺点是对噪声敏感。训练数据如果有少量错误，可能会产生决策树分类错误。C4.5 在 IID3 的基础上，用信息增益率代替了信息增益，解决了噪声敏感的问题，并且可以对构造树进行剪枝、处理连续数值以及数值缺失等情况，但是由于 C4.5 需要对数据集进行多次扫描，算法效率相对较低。 CART算法D3 和 C4.5 算法可以生成二叉树或多叉树，而 CART 只支持二叉树。同时 CART 决策树比较特殊，既可以作分类树，又可以作回归树。 那么你首先需要了解的是，什么是分类树，什么是回归树呢？ 我用下面的训练数据举个例子，你能看到不同职业的人，他们的年龄不同，学习时间也不同。如果我构造了一棵决策树，想要基于数据判断这个人的职业身份，这个就属于分类树，因为是从几个分类中来做选择。如果是给定了数据，想要预测这个人的年龄，那就属于回归树。 分类树可以处理离散数据，也就是数据种类有限的数据，它输出的是样本的类别。 回归树可以对连续型的数值进行预测，也就是数据在某个区间内都有取值的可能，它输出的是一个数值。 CART 分类树的工作流程通过上一讲，我们知道决策树的核心就是寻找纯净的划分，因此引入了纯度的概念。 在属性选择上，我们是通过统计“不纯度”来做判断的，ID3 是基于信息增益做判断，C4.5 在 ID3 的基础上做了改进，提出了信息增益率的概念。实际上 CART 分类树与 C4.5 算法类似，只是属性选择的指标采用的是基尼系数。 你可能在经济学中听过说基尼系数，它是用来衡量一个国家收入差距的常用指标。当基尼系数大于 0.4 的时候，说明财富差异悬殊。基尼系数在 0.2-0.4 之间说明分配合理，财富差距不大。 基尼系数本身反应了样本的不确定度。当基尼系数越小的时候，说明样本之间的差异性小，不确定程度低。分类的过程本身是一个不确定度降低的过程，即纯度的提升过程。 所以 CART 算法在构造分类树的时候，会选择基尼系数最小的属性作为属性的划分。 假设 t 为节点，那么该节点的 GINI 系数的计算公式为： 这里 p(Ck|t) 表示节点 t 属于类别 Ck 的概率，节点 t 的基尼系数为 1 减去各类别 Ck 概率平方和。 通过下面这个例子，我们计算一下两个集合的基尼系数分别为多少： 集合 1：6 个都去打篮球； 集合 2：3 个去打篮球，3 个不去打篮球。 针对集合 1，所有人都去打篮球，所以 p(Ck|t)=1，因此 GINI(t)=1-1=0。 针对集合 2，有一半人去打篮球，而另一半不去打篮球，所以，p(C1|t)=0.5，p(C2|t)=0.5，GINI(t)=1-（0.50.5+0.50.5）=0.5。 通过两个基尼系数你可以看出，集合 1 的基尼系数最小，也证明样本最稳定，而集合 2 的样本不稳定性更大。 在 CART 算法中，基于基尼系数对特征属性进行二元分裂，假设属性 A 将节点 D 划分成了 D1 和 D2，如下图所示： 节点 D 的基尼系数等于子节点 D1 和 D2 的归一化基尼系数之和，用公式表示为： 归一化基尼系数代表的是每个子节点的基尼系数乘以该节点占整体父亲节点 D 中的比例。 上面我们已经计算了集合 D1 和集合 D2 的 GINI 系数，得到： 所以节点 D 的基尼系数为： 节点 D 被属性 A 划分后的基尼系数越大，样本集合的不确定性越大，也就是不纯度越高。 如何使用 CART 算法来创建分类树在 Python 的 sklearn 中，如果我们想要创建CART 分类树，可以直接使用 DecisionTreeClassifier 这个类。创建这个类的时候，默认情况下 criterion 这个参数等于 gini，也就是按照基尼系数来选择属性划分，即默认采用的是 CART 分类树。 12345678910111213141516171819202122232425262728# encoding=utf-8from sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_scorefrom sklearn.tree import DecisionTreeClassifierfrom sklearn.datasets import load_iris# 准备数据集iris = load_iris()# 获取特征集和分类标识features = iris.datalabels = iris.target# 随机抽取 33% 的数据作为测试集，其余为训练集train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.33, random_state = 0)# 创建 CART 分类树clf = DecisionTreeClassifier(criterion = 'gini')# 拟合构造 CART 分类树clf = clf.fit(train_features, train_labels)# 用 CART 分类树做预测test_predict = clf.predict(test_features)# 预测结果与测试集结果作比对score = accuracy_score(test_labels, test_predict)print(\"CART 分类树准确率 %.4lf\" %score) 12# 运行结果：CART 分类树准确率 0.9600 如果把决策树画出来得到结果： 首先train_test split可以帮助我们把数据集抽取一部分作为测试集，这样我们就可以得到训练集和测试集。 使用clf=DecisionTreeClassifier(criterion=‘gini’)初始化一棵CART分类树。这样你就可以对CART分类树进行训练。 使用clf.fit(train_features, train_labels)函数，将训练集的特征值和分类标识作为参数进行拟合 到CART分类树。 使用clf.predict(test_features)函数进行预测，传入测试集的特征值，可以得到测试结！ _predict, 最后使用accuracy_score(test labels，test_predict)函数，传入测试集的预 结果与实际的结果作为参数，得到准确率score. 我们能看到sklearn帮我们做了CART分类树的使用封装，使用起来还是很方便的。 CART 回归树的工作流程CART 回归树划分数据集的过程和分类树的过程是一样的，只是回归树得到的预测结果是连续值，而且评判“不纯度”的指标不同。 在 CART 分类树中采用的是基尼系数作为标准，在 CART 回归树中，要根据样本的混乱程度，也就是样本的离散程度来评价“不纯度”。 样本的离散程度具体的计算方式是，先计算所有样本的均值，然后计算每个样本值到均值的差值。我们假设 x 为样本的个体，均值为u。为了统计样本的离散程度，我们可以取差值的绝对值，或者方差。 其中差值的绝对值为样本值减去样本均值的绝对值： 方差为每个样本值减去样本均值的平方和除以样本个数： 所以这两种节点划分的标准，分别对应着两种目标函数最优化的标准，即用最小绝对偏差（LAD），或者使用最小二乘偏差（LSD）。这两种方式都可以让我们找到节点划分的方法，通常使用最小二乘偏差的情况更常见一些。 如何使用 CART 回归树做预测这里我们使用到 sklearn 自带的波士顿房价数据集，该数据集给出了影响房价的一些指标，比如犯罪率，房产税等，最后给出了房价。 12345678910111213141516171819202122232425262728293031# encoding=utf-8from sklearn.model_selection import train_test_splitfrom sklearn.datasets import load_bostonfrom sklearn.metrics import mean_absolute_error,mean_squared_errorfrom sklearn.tree import DecisionTreeRegressor# 准备数据集boston = load_boston()# 探索数据print(boston.feature_names)# 获取特征集和房价features = boston.dataprices = boston.target# 随机抽取 33% 的数据作为测试集，其余为训练集train_features, test_features, train_price, test_price = train_test_split(features, prices, test_size=0.33)# 创建 CART 回归树dtr = DecisionTreeRegressor()# 拟合构造 CART 回归树dtr.fit(train_features, train_price)# 预测测试集中的房价predict_price = dtr.predict(test_features)# 测试集的结果评价print('回归树二乘偏差均值:', mean_squared_error(test_price, predict_price))print('回归树绝对值偏差均值:', mean_absolute_error(test_price, predict_price)) 12345# 运行结果（每次运行结果可能会有不同）：[&apos;CRIM&apos; &apos;ZN&apos; &apos;INDUS&apos; &apos;CHAS&apos; &apos;NOX&apos; &apos;RM&apos; &apos;AGE&apos; &apos;DIS&apos; &apos;RAD&apos; &apos;TAX&apos; &apos;PTRATIO&apos; &apos;B&apos; &apos;LSTAT&apos;]回归树二乘偏差均值: 22.308083832335328回归树绝对值偏差均值: 3.3934131736526947 回归树画出来： 首先加载了波士顿房价数据集，得到特征集和房价。然后通过train_test_split帮助我们把数据集抽取 部分作为测试集，其余作为训练集。 使用dtr=DecisionTreeRegressor()初始化一棵CART回归树。 使用dtr.fit(train_features,train_price)函数，将训练集的特征值和结果作为参数进行拟合，得到CART回归树。 使用dtr.predict(test_features)函数进行预测，传入测试集的特征值，可以得到预测结果predict_price。 最后我们可以求得这棵回归树的二乘偏差均值，以及绝对值偏差均值。 我们能看到CART回归树的使用和分类树类似，只是最后求得的预测值是个连续值。 CART 决策树的剪枝CART 决策树的剪枝主要采用的是 CCP 方法，它是一种后剪枝的方法，英文全称叫做 cost-complexity prune，中文叫做代价复杂度。这种剪枝方式用到一个指标叫做节点的表面误差率增益值，以此作为剪枝前后误差的定义。用公式表示则是： 其中 Tt 代表以 t 为根节点的子树，C(Tt) 表示节点t 的子树没被裁剪时子树 Tt 的误差，C(t) 表示节点t 的子树被剪枝后节点 t 的误差，|Tt|代子树 Tt的叶子数，剪枝后，T 的叶子数减少了|Tt|-1。 所以节点的表面误差率增益值等于节点 t 的子树被剪枝后的误差变化除以剪掉的叶子数量。 因为我们希望剪枝前后误差最小，所以我们要寻找的就是最小α值对应的节点，把它剪掉。这时候生成了第一个子树。重复上面的过程，继续剪枝，直到最后只剩下根节点，即为最后一个子树。 得到了剪枝后的子树集合后，我们需要用验证集对所有子树的误差计算一遍。可以通过计算每个子树的基尼指数或者平方误差，取误差最小的那个树，得到我们想要的结果。 总结：CART 决策树，它是一棵决策二叉树，既可以做分类树，也可以做回归树。你需要记住的是，作为分类树，CART 采用基尼系数作为节点划分的依据，得到的是离散的结果，也就是分类结果；作为回归树，CART 可以采用最小绝对偏差（LAD），或者最小二乘偏差（LSD）作为节点划分的依据，得到的是连续值，即回归预测结果。 三种决策树之间在属性选择标准上的差异： ID3 算法，基于信息增益做判断； C4.5 算法，基于信息增益率做判断； CART 算法，分类树是基于基尼系数做判断。回归树是基于偏差做判断。 在工具使用上，我们可以使用 sklearn 中的 DecisionTreeClassifier 创建 CART 分类树，通过 DecisionTreeRegressor 创建 CART 回归树。 ※ 决策树之泰坦尼克号生存预测决策树分类的应用场景非常广泛，在各行各业都有应用，比如在金融行业可以用决策树做贷款风险评估，医疗行业可以用决策树生成辅助诊断，电商行业可以用决策树对销售额进行预测等。 基于决策树还诞生了很多数据挖掘算法，比如随机森林（Random forest）。 sklearn 中的决策树模型到目前为止，sklearn 中只实现了 ID3 与 CART决策树，所以我们暂时只能使用这两种决策树，在构造 DecisionTreeClassifier 类时，其中有一个参数是criterion，意为标准。它决定了构造的分类树是采用 ID3 分类树，还是 CART 分类树，对应的取值分别是 entropy 或者 gini： entropy: 基于信息熵，也就是 ID3 算法，实际结果与 C4.5 相差不大； gini：默认参数，基于基尼系数。CART 算法是基于基尼系数做属性划分的，所以 criterion=gini 时，实际上执行的是 CART 算法。 我们通过设置 criterion=’entropy’可以创建一个 ID3 决策树分类器，然后打印下 clf，看下决策树在sklearn 中是个什么东西？ 1`DecisionTreeClassifier(class_weight``=``None``, criterion``=``'entropy'``, max_depth``=``None``,`` ``max_features``=``None``, max_leaf_nodes``=``None``,`` ``min_impurity_decrease``=``0.0``, min_impurity_split``=``None``,`` ``min_samples_leaf``=``1``, min_samples_split``=``2``,`` ``min_weight_fraction_leaf``=``0.0``, presort``=``False``, random_state``=``None``,`` ``splitter``=``'best'``)` 这里我们看到了很多参数，除了设置 criterion 采用不同的决策树算法外，一般建议使用默认的参数，默认参数不会限制决策树的最大深度，不限制叶子节点数，认为所有分类的权重都相等等。当然你也可以调整这些参数，来创建不同的决策树模型。 在构造决策树分类器后，我们可以使用 fit 方法让分类器进行拟合，使用 predict 方法对新数据进行预测，得到预测的分类结果，也可以使用 score 方法得到分类器的准确率。 Titanic 乘客生存预测数据集：https://github.com/cystanford/Titanic_Data 其中数据集格式为 csv，一共有两个文件： train.csv 是训练数据集，包含特征信息和存活与否的标签； test.csv: 测试数据集，只包含特征信息。 现在我们需要用决策树分类对训练集进行训练，针对测试集中的乘客进行生存预测，并告知分类器的准确率。 在训练集中，包括了以下字段，它们具体为： 生存预测的关键流程我们要对训练集中乘客的生存进行预测，这个过程可以划分为两个重要的阶段： 准备阶段：我们首先需要对训练集、测试集的数据进行探索，分析数据质量，并对数据进行清洗，然后通过特征选择对数据进行降维，方便后续分类运算； 分类阶段：首先通过训练集的特征矩阵、分类结果得到决策树分类器，然后将分类器应用于测试集。然后我们对决策树分类器的准确性进行分析，并对决策树模型进行可视化。 模块 1：数据探索 使用 info() 了解数据表的基本情况：行数、列数、每列的数据类型、数据完整度； 使用 describe() 了解数据表的统计情况：总数、平均值、标准差、最小值、最大值等； 使用 describe(include=[‘O’]) 查看字符串类型（非数字）的整体情况； 使用 head 查看前几行数据（默认是前 5 行）； 使用 tail 查看后几行数据（默认是最后 5 行）。 1`import` `pandas as pd``# 数据加载``train_data ``=` `pd.read_csv(``'./Titanic_Data/train.csv'``)``test_data ``=` `pd.read_csv(``'./Titanic_Data/test.csv'``)``# 数据探索``print``(train_data.info())``print``(``'-'``*``30``)``print``(train_data.describe())``print``(``'-'``*``30``)``print``(train_data.describe(include``=``[``'O'``]))``print``(``'-'``*``30``)``print``(train_data.head())``print``(``'-'``*``30``)``print``(train_data.tail())` 模块 2：数据清洗通过数据探索，我们发现 Age、Fare、Cabin、Embarked 这几个字段的数据有所缺失。其中 Age 为年龄字段，是数值型，我们可以通过平均值进行补齐。Fare票价一样（注意，不仅要看训练数据，也要看测试数据缺失） 1`# 使用平均年龄来填充年龄中的 nan 值``train_data[``'Age'``].fillna(train_data[``'Age'``].mean(), inplace``=``True``)``test_data[``'Age'``].fillna(test_data[``'Age'``].mean(),inplace``=``True``)``# 使用票价的均值填充票价中的 nan 值``train_data[``'Fare'``].fillna(train_data[``'Fare'``].mean(), inplace``=``True``)``test_data[``'Fare'``].fillna(test_data[``'Fare'``].mean(),inplace``=``True``)` Cabin 为船舱，有大量的缺失值。在训练集和测试集中的缺失率分别为 77% 和 78%，无法补齐；Embarked 为登陆港口，有少量的缺失值，我们可以把缺失值补齐。 1`print``(train_data[``'Embarked'``].value_counts())` `# 运行结果：``S ``644``C ``168``Q ``77` 我们发现一共就 3 个登陆港口，其中 S 港口人数最多，占到了 72%，因此我们将其余缺失的 Embarked 数值均设置为 S： 1`# 使用登录最多的港口来填充登录港口的 nan 值``train_data[``'Embarked'``].fillna(``'S'``, inplace``=``True``)``test_data[``'Embarked'``].fillna(``'S'``,inplace``=``True``)` 模块 3：特征选择特征选择是分类器的关键。特征选择不同，得到的分类器也不同。通过数据探索我们发现： PassengerId 为乘客编号，对分类没有作用，可以放弃；Name 为乘客姓名，对分类没有作用，可以放弃；Cabin 字段缺失值太多，可以放弃；Ticke字段为船票号码，杂乱无章且无规律，可以放弃。 其余的字段包括：Pclass、Sex、Age、SibSp、Parch 和 Fare，这些属性分别表示了乘客的船票等级、性别、年龄、亲戚数量以及船票价格，可能会和乘客的生存预测分类有关系。具体是什什么关系，我们可以交给分类器来处理。 因此我们先将 Pclass、Sex、Age 等这些其余的字段作特征，放到特征向量 features 里。 1`# 特征选择``features ``=` `[``'Pclass'``, ``'Sex'``, ``'Age'``, ``'SibSp'``, ``'Parch'``, ``'Fare'``, ``'Embarked'``]``train_features ``=` `train_data[features]``train_labels ``=` `train_data[``'Survived'``]``test_features ``=` `test_data[features]` 特征值里有一些是字符串，这样不方便后续的运算，需要转成数值类型，比如 Sex 字段，有 male 和 female 两种取值。我们可以把它变成 Sex=male 和 Sex=female 两个字段，数值用 0 或 1 来表示。 同理 Embarked 有 S、C、Q 三种可能，我们也可以改成 Embarked=S、Embarked=C 和 Embarked=Q 三个字段，数值用 0 或 1 来表示。 那该如何操作呢，我们可以使用 sklearn 特征选择中的 DictVectorizer 类，用它将可以处理符号化的对象，将符号转成数字 0/1 进行表示。具体方法如下： 1`from` `sklearn.feature_extraction ``import` `DictVectorizer``dvec``=``DictVectorizer(sparse``=``False``)``train_features``=``dvec.fit_transform(train_features.to_dict(orient``=``'record'``))` 你会看到代码中使用了 fit_transform 这个函数，它可以将特征向量转化为特征值矩阵。然后我们看下 dvec 在转化后的特征属性是怎样的，即查看 dvec 的 feature_names_ 属性值，方法如下： 1`print``(dvec.feature_names_)` `# 运行结果``[``'Age'``, ``'Embarked=C'``, ``'Embarked=Q'``, ``'Embarked=S'``, ``'Fare'``, ``'Parch'``, ``'Pclass'``, ``'Sex=female'``, ``'Sex=male'``, ``'SibSp'``]` 这样 train_features 特征矩阵就包括 10 个特征值（列），以及 891 个样本（行），即 891 行，10 列的特征矩阵。 模块 4：决策树模型1`from` `sklearn.tree ``import` `DecisionTreeClassifier``# 构造 ID3 决策树``clf ``=` `DecisionTreeClassifier(criterion``=``'entropy'``)``# 决策树训练``clf.fit(train_features, train_labels)` 模块 5：模型预测 &amp; 评估在预测中，我们首先需要得到测试集的特征值矩阵，然后使用训练好的决策树 clf 进行预测，得到预测结果 pred_labes： 1`test_features``=``dvec.transform(test_features.to_dict(orient``=``'record'``))``# 决策树预测``pred_labels ``=` `clf.predict(test_features)` 在模型评估中，决策树提供了 score 函数可以直接得到准确率，但是我们并不知道真实的预测结果，所以无法用预测值和真实的预测结果做比较（test_labels, test_predict）。 我们只能使用训练集中的数据进行模型评估（不是比较了），可以使用决策树自带的 score 函数计算下得到的结果： 1`# 得到决策树准确率``acc_decision_tree ``=` `round``(clf.score(train_features, train_labels), ``6``)``print``(u``'score 准确率为 %.4lf'` `%` `acc_decision_tree)` `# 运行结果：``score 准确率为 ``0.9820` 注：我在构造特征向量时使用了 DictVectorizer 类，使用 fit_transform 函数将特征向量转化为特征值矩阵。DictVectorizer 类同时也提供 transform 函数，这两个函数区别： fit:从一个训练集中学习模型参数，其中就包括了归一化时用到的均值，标准偏差等，可以理解为一个训练过程。transform: 在fit的基础上，对数据进行标准化，降维，归一化等数据转换操作fit_transform: 将模型训练和转化合并到一起，训练样本先做fit，得到mean，standard deviation，然后将这些参数用于transform（归一化训练数据），使得到的训练数据是归一化的，而测试数据只需要在原先fit得到的mean，std上来做归一化就行了，所以用transform就行了。 你会发现你刚用训练集做训练，再用训练集自身做准确率评估自然会很高。但这样得出的准确率并不能代表决策树分类器的准确率。 那么有什么办法，来统计决策树分类器的准确率呢？ 这里可以使用 K 折交叉验证的方式，交叉验证是一种常用的验证分类准确率的方法，原理是拿出大部分样本进行训练，少量的用于分类器的验证。K 折交叉验证，就是做 K 次交叉验证，每次选取K 分之一的数据作为验证，其余作为训练。轮流 K 次，取平均值。 K 折交叉验证的原理是这样的： 将数据集平均分割成 K 个等份； 使用 1 份数据作为测试数据，其余作为训练数据； 计算测试准确率； 使用不同的测试集，重复 2、3 步骤。 在 sklearn 的 model_selection 模型选择中提供了 cross_val_score 函数。cross_val_score 函数中的参数 cv 代表对原始数据划分成多少份，也就是我们的 K 值，一般建议 K 值取 10，因此我们可以设置 CV=10，我们可以对比下 score和 cross_val_score 两种函数的正确率的评估结果： 1`import` `numpy as np``from` `sklearn.model_selection ``import` `cross_val_score``# 使用 K 折交叉验证 统计决策树准确率``print``(u``'cross_val_score 准确率为 %.4lf'` `%` `np.mean(cross_val_score(clf, train_features, train_labels, cv``=``10``)))` `# 运行结果：``cross_val_score 准确率为 ``0.7835` 模块 6：决策树可视化Graphviz 可视化工具 完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import pandas as pdfrom sklearn.feature_extraction import DictVectorizerfrom sklearn.tree import DecisionTreeClassifierimport numpy as npfrom sklearn.model_selection import cross_val_score# 数据加载train_data = pd.read_csv('./Titanic_Data-master/train.csv')test_data = pd.read_csv('./Titanic_Data-master/test.csv')# 数据探索print(train_data.info())print(train_data.describe())print(train_data.describe(include=['O']))print(train_data.head())print(train_data.tail())# 数据清洗# 使用平均年龄来填充年龄中的Nan值train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)test_data['Age'].fillna(test_data['Age'].mean(),inplace=True)# 使用票价的均值填充票价中的Nan值train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)test_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)# 使用登录最多的港口来填充登录港口的nan值# print(train_data['Embarked'].value_counts())train_data['Embarked'].fillna('S', inplace=True)test_data['Embarked'].fillna('S',inplace=True)# 特征选择features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']train_features = train_data[features]train_labels = train_data['Survived']test_features = test_data[features]dvec = DictVectorizer(sparse=False)train_features = dvec.fit_transform(train_features.to_dict(orient='record'))# 构造ID3决策树clf = DecisionTreeClassifier(criterion='entropy')# 决策树训练clf.fit(train_features, train_labels)# # 模型预测 &amp; 评估# test_features=dvec.transform(test_features.to_dict(orient='record'))# # 决策树预测# pred_labels = clf.predict(test_features)# 得到决策树准确率acc_decision_tree = round(clf.score(train_features, train_labels), 6)print(u'score准确率为 %.4lf' % acc_decision_tree)# 使用K折交叉验证 统计决策树准确率print(u'cross_val_score准确率为 %.4lf' % np.mean(cross_val_score(clf, train_features, train_labels, cv=10))) 决策树模型使用技巧总结今天用泰坦尼克乘客生存预测案例把决策树模型的流程跑了一遍。在实战中，你需要注意一下几点： 特征选择是分类模型好坏的关键。选择什么样的特征，以及对应的特征值矩阵，决定了分类模型的好坏。通常情况下，特征值不都是数值类型，可以使用 DictVectorizer 类进行转化； 模型准确率需要考虑是否有测试集的实际结果可以做对比，当测试集没有真实结果可以对比时，需要使用 K 折交叉验证 cross_val_score； Graphviz 可视化工具可以很方便地将决策模型呈现出来，帮助你更好理解决策树的构建。 17.朴素贝叶斯分类贝叶斯原理跟我们的生活联系非常紧密。举个例子，如果你看到一个人总是花钱，那么会推断这个人多半是个有钱人。当然这也不是绝对，也就是说，当你不能准确预知一个事物本质的时候，你可以依靠和事物本质相关的事件来进行判断，如果事情发生的频次多，则证明这个属性更有可能存在。 贝叶斯原理贝叶斯原理是怎么来的呢？贝叶斯为了解决一个叫“逆向概率”问题写了一篇文章，尝试解答在没有太多可靠证据的情况下，怎样做出更符合数学逻辑的推测。 逆向概率 所谓“逆向概率”是相对“正向概率”而言。正向概率的问题很容易理解，比如我们已经知道袋子里面有 N 个球，不是黑球就是白球，其中 M 个是黑球，那么把手伸进去摸一个球，就能知道摸出黑球的概率是多少。但这种情况往往是上帝视角，即了解了事情的全貌再做判断。 在现实生活中，我们很难知道事情的全貌。贝叶斯则从实际场景出发，提了一个问题：如果我们事先不知道袋子里面黑球和白球的比例，而是通过我们摸出来的球的颜色，能判断出袋子里面黑白球的比例么？ 正是这样的一个问题，影响了接下来近 200 年的统计学理论。这是因为，贝叶斯原理与其他统计学推断方法截然不同，它是建立在主观判断的基础上：在我们不了解所有客观事实的情况下，同样可以先估计一个值，然后根据实际结果不断进行修正。 我们用一个题目来体会下：假设有一种病叫做“贝叶死”，它的发病率是万分之一，即 10000 人中会有 1 个人得病。现有一种测试可以检验一个人是否得病的准确率是 99.9%，它的误报率是 0.1%，那么现在的问题是，如果一个人被查出来患有“叶贝死”，实际上患有的可能性有多大？ 你可能会想说，既然查出患有“贝叶死”的准确率是 99.9%，那是不是实际上患“贝叶死”的概率也是 99.9% 呢？实际上不是的。你自己想想，在 10000 个人中，还存在 0.1% 的误查的情况，也就是 10 个人没有患病但是被诊断成阳性。当然 10000 个人中，也确实存在一个患有贝叶死的人，他有 99.9% 的概率被检查出来。所以你可以粗算下，患病的这个人实际上是这 11 个人里面的一员，即实际患病比例是 1/11≈9%。 上面这个例子中，实际上涉及到了贝叶斯原理中的几个概念： 先验概率 通过经验来判断事情发生的概率，比如说“贝叶死”的发病率是万分之一，就是先验概率。再比如南方的梅雨季是 6-7 月，就是通过往年的气候总结出来的经验，这个时候下雨的概率就比其他时间高出很多。 后验概率 后验概率就是发生结果之后，推测原因的概率。比如说某人查出来了患有“贝叶死”，那么患病的原因可能是 A、B 或 C。患有“贝叶死”是因为原因 A 的概率就是后验概率。它是属于条件概率的一种。 条件概率 事件 A 在另外一个事件 B 已经发生条件下的发生概率，表示为 P(A|B)，读作“在 B 发生的条件下 A 发生的概率”。比如原因 A 的条件下，患有“贝叶死”的概率，就是条件概率。 似然函数（likelihood function） 你可以把概率模型的训练过程理解为求参数估计的过程。举个例子，如果一个硬币在 10 次抛落中正面均朝上。那么你肯定在想，这个硬币是均匀的可能性是多少？这里硬币均匀就是个参数，似然函数就是用来衡量这个模型的参数。似然在这里就是可能性的意思，它是关于统计参数的函数。 介绍完贝叶斯原理中的这几个概念，我们再来看下贝叶斯原理，实际上贝叶斯原理就是求解后验概率，我们假设：A 表示事件 “测出为阳性”, 用 B1 表示“患有贝叶死”, B2 表示“没有患贝叶死”。根据上面那道题，我们可以得到下面的信息。 患有贝叶死的情况下，测出为阳性的概率为 P(A|B1)=99.9%，没有患贝叶死，但测出为阳性的概率为 P(A|B2)=0.1%。另外患有贝叶死的概率为 P(B1)=0.01%，没有患贝叶死的概率 P(B2)=99.99%。 那么我们检测出来为阳性，而且是贝叶死的概率 P(B1A）=P(B1)P(A|B1)=0.01%99.9%=0.00999%。 这里 P(B1A) 代表的是联合概率，同样我们可以求得 P(B2A)=P(B2)P(A|B2)=99.99%0.1%=0.09999%。 然后我们想求得是检查为阳性的情况下，患有贝叶死的概率，也即是 P(B1|A)。 所以检查出阳性，且患有贝叶死的概率为： 检查出是阳性，但没有患有贝叶死的概率为： 这里我们能看出来 0.01%+0.1% 均出现在了 P(B1|A) 和 P(B2|A) 的计算中作为分母。我们把它称之为论据因子，也相当于一个权值因子。 其中 P(B1）、P(B2) 就是先验概率，我们现在知道了观测值，就是被检测出来是阳性，来求患贝叶死的概率，也就是求后验概率。求后验概率就是贝叶斯原理要求的，基于刚才求得的 P(B1|A)，P(B2|A)，我们可以总结出贝叶斯公式为： 由此，我们可以得出通用的贝叶斯公式： 朴素贝叶斯朴素贝叶斯，是一种简单但极为强大的预测建模算法 。之所以称为朴素贝叶斯，是因为它假设每个输入变量是独立的。这是一个强硬的假设，实际情况并不一定，但是这项技术对于绝大部分的复杂问题仍然非常有效。 朴素贝叶斯模型由两种类型的概率组成： 每个类别的概率 P(Cj) 每个属性的条件概率 P(Ai|Cj) 举个例子说明下什么是类别概率和条件概率。假设我有 7 个棋子，其中 3 个是白色的，4 个是黑色的。那么棋子是白色的概率就是 3/7，黑色的概率就是 4/7，这个就是类别概率。 假设我把这 7 个棋子放到了两个盒子里，其中盒子 A 里面有 2 个白棋，2 个黑棋；盒子 B 里面有 1 个白棋，2 个黑棋。那么在盒子 A 中抓到白棋的概率就是 1/2，抓到黑棋的概率也是 1/2，这个就是条件概率，也就是在某个条件（比如在盒子 A 中）下的概率。 在朴素贝叶斯中，我们要统计的是属性的条件概率，也就是假设取出来的是白色的棋子，那么它属于盒子 A 的概率是 2/3。 为了训练朴素贝叶斯模型，我们需要先给出训练数据，以及这些数据对应的分类。那么上面这两个概率，也就是类别概率和条件概率。他们都可以从给出的训练数据中计算出来。一旦计算出来，概率模型就可以使用贝叶斯原理对新数据进行预测。 另外，贝叶斯原理、贝叶斯分类和朴素贝叶斯这三者之间是有区别的。 贝叶斯原理是最大的概念，它解决了概率论中“逆向概率”的问题，在这个理论基础上，人们设计出了贝叶斯分类器，朴素贝叶斯分类是贝叶斯分类器中的一种，也是最简单，最常用的分类器。朴素贝叶斯之所以朴素是因为它假设属性是相互独立的，因此对实际情况有所约束，如果属性之间存在关联，分类准确率会降低。不过好在对于大部分情况下，朴素贝叶斯的分类效果都不错。 朴素贝叶斯分类工作原理朴素贝叶斯分类是常用的贝叶斯分类方法。我们日常生活中看到一个陌生人，要做的第一件事情就是判断 TA 的性别，判断性别的过程就是一个分类的过程。根据以往的经验，我们通常会从身高、体重、鞋码、头发长短、服饰、声音等角度进行判断。这里的“经验”就是一个训练好的关于性别判断的模型，其训练数据是日常中遇到的各式各样的人，以及这些人实际的性别数据。 离散数据案例我们遇到的数据可以分为两种，一种是离散数据，另一种是连续数据。 我以下面的数据为例，这些是根据你之前的经验所获得的数据。然后给你一个新的数据：身高“高”、体重“中”，鞋码“中”，请问这个人是男还是女？ 针对这个问题，我们先确定一共有 3 个属性，假设我们用 A 代表属性，用 A1, A2, A3 分别为身高 = 高、体重 = 中、鞋码 = 中。一共有两个类别，假设用 C 代表类别，那么 C1,C2 分别是：男、女，在未知的情况下我们用 Cj 表示。 那么我们想求在 A1、A2、A3 属性下，Cj 的概率，用条件概率表示就是 P(Cj|A1A2A3)。根据上面讲的贝叶斯的公式，我们可以得出： 因为一共有 2 个类别，所以我们只需要求得 P(C1|A1A2A3) 和 P(C2|A1A2A3) 的概率即可，然后比较下哪个分类的可能性大，就是哪个分类结果。 在这个公式里，因为 P(A1A2A3) 都是固定的，我们想要寻找使得 P(Cj|A1A2A3) 的最大值，就等价于求 P(A1A2A3|Cj)P(Cj) 最大值。 我们假定 Ai 之间是相互独立的，那么： P(A1A2A3|Cj)=P(A1|Cj)P(A2|Cj)P(A3|Cj) 然后我们需要从 Ai 和 Cj 中计算出 P(Ai|Cj) 的概率，带入到上面的公式得出 P(A1A2A3|Cj)，最后找到使得 P(A1A2A3|Cj) 最大的类别 Cj。 我分别求下这些条件下的概率： P(A1|C1)=1/2, P(A2|C1)=1/2, P(A3|C1)=1/4，P(A1|C2)=0, P(A2|C2)=1/2, P(A3|C2)=1/2，所以 P(A1A2A3|C1)=1/16, P(A1A2A3|C2)=0。 因为 P(A1A2A3|C1)P(C1)&gt;P(A1A2A3|C2)P(C2)，所以应该是 C1 类别，即男性。 连续数据案例实际生活中我们得到的是连续的数值，比如下面这组数据： 那么如果给你一个新的数据，身高 180、体重 120，鞋码 41，请问该人是男是女呢？ 公式还是上面的公式，这里的困难在于，由于身高、体重、鞋码都是连续变量，不能采用离散变量的方法计算概率。而且由于样本太少，所以也无法分成区间计算。怎么办呢？ 这时，可以假设男性和女性的身高、体重、鞋码都是正态分布，通过样本计算出均值和方差，也就是得到正态分布的密度函数。有了密度函数，就可以把值代入，算出某一点的密度函数的值。比如，男性的身高是均值 179.5、标准差为 3.697 的正态分布。所以男性的身高为 180 的概率为 0.1069。怎么计算得出的呢? 你可以使用 EXCEL 的 NORMDIST(x,mean,standard_dev,cumulative) 函数，一共有 4 个参数： x：正态分布中，需要计算的数值； Mean：正态分布的平均值； Standard_dev：正态分布的标准差； Cumulative：取值为逻辑值，即 False 或 True。它决定了函数的形式。当为 TRUE 时，函数结果为累积分布；为 False 时，函数结果为概率密度。 这里我们使用的是 NORMDIST(180,179.5,3.697,0)=0.1069。 同理我们可以计算得出男性体重为 120 的概率为 0.000382324，男性鞋码为 41 号的概率为 0.120304111。 所以我们可以计算得出： P(A1A2A3|C1)=P(A1|C1)P(A2|C1)P(A3|C1)=0.10690.000382324 0.120304111=4.9169e-6 同理我们也可以计算出来该人为女的可能性： P(A1A2A3|C2)=P(A1|C2)P(A2|C2)P(A3|C2)=0.00000147489* 0.015354144* 0.120306074=2.7244e-9 很明显这组数据分类为男的概率大于分类为女的概率。 当然在 Python 中，有第三方库可以直接帮我们进行上面的操作，这个我们会在下文中介绍。这里主要是给你讲解下具体的运算原理。 朴素贝叶斯分类器工作流程朴素贝叶斯分类常用于文本分类，尤其是对于英文等语言来说，分类效果很好。它常用于垃圾文本过滤、情感预测、推荐系统等。 朴素贝叶斯分类器需要三个流程。 第一阶段：准备阶段 在这个阶段我们需要确定特征属性，比如上面案例中的“身高”、“体重”、“鞋码”等，并对每个特征属性进行适当划分，然后由人工对一部分数据进行分类，形成训练样本。 这一阶段是整个朴素贝叶斯分类中唯一需要人工完成的阶段，其质量对整个过程将有重要影响，分类器的质量很大程度上由特征属性、特征属性划分及训练样本质量决定。 第二阶段：训练阶段 这个阶段就是生成分类器，主要工作是计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率。 输入是特征属性和训练样本，输出是分类器。 第三阶段：应用阶段 这个阶段是使用分类器对新数据进行分类。 输入是分类器和新数据，输出是新数据的分类结果。 sklearn 机器学习包接下来带你一起使用朴素贝叶斯做下文档分类的项目，最重要的工具就是 sklearn 这个机器学习神器。 sklearn 的全称叫 Scikit-learn，它给我们提供了 3 个朴素贝叶斯分类算法，分别是高斯朴素贝叶斯（GaussianNB）、多项式朴素贝叶斯（MultinomialNB）和伯努利朴素贝叶斯（BernoulliNB）。 这三种算法适合应用在不同的场景下，我们应该根据特征变量的不同选择不同的算法： 高斯朴素贝叶斯 ：特征变量是连续变量，符合高斯分布，比如说人的身高，物体的长度。 多项式朴素贝叶斯 ：特征变量是离散变量，符合多项分布，在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。 伯努利朴素贝叶斯 ：特征变量是布尔变量，符合 0/1 分布，在文档分类中特征是单词是否出现。 伯努利朴素贝叶斯是以文件为粒度，如果该单词在某文件中出现了即为 1，否则为 0。而多项式朴素贝叶斯是以单词为粒度，会计算在某个文件中的具体次数。而高斯朴素贝叶斯适合处理特征变量是连续变量，且符合正态分布（高斯分布）的情况。比如身高、体重这种自然界的现象就比较适合用高斯朴素贝叶斯来处理。而文本分类是使用多项式朴素贝叶斯或者伯努利朴素贝叶斯。 TF-IDF 值： TF-IDF 是一个统计方法，用来评估某个词语对于一个文件集或文档库中的其中一份文件的重要程度。 TF-IDF 实际上是两个词组 Term Frequency 和 Inverse Document Frequency 的总称，两者缩写为 TF 和 IDF，分别代表了词频和逆向文档频率。 词频 TF 计算了一个单词在文档中出现的次数，它认为一个单词的重要性和它在文档中出现的次数呈正比。 逆向文档频率 IDF ，是指一个单词在文档中的区分度。它认为一个单词出现在的文档数越少，就越能通过这个单词把该文档和其他文档区分开。IDF 越大就代表该单词的区分度越大。 所以 TF-IDF 实际上是词频 TF 和逆向文档频率 IDF 的乘积 。这样我们倾向于找到 TF 和 IDF 取值都高的单词作为区分，即这个单词在一个文档中出现的次数多，同时又很少出现在其他文档中。这样的单词适合用于分类。 TF-IDF 如何计算 首先我们看下词频 TF 和逆向文档概率 IDF 的公式。 TF-IDF=TF*IDF （ IDF 为了避免分母为 0，统一给单词出现的文档数都加 1） 举个例子。假设一个文件夹里一共有 10 篇文档，其中一篇文档有 1000 个单词，“this”这个单词出现 20 次，“bayes”出现了 5 次。“this”在所有文档中均出现过，而“bayes”只在 2 篇文档中出现过。我们来计算一下这两个词语的 TF-IDF 值。 针对“this”，计算 TF-IDF 值： 所以 TF-IDF=0.02*(-0.0414)=-8.28e-4。 针对“bayes”，计算 TF-IDF 值： 很明显“bayes”的 TF-IDF 值要大于“this”的 TF-IDF 值。这就说明用“bayes”这个单词做区分比单词“this”要好。 如何求 TF-IDF在 sklearn 中我们直接使用 TfidfVectorizer 类，它可以帮我们计算单词 TF-IDF 向量的值。在这个类中，取 sklearn 计算的对数 log 时，底数是 e，不是 10。 下面我来讲下如何创建 TfidfVectorizer 类。 TfidfVectorizer 类的创建： 创建 TfidfVectorizer 的方法是： 1TfidfVectorizer(stop_words=stop_words, token_pattern=token_pattern) 我们在创建的时候，有两个构造参数，可以自定义停用词 stop_words 和规律规则 token_pattern。需要注意的是传递的数据结构，停用词 stop_words 是一个列表 List 类型，而过滤规则 token_pattern 是正则表达式。 什么是停用词？停用词就是在分类中没有用的词，这些词一般词频 TF 高，但是 IDF 很低，起不到分类的作用。为了节省空间和计算时间，我们把这些词作为停用词 stop words，告诉机器这些词不需要帮我计算。 当我们创建好 TF-IDF 向量类型时，可以用 fit_transform 帮我们计算，返回给我们文本矩阵，该矩阵表示了每个单词在每个文档中的 TF-IDF 值。 在我们进行 fit_transform 拟合模型后，我们可以得到更多的 TF-IDF 向量属性，比如，我们可以得到词汇的对应关系（字典类型）和向量的 IDF 值，当然也可以获取设置的停用词 stop_words。 举个例子，假设我们有 4 个文档： 文档 1：this is the bayes document； 文档 2：this is the second second document； 文档 3：and the third one； 文档 4：is this the document。 现在想要计算文档里都有哪些单词，这些单词在不同文档中的 TF-IDF 值是多少呢？ 首先我们创建 TfidfVectorizer 类： 12from sklearn.feature_extraction.text import TfidfVectorizertfidf_vec = TfidfVectorizer() 然后我们创建 4 个文档的列表 documents，并让创建好的 tfidf_vec 对 documents 进行拟合，得到 TF-IDF 矩阵： 1234567 documents = [ 'this is the bayes document', 'this is the second second document', 'and the third one', 'is this the document'] tfidf_matrix = tfidf_vec.fit_transform(documents) 输出文档中所有不重复的词： 1print('不重复的词:', tfidf_vec.get_feature_names()) 运行结果 1不重复的词: [&apos;and&apos;, &apos;bayes&apos;, &apos;document&apos;, &apos;is&apos;, &apos;one&apos;, &apos;second&apos;, &apos;the&apos;, &apos;third&apos;, &apos;this&apos;] 输出每个单词对应的 id 值： 1print('每个单词的 ID:', tfidf_vec.vocabulary_) 运行结果 1每个单词的 ID: &#123;&apos;this&apos;: 8, &apos;is&apos;: 3, &apos;the&apos;: 6, &apos;bayes&apos;: 1, &apos;document&apos;: 2, &apos;second&apos;: 5, &apos;and&apos;: 0, &apos;third&apos;: 7, &apos;one&apos;: 4&#125; 输出每个单词在每个文档中的 TF-IDF 值，向量里的顺序是按照词语的 id 顺序来的： 1print('每个单词的 tfidf 值:', tfidf_matrix.toarray()) 运行结果： 12345678 每个单词的 tfidf 值: [[0. 0.63314609 0.40412895 0.40412895 0. 0. 0.33040189 0. 0.40412895] [0. 0. 0.27230147 0.27230147 0. 0.853225740.22262429 0. 0.27230147] [0.55280532 0. 0. 0. 0.55280532 0. 0.28847675 0.55280532 0. ] [0. 0. 0.52210862 0.52210862 0. 0. 0.42685801 0. 0.52210862]] 如何对文档进行分类如果我们要对文档进行分类，有两个重要的阶段： 基于分词的数据准备 ，包括分词、单词权重计算、去掉停用词； 应用朴素贝叶斯分类进行分类 ，首先通过训练集得到朴素贝叶斯分类器，然后将分类器应用于测试集，并与实际结果做对比，最终得到测试集的分类准确率。 下面，我分别对这些模块进行介绍。 模块 1：对文档进行分词 在准备阶段里，最重要的就是分词。那么如果给文档进行分词呢？英文文档和中文文档所使用的分词工具不同。 在英文文档中，最常用的是 NTLK 包。NTLK 包中包含了英文的停用词 stop words、分词和标注方法。 123import nltkword_list = nltk.word_tokenize(text) # 分词nltk.pos_tag(word_list) # 标注单词的词性 在中文文档中，最常用的是 jieba 包。jieba 包中包含了中文的停用词 stop words 和分词方法。 12import jiebaword_list = jieba.cut (text) # 中文分词 模块 2：加载停用词表 我们需要自己读取停用词表文件，从网上可以找到中文常用的停用词保存在 stop_words.txt，然后利用 Python 的文件读取函数读取文件，保存在 stop_words 数组中。 1stop_words = [line.strip().decode('utf-8') for line in io.open('stop_words.txt').readlines()] 模块 3：计算单词的权重 这里我们用到 sklearn 里的 TfidfVectorizer 类，上面我们介绍过它使用的方法。 直接创建 TfidfVectorizer 类，然后使用 fit_transform 方法进行拟合，得到 TF-IDF 特征空间 features，你可以理解为选出来的分词就是特征。我们计算这些特征在文档上的特征向量，得到特征空间 features。 12tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5)features = tf.fit_transform(train_contents) 这里 max_df 参数用来描述单词在文档中的最高出现率。假设 max_df=0.5，代表一个单词在 50% 的文档中都出现过了，那么它只携带了非常少的信息，因此就不作为分词统计。 一般很少设置 min_df，因为 min_df 通常都会很小。 模块 4：生成朴素贝叶斯分类器 我们将特征训练集的特征空间 train_features，以及训练集对应的分类 train_labels 传递给贝叶斯分类器 clf，它会自动生成一个符合特征空间和对应分类的分类器。 这里我们采用的是多项式贝叶斯分类器，其中 alpha 为平滑参数。为什么要使用平滑呢？因为如果一个单词在训练样本中没有出现，这个单词的概率就会被计算为 0。但训练集样本只是整体的抽样情况，我们不能因为一个事件没有观察到，就认为整个事件的概率为 0。为了解决这个问题，我们需要做平滑处理。 当 alpha=1 时，使用的是 Laplace 平滑。Laplace 平滑就是采用加 1 的方式，来统计没有出现过的单词的概率。这样当训练样本很大的时候，加 1 得到的概率变化可以忽略不计，也同时避免了零概率的问题。 当 0&lt;alpha&lt;1 时，使用的是 Lidstone 平滑。对于 Lidstone 平滑来说，alpha 越小，迭代次数越多，精度越高。我们可以设置 alpha 为 0.001。 # 多项式贝叶斯分类器 12from sklearn.naive_bayes import MultinomialNBclf = MultinomialNB(alpha=0.001).fit(train_features, train_labels) 模块 5：使用生成的分类器做预测 首先我们需要得到测试集的特征矩阵。 方法是用训练集的分词创建一个 TfidfVectorizer 类，使用同样的 stop_words 和 max_df，然后用这个 TfidfVectorizer 类对测试集的内容进行 fit_transform 拟合，得到测试集的特征矩阵 test_features。 12test_tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5, vocabulary=train_vocabulary)test_features=test_tf.fit_transform(test_contents) 然后我们用训练好的分类器对新数据做预测。 方法是使用 predict 函数，传入测试集的特征矩阵 test_features，得到分类结果 predicted_labels。predict 函数做的工作就是求解所有后验概率并找出最大的那个。 1predicted_labels=clf.predict(test_features) 模块 6：计算准确率 计算准确率实际上是对分类模型的评估。我们可以调用 sklearn 中的 metrics 包，在 metrics 中提供了 accuracy_score 函数，方便我们对实际结果和预测的结果做对比，给出模型的准确率。 使用方法如下： 12from sklearn import metricsprint metrics.accuracy_score(test_labels, predicted_labels) 数据挖掘神器sklearn 从数据挖掘的流程来看，一般包括了获取数据、数据清洗、模型训练、模型评估和模型部署这几个过程。 sklearn中包含了大量的数据挖掘算法，比如三种朴素贝叶斯算法，我们只需要了解不同算法的适用条件，以及创建时所需的参数，就可以用模型帮我们进行训练。在模型评估中 klearn提供了metrics包，帮我们对预测结果与实际结果进行评估。 18.SVM分类SVM 的英文叫 Support Vector Machine，中文名为支持向量机。它是常见的一种分类方法，在机器学习中，SVM 是有监督的学习模型。 什么是有监督的学习模型呢？它指的是我们需要事先对数据打上分类标签，这样机器就知道这个数据属于哪个分类。同样无监督学习，就是数据没有被打上分类标签，这可能是因为我们不具备先验的知识，或者打标签的成本很高。所以我们需要机器代我们部分完成这个工作，比如将数据进行聚类，方便后续人工对每个类进行分析。SVM 作为有监督的学习模型，通常可以帮我们模式识别、分类以及回归分析。 一、SVM 的工作原理用 SVM 计算的过程就是帮我们找到一个超平面，能够将样本区分的过程，这个超平面就是我们的 SVM 分类器。 比如下图所示的直线 A、直线 B 和直线 C，究竟哪种才是更好的划分呢？ 很明显图中的直线 B 更靠近蓝色球，但是在真实环境下，球再多一些的话，蓝色球可能就被划分到了直线 B 的右侧，被认为是红色球。同样直线 A 更靠近红色球，在真实环境下，如果红色球再多一些，也可能会被误认为是蓝色球。所以相比于直线 A 和直线 B，直线 C 的划分更优，因为它的鲁棒性更强。 那怎样才能寻找到直线 C 这个更优的答案呢？这里，我们引入一个 SVM 特有的概念： 分类间隔。 实际上，我们的分类环境不是在二维平面中的，而是在多维空间中，这样直线 C 就变成了决策面 C。 在保证决策面不变，且分类不产生错误的情况下，我们可以移动决策面 C，直到产生两个极限的位置：如图中的决策面 A 和决策面 B。极限的位置是指，如果越过了这个位置，就会产生分类错误。这样的话，两个极限位置 A 和 B 之间的分界线 C 就是最优决策面。极限位置到最优决策面 C 之间的距离，就是“分类间隔”，英文叫做 margin。 如果我们转动这个最优决策面，你会发现可能存在多个最优决策面，它们都能把数据集正确分开，这些最优决策面的分类间隔可能是不同的，而那个拥有“最大间隔”（max margin）的决策面就是 SVM 要找的最优解。 点到超平面的距离公式 在上面这个例子中，如果我们把红蓝两种颜色的球放到一个三维空间里，你发现决策面就变成了一个平面。这里我们可以用线性函数来表示，如果在一维空间里就表示一个点，在二维空间里表示一条直线，在三维空间中代表一个平面，当然空间维数还可以更多，这样我们给这个线性函数起个名称叫做“超平面”。超平面的数学表达可以写成： 在这个公式里，w、x 是 n 维空间里的向量，其中 x 是函数变量；w 是法向量。法向量这里指的是垂直于平面的直线所表示的向量，它决定了超平面的方向。 SVM 就是帮我们找到一个超平面 ，这个超平面能将不同的样本划分开，同时使得样本集中的点到这个分类超平面的最小距离（即分类间隔）最大化。 在这个过程中， 支持向量 就是离 分类超平面 最近的样本点，实际上如果确定了支持向量也就确定了这个超平面。所以支持向量决定了分类间隔到底是多少，而在最大间隔以外的样本点，其实对分类都没有意义。 所以说， SVM 就是求解最大分类间隔的过程，我们还需要对分类间隔的大小进行定义。 首先，我们定义某类样本集到超平面的距离是这个样本集合内的样本到超平面的最短距离。我们用 di 代表点 xi 到超平面 wxi+b=0 的欧氏距离。因此我们要求 di 的最小值，用它来代表这个样本到超平面的最短距离。di 可以用公式计算得出： 其中||w||为超平面的范数，di 的公式可以用解析几何知识进行推导，这里不做解释。 最大间隔的优化模型 我们的目标就是找出所有分类间隔中最大的那个值对应的超平面。在数学上，这是一个凸优化问题（凸优化就是关于求凸集中的凸函数最小化的问题，这里不具体展开）。通过凸优化问题，最后可以求出最优的 w 和 b，也就是我们想要找的最优超平面。中间求解的过程会用到拉格朗日乘子，和 KKT（Karush-Kuhn-Tucker）条件。数学公式比较多，这里不进行展开。 硬间隔、软间隔和非线性 SVM 假如数据是完全的线性可分的，那么学习到的模型可以称为硬间隔支持向量机。 换个说法，硬间隔指的就是完全分类准确，不能存在分类错误的情况。软间隔，就是允许一定量的样本分类错误。 我们知道，实际工作中的数据没有那么“干净”，或多或少都会存在一些噪点。所以线性可分是个理想情况。这时，我们需要使用到软间隔 SVM（近似线性可分），比如下面这种情况： 另外还存在一种情况，就是非线性支持向量机。 比如下面的样本集就是个非线性的数据。图中的两类数据，分别分布为两个圆圈的形状。那么这种情况下，不论是多高级的分类器，只要映射函数是线性的，就没法处理，SVM 也处理不了。这时，我们需要引入一个新的概念： 核函数。它可以将样本从原始空间映射到一个更高维的特质空间中，使得样本在新的空间中线性可分 。这样我们就可以使用原来的推导来进行计算，只是所有的推导是在新的空间，而不是在原来的空间中进行。 所以在非线性 SVM 中，核函数的选择就是影响 SVM 最大的变量。最常用的核函数有线性核、多项式核、高斯核、拉普拉斯核、sigmoid 核，或者是这些核函数的组合。这些函数的区别在于映射方式的不同。通过这些核函数，我们就可以把样本空间投射到新的高维空间中。 当然软间隔和核函数的提出，都是为了方便我们对上面超平面公式中的 w* 和 b* 进行求解，从而得到最大分类间隔的超平面。 二、 用 SVM 如何解决多分类问题SVM 本身是一个二值分类器，最初是为二分类问题设计的，也就是回答 Yes 或者是 No。而实际上我们要解决的问题，可能是多分类的情况，比如对文本进行分类，或者对图像进行识别。 针对这种情况，我们可以将多个二分类器组合起来形成一个多分类器，常见的方法有“一对多法”和“一对一法”两种。 1. 一对多法 假设我们要把物体分成 A、B、C、D 四种分类，那么我们可以先把其中的一类作为分类 1，其他类统一归为分类 2。这样我们可以构造 4 种 SVM，分别为以下的情况： （1）样本 A 作为正集，B，C，D 作为负集； （2）样本 B 作为正集，A，C，D 作为负集； （3）样本 C 作为正集，A，B，D 作为负集； （4）样本 D 作为正集，A，B，C 作为负集。 这种方法，针对 K 个分类，需要训练 K 个分类器，分类速度较快，但训练速度较慢，因为每个分类器都需要对全部样本进行训练，而且负样本数量远大于正样本数量，会造成样本不对称的情况，而且当增加新的分类，比如第 K+1 类时，需要重新对分类器进行构造。 2. 一对一法 一对一法的初衷是想在训练的时候更加灵活。我们可以在任意两类样本之间构造一个 SVM，这样针对 K 类的样本，就会有 C(k,2) 类分类器。 比如我们想要划分 A、B、C 三个类，可以构造 3 个分类器： （1）分类器 1：A、B； （2）分类器 2：A、C； （3）分类器 3：B、C。 当对一个未知样本进行分类时，每一个分类器都会有一个分类结果，即为 1 票，最终得票最多的类别就是整个未知样本的类别。 这样做的好处是，如果新增一类，不需要重新训练所有的 SVM，只需要训练和新增这一类样本的分类器。而且这种方式在训练单个 SVM 模型的时候，训练速度快。 但这种方法的不足在于，分类器的个数与 K 的平方成正比，所以当 K 较大时，训练和测试的时间会比较慢。 三、 如何在 sklearn 中使用 SVM在 Python 的 sklearn 工具包中有 SVM 算法，首先需要引用工具包： 1from sklearn import svm SVM 既可以做回归，也可以做分类器。 当用 SVM 做回归的时候，我们可以使用 SVR 或 LinearSVR。SVR 的英文是 Support Vector Regression。这篇文章只讲分类，这里只是简单地提一下。 当做分类器的时候，我们使用的是 SVC 或者 LinearSVC。SVC 的英文是 Support Vector Classification。 我简单说一下这两者之前的差别。 从名字上你能看出 LinearSVC 是个线性分类器，用于处理线性可分的数据，只能使用线性核函数。上一节，我讲到 SVM 是通过核函数将样本从原始空间映射到一个更高维的特质空间中，这样就使得样本在新的空间中线性可分。 如果是针对非线性的数据，需要用到 SVC。在 SVC 中，我们既可以使用到线性核函数（进行线性划分），也能使用高维的核函数（进行非线性划分）。 创建一个 SVM 分类器 我们首先使用 SVC 的构造函数：model = svm.SVC(kernel=‘rbf’, C=1.0, gamma=‘auto’)，这里有三个重要的参数 kernel、C 和 gamma。 kernel 代表核函数的选择，它有四种选择，只不过默认是 rbf，即高斯核函数。 linear：线性核函数 poly：多项式核函数 rbf：高斯核函数（默认） sigmoid：sigmoid 核函数 这四种函数代表不同的映射方式，在实际工作中，如何选择这 4 种核函数： 线性核函数，是在数据线性可分的情况下使用的，运算速度快，效果好。不足在于它不能处理线性不可分的数据。 多项式核函数可以将数据从低维空间映射到高维空间，但参数比较多，计算量大。 高斯核函数同样可以将样本映射到高维空间，但相比于多项式核函数来说所需的参数比较少，通常性能不错，所以是默认使用的核函数。 了解深度学习的同学应该知道 sigmoid 经常用在神经网络的映射中。因此当选用 sigmoid 核函数时，SVM 实现的是多层神经网络。 上面介绍的 4 种核函数，除了第一种线性核函数外，其余 3 种都可以处理线性不可分的数据。 参数 C 代表目标函数的惩罚系数 惩罚系数指的是分错样本时的惩罚程度，默认情况下为 1.0。当 C 越大的时候，分类器的准确性越高，但同样容错率会越低，泛化能力会变差。相反，C 越小，泛化能力越强，但是准确性会降低。 参数 gamma 代表核函数的系数 默认为样本特征数的倒数，即 gamma = 1 / n_features。 在创建 SVM 分类器之后，就可以输入训练集对它进行训练。我们使用 model.fit(train_X,train_y)，传入训练集中的特征值矩阵 train_X 和分类标识 train_y。特征值矩阵就是我们在特征选择后抽取的特征值矩阵（当然你也可以用全部数据作为特征值矩阵）；分类标识就是人工事先针对每个样本标识的分类结果。这样模型会自动进行分类器的训练。我们可以使用 prediction=model.predict(test_X) 来对结果进行预测，传入测试集中的样本特征矩阵 test_X，可以得到测试集的预测分类结果 prediction。 同样我们也可以创建线性 SVM 分类器，使用 model=svm.LinearSVC()。在 LinearSVC 中没有 kernel 这个参数，限制我们只能使用线性核函数。由于 LinearSVC 对线性分类做了优化，对于数据量大的线性可分问题，使用 LinearSVC 的效率要高于 SVC。 如果你不知道数据集是否为线性，可以直接使用 SVC 类创建 SVM 分类器。 在训练和预测中，LinearSVC 和 SVC 一样，都是使用 model.fit(train_X,train_y) 和 model.predict(test_X)。 四、 如何用 SVM 进行乳腺癌检测在了解了如何创建和使用 SVM 分类器后，我们来看一个实际的项目，数据集来自美国威斯康星州的乳腺癌诊断数据集， 点击这里进行下载。 医疗人员采集了患者乳腺肿块经过细针穿刺 (FNA) 后的数字化图像，并且对这些数字图像进行了特征提取，这些特征可以描述图像中的细胞核呈现。肿瘤可以分成良性和恶性。部分数据截屏如下所示： 数据表一共包括了 32 个字段，代表的含义如下： 上面的表格中，mean 代表平均值，se 代表标准差，worst 代表最大值（3 个最大值的平均值）。每张图像都计算了相应的特征，得出了这 30 个特征值（不包括 ID 字段和分类标识结果字段 diagnosis），实际上是 10 个特征值（radius、texture、perimeter、area、smoothness、compactness、concavity、concave points、symmetry 和 fractal_dimension_mean）的 3 个维度，平均、标准差和最大值。这些特征值都保留了 4 位数字。字段中没有缺失的值。在 569 个患者中，一共有 357 个是良性，212 个是恶性。 好了，我们的目标是生成一个乳腺癌诊断的 SVM 分类器，并计算这个分类器的准确率。 首先加载数据并对数据做部分的探索： 12345678# 加载数据集，你需要把数据放到目录中data = pd.read_csv(\"./data.csv\")# 数据探索print(data.columns)print(data.info())print(data.head(5))print(data.describe()) 对数据进行清洗 运行结果中，你能看到 32 个字段里，id 是没有实际含义的，可以去掉。diagnosis 字段的取值为 B 或者 M，我们可以用 0 和 1 来替代。另外其余的 30 个字段，其实可以分成三组字段，下划线后面的 mean、se 和 worst 代表了每组字段不同的度量方式，分别是平均值、标准差和最大值。 12345678910# 将特征字段分成 3 组(获得三组columns list)features_mean= list(data.columns[2:12])features_se= list(data.columns[12:22])features_worst=list(data.columns[22:32])# 数据清洗# ID 列没有用，删除该列data.drop(\"id\",axis=1,inplace=True)# 将 B 良性替换为 0，M 恶性替换为 1data['diagnosis']=data['diagnosis'].map(&#123;'M':1,'B':0&#125;) 做特征字段的筛选 首先需要观察下 features_mean 各变量之间的关系，这里我们可以用 DataFrame 的 corr() 函数，然后用热力图帮我们可视化呈现。同样，我们也会看整体良性、恶性肿瘤的诊断情况。 （特征字段：根据什么字段分类） 12345678910# 将肿瘤诊断结果可视化sns.countplot(data['diagnosis'],label=\"Count\")plt.show()# 用热力图呈现 features_mean 字段之间的相关性corr = data[features_mean].corr()plt.figure(figsize=(14,14))# annot=True 显示每个方格的数据sns.heatmap(corr, annot=True)plt.show() 这是运行的结果： 热力图中对角线上的为单变量自身的相关系数是 1。颜色越浅代表相关性越大。所以你能看出来 radius_mean、perimeter_mean 和 area_mean 相关性非常大，compactness_mean、concavity_mean、concave_points_mean 这三个字段也是相关的，因此我们可以取其中的一个作为代表。 进行特征选择 特征选择的目的是降维，用少量的特征代表数据的特性，这样也可以增强分类器的泛化能力，避免数据过拟合。 我们能看到 mean、se 和 worst 这三组特征是对同一组内容的不同度量方式，我们可以保留 mean 这组特征，在特征选择中忽略掉 se 和 worst。同时我们能看到 mean 这组特征中，radius_mean、perimeter_mean、area_mean 这三个属性相关性大，compactness_mean、daconcavity_mean、concave points_mean 这三个属性相关性大。我们分别从这 2 类中选择 1 个属性作为代表，比如 radius_mean 和 compactness_mean。 这样我们就可以把原来的 10 个属性缩减为 6 个属性，代码如下： 12345678910111213141516171819202122232425262728# 特征选择features_remain = ['radius_mean','texture_mean', 'smoothness_mean','compactness_mean','symmetry_mean', 'fractal_dimension_mean']# 对特征进行选择之后，我们就可以准备训练集和测试集：# 抽取 30% 的数据作为测试集，其余作为训练集train, test = train_test_split(data, test_size = 0.3)# in this our main data is splitted into train and test# 抽取特征选择的数值作为训练和测试数据train_X = train[features_remain]train_y=train['diagnosis']test_X= test[features_remain]test_y =test['diagnosis']# 在训练之前，我们需要对数据进行规范化，这样让数据同在同一个量级上，避免因为维度问题造成数据误差：# 采用 Z-Score 规范化数据，保证每个特征维度的数据均值为 0，方差为 1# fit_transform()特征向量转化为特征矩阵ss = StandardScaler()train_X = ss.fit_transform(train_X)test_X = ss.transform(test_X)# 最后我们可以让 SVM 做训练和预测了：# 创建 SVM 分类器model = svm.SVC()# 用训练集做训练model.fit(train_X,train_y)# 用测试集做预测prediction=model.predict(test_X)print('准确率: ', metrics.accuracy_score(prediction,test_y)) 运行结果： 1准确率: 0.9181286549707602 准确率大于 90%，说明训练结果还不错。 完整代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import pandas as pdimport seaborn as snsimport matplotlib.pyplot as pltfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import StandardScalerfrom sklearn import svmfrom sklearn import metricspd.set_option('display.max_columns', None)pd.set_option('display.max_rows', None)pd.set_option('max_colwidth', 100)data = pd.read_csv('../test_data/breast_cancer_data/data.csv')# print(data.columns)# print(data.info())# print(data.head(5))# print(data.describe())features_mean = list(data.columns[2:12])features_se = list(data.columns[12:22])features_worst = list(data.columns[22:32])data.drop(\"id\", axis=1, inplace=True)data['diagnosis'] = data['diagnosis'].map(&#123;'M': 1, 'B': 0&#125;)# sns.countplot(data['diagnosis'], label=\"Count\")# plt.show()## corr = data[features_mean].corr()# plt.figure(figsize=(14,14))# sns.heatmap(corr, annot=True)# plt.show()features_remain = ['radius_mean','texture_mean', 'smoothness_mean', 'compactness_mean', 'symmetry_mean', 'fractal_dimension_mean']train, test = train_test_split(data, test_size=0.3)train_X = train[features_remain]train_y = train['diagnosis']test_X = test[features_remain]test_y = test['diagnosis']ss = StandardScaler()train_X = ss.fit_transform(train_X)test_X = ss.transform(test_X)model = svm.SVC()model.fit(train_X, train_y)prediction = model.predict(test_X)print('准确率: ', metrics.accuracy_score(prediction, test_y)) 19.KNN分类KNN 的英文叫 K-Nearest Neighbor，应该算是数据挖掘算法中最简单的一种。 假设，我们想对电影的类型进行分类，统计了电影中打斗次数、接吻次数，当然还有其他的指标也可以被统计到，如下表所示。 我们很容易理解《战狼》《红海行动》《碟中谍 6》是动作片，《前任 3》《春娇救志明》《泰坦尼克号》是爱情片，但是有没有一种方法让机器也可以掌握这个分类的规则，当有一部新电影的时候，也可以对它的类型自动分类呢？ 我们可以把打斗次数看成 X 轴，接吻次数看成 Y 轴，然后在二维的坐标轴上，对这几部电影进行标记，如下图所示。对于未知的电影 A，坐标为 (x,y)，我们需要看下离电影 A 最近的都有哪些电影，这些电影中的大多数属于哪个分类，那么电影 A 就属于哪个分类。实际操作中，我们还需要确定一个 K 值，也就是我们要观察离电影 A 最近的电影有多少个。 一、KNN 的工作原理“近朱者赤，近墨者黑”可以说是 KNN 的工作原理。整个计算过程分为三步： 计算待分类物体与其他物体之间的距离； 统计距离最近的 K 个邻居； 对于 K 个最近的邻居，它们属于哪个分类最多，待分类物体就属于哪一类。 K 值如何选择你能看出整个 KNN 的分类过程，K 值的选择还是很重要的，K 值选择多少是适合的呢？ 如果 K 值比较小，就相当于未分类物体与它的邻居非常接近才行。这样产生的一个问题就是，如果邻居点是个噪声点，那么未分类物体的分类也会产生误差，这样 KNN 分类就会产生过拟合。 如果 K 值比较大，相当于距离过远的点也会对未知物体的分类产生影响，虽然这种情况的好处是鲁棒性强，但是不足也很明显，会产生欠拟合情况，也就是没有把未分类物体真正分类出来。 所以 K 值应该是个实践出来的结果，并不是我们事先而定的。在工程上，我们一般采用交叉验证的方式选取 K 值。 交叉验证的思路就是，把样本集中的大部分样本作为训练集，剩余的小部分样本用于预测，来验证分类模型的准确性。所以在 KNN 算法中，我们一般会把 K 值选取在较小的范围内，同时在验证集上准确率最高的那一个最终确定作为 K 值。 距离如何计算在 KNN 算法中，还有一个重要的计算就是关于距离的度量。两个样本点之间的距离代表了这两个样本之间的相似度。距离越大，差异性越大；距离越小，相似度越大。 关于距离的计算方式有下面五种方式： 欧氏距离； 曼哈顿距离； 闵可夫斯基距离； 切比雪夫距离； 余弦距离。 其中前三种距离是 KNN 中最常用的距离，现在分别讲解下。 欧氏距离 最常用的距离公式，也叫做欧几里得距离。在二维空间中，两点的欧式距离就是： 同理，我们也可以求得两点在 n 维空间中的距离： 曼哈顿距离 在几何空间中用的比较多。曼哈顿距离等于两个点在坐标系上绝对轴距总和。用公式表示就是： 闵可夫斯基距离 不是一个距离，而是一组距离的定义。对于 n 维空间中的两个点 x(x1,x2,…,xn) 和 y(y1,y2,…,yn) ， x 和 y 两点之间的闵可夫斯基距离为： 其中 p 代表空间的维数，当 p=1 时，就是曼哈顿距离；当 p=2 时，就是欧氏距离；当 p→∞时，就是切比雪夫距离。 切比雪夫距离：二个点之间的切比雪夫距离就是这两个点坐标数值差的绝对值的最大值，用数学表示就是：max(|x1-y1|,|x2-y2|)。 余弦距离：实际上计算的是两个向量的夹角，是在方向上计算两者之间的差异，对绝对数值不敏感。在兴趣相关性比较上，角度关系比距离的绝对值更重要，因此余弦距离可以用于衡量用户对内容兴趣的区分度。比如我们用搜索引擎搜索某个关键词，它还会给你推荐其他的相关搜索，这些推荐的关键词就是采用余弦距离计算得出的。 KD 树其实从上文你也能看出来，KNN 的计算过程是大量计算样本点之间的距离。为了减少计算距离次数，提升 KNN 的搜索效率，人们提出了 KD 树（K-Dimensional 的缩写）。KD 树是对数据点在 K 维空间中划分的一种数据结构。在 KD 树的构造中，每个节点都是 k 维数值点的二叉树。既然是二叉树，就可以采用二叉树的增删改查操作，这样就大大提升了搜索效率。 在这里，我们不需要对 KD 树的数学原理了解太多，你只需要知道它是一个二叉树的数据结构，方便存储 K 维空间的数据就可以了。而且在 sklearn 中，我们直接可以调用 KD 树，很方便。 用 KNN 做回归KNN 不仅可以做分类，还可以做回归。首先讲下什么是回归。在开头电影这个案例中，如果想要对未知电影进行类型划分，这是一个分类问题。首先看一下要分类的未知电影，离它最近的 K 部电影大多数属于哪个分类，这部电影就属于哪个分类。 如果是一部新电影，已知它是爱情片，想要知道它的打斗次数、接吻次数可能是多少，这就是一个回归问题。 那么 KNN 如何做回归呢？ 对于一个新点，我们需要找出这个点的 K 个最近邻居，然后将这些邻居的属性的平均值赋给该点，就可以得到该点的属性。当然不同邻居的影响力权重可以设置成不同的。举个例子，比如一部电影 A，已知它是动作片，当 K=3 时，最近的 3 部电影是《战狼》，《红海行动》和《碟中谍 6》，那么它的打斗次数和接吻次数的预估值分别为 (100+95+105)/3=100 次、(5+3+31)/3=13 次。 二、 如何在 sklearn 中使用 KNN接下来，我们先看下如何在 sklearn 中使用 KNN 算法，然后通过 sklearn 中自带的手写数字数据集来进行实战。 在 Python 的 sklearn 工具包中有 KNN 算法。KNN 既可以做分类器，也可以做回归。 如果是做分类，你需要引用： 1from sklearn.neighbors import KNeighborsClassifier 如果是做回归，你需要引用： 1from sklearn.neighbors import KNeighborsRegressor 从名字上你也能看出来 Classifier 对应的是分类，Regressor 对应的是回归。一般来说如果一个算法有 Classifier 类，都能找到相应的 Regressor 类。比如在决策树分类中，你可以使用 DecisionTreeClassifier，也可以使用决策树来做回归 DecisionTreeRegressor。 如何在 sklearn 中创建 KNN 分类器 这里，我们使用构造函数 KNeighborsClassifier(n_neighbors=5, weights=‘uniform’, algorithm=‘auto’, leaf_size=30)，这里有几个比较主要的参数，我分别来讲解下： n_neighbors：即 KNN 中的 K 值，代表的是邻居的数量。K 值如果比较小，会造成过拟合。如果 K 值比较大，无法将未知物体分类出来。一般我们使用默认值 5。 weights：是用来确定邻居的权重，有三种方式： weights=uniform，代表所有邻居的权重相同； weights=distance，代表权重是距离的倒数，即与距离成反比； 自定义函数，你可以自定义不同距离所对应的权重。大部分情况下不需要自己定义函数。 algorithm：用来规定计算邻居的方法，它有四种方式： algorithm=auto，根据数据的情况自动选择适合的算法，默认情况选择 auto； algorithm=kd_tree，也叫作 KD 树，是多维空间的数据结构，方便对关键数据进行检索，不过 KD 树适用于维度少的情况，一般维数不超过 20，如果维数大于 20 之后，效率反而会下降； algorithm=ball_tree，也叫作球树，它和 KD 树一样都是多维空间的数据结果，不同于 KD 树，球树更适用于维度大的情况； algorithm=brute，也叫作暴力搜索，它和 KD 树不同的地方是在于采用的是线性扫描，而不是通过构造树结构进行快速检索。当训练集大的时候，效率很低。 leaf_size：代表构造 KD 树或球树时的叶子数，默认是 30，调整 leaf_size 会影响到树的构造和搜索速度。 创建完 KNN 分类器之后，我们就可以输入训练集对它进行训练，这里我们使用 fit() 函数，传入训练集中的样本特征矩阵和分类标识，会自动得到训练好的 KNN 分类器。然后可以使用 predict() 函数来对结果进行预测，这里传入测试集的特征矩阵，可以得到测试集的预测分类结果。 三、 如何用 KNN 对手写数字进行识别分类手写数字数据集是个非常有名的用于图像识别的数据集。数字识别的过程就是将这些图片与分类结果 0-9 一一对应起来。完整的手写数字数据集 MNIST 里面包括了 60000 个训练样本，以及 10000 个测试样本。如果你学习深度学习的话，MNIST 基本上是你接触的第一个数据集。 今天我们用 sklearn 自带的手写数字数据集做 KNN 分类，你可以把这个数据集理解成一个简版的 MNIST 数据集，它只包括了 1797 幅数字图像，每幅图像大小是 8*8 像素。 先规划下整个 KNN 分类的流程： 数据加载：我们可以直接从 sklearn 中加载自带的手写数字数据集； 准备阶段：在这个阶段中，我们需要对数据集有个初步的了解，比如样本的个数、图像长什么样、识别结果是怎样的。可以通过可视化的方式来查看图像的呈现。通过数据规范化可以让数据都在同一个数量级的维度。另外，因为训练集是图像，每幅图像是个 8*8 的矩阵，我们不需要对它进行特征选择，将全部的图像数据作为特征值矩阵即可； 分类阶段：通过训练可以得到分类器，然后用测试集进行准确率的计算。 加载数据和对数据的探索： 12345678910111213141516# 加载数据digits = load_digits()data = digits.data# 数据探索print(data.shape)print(data[0])# 查看第一幅图像print(digits.images[0])# 第一幅图像代表的数字含义print(digits.target[0])# 将第一幅图像显示出来plt.gray()plt.imshow(digits.images[0])plt.show() 运行结果： 1234567891011121314(1797, 64)[ 0. 0. 5. 13. 9. 1. 0. 0. 0. 0. 13. 15. 10. 15. 5. 0. 0. 3. 15. 2. 0. 11. 8. 0. 0. 4. 12. 0. 0. 8. 8. 0. 0. 5. 8. 0. 0. 9. 8. 0. 0. 4. 11. 0. 1. 12. 7. 0. 0. 2. 14. 5. 10. 12. 0. 0. 0. 0. 6. 13. 10. 0. 0. 0.][[ 0. 0. 5. 13. 9. 1. 0. 0.][ 0. 0. 13. 15. 10. 15. 5. 0.][ 0. 3. 15. 2. 0. 11. 8. 0.][ 0. 4. 12. 0. 0. 8. 8. 0.][ 0. 5. 8. 0. 0. 9. 8. 0.][ 0. 4. 11. 0. 1. 12. 7. 0.][ 0. 2. 14. 5. 10. 12. 0. 0.][ 0. 0. 6. 13. 10. 0. 0. 0.]]0 我们对原始数据集中的第一幅进行数据可视化，可以看到图像是个 8*8 的像素矩阵，上面这幅图像是一个“0”，从训练集的分类标注中我们也可以看到分类标注为“0”。 sklearn 自带的手写数字数据集一共包括了 1797 个样本，每幅图像都是 8*8 像素的矩阵。因为并没有专门的测试集，所以我们需要对数据集做划分，划分成训练集和测试集。因为 KNN 算法和距离定义相关，我们需要对数据进行规范化处理，采用 Z-Score 规范化，代码如下： 1234567891011121314# 分割数据，将 25% 的数据作为测试集，其余作为训练集（你也可以指定其他比例的数据作为训练集）train_x, test_x, train_y, test_y = train_test_split(data, digits.target, test_size=0.25, random_state=33)# 采用 Z-Score 规范化ss = preprocessing.StandardScaler()train_ss_x = ss.fit_transform(train_x)test_ss_x = ss.transform(test_x)# 然后我们构造一个 KNN 分类器 knn，把训练集的数据传入构造好的 knn，并通过测试集进行结果预测，与测试集的结果进行对比，得到 KNN 分类器准确率，代码如下：# 创建 KNN 分类器knn = KNeighborsClassifier()knn.fit(train_ss_x, train_y)predict_y = knn.predict(test_ss_x)print(\"KNN 准确率: %.4lf\" % accuracy_score(predict_y, test_y)) 运行结果： 1KNN 准确率: 0.9756 好了，这样我们就构造好了一个 KNN 分类器。之前我们还讲过 SVM、朴素贝叶斯和决策树分类。我们用手写数字数据集一起来训练下这些分类器，然后对比下哪个分类器的效果更好。代码如下： 123456789101112131415161718192021# 创建 SVM 分类器svm = SVC()svm.fit(train_ss_x, train_y)predict_y=svm.predict(test_ss_x)print('SVM 准确率: %0.4lf' % accuracy_score(predict_y, test_y))# 采用 Min-Max 规范化mm = preprocessing.MinMaxScaler()train_mm_x = mm.fit_transform(train_x)test_mm_x = mm.transform(test_x)# 创建 Naive Bayes 分类器mnb = MultinomialNB()mnb.fit(train_mm_x, train_y)predict_y = mnb.predict(test_mm_x)print(\" 多项式朴素贝叶斯准确率: %.4lf\" % accuracy_score(predict_y, test_y))# 创建 CART 决策树分类器dtc = DecisionTreeClassifier()dtc.fit(train_mm_x, train_y)predict_y = dtc.predict(test_mm_x)print(\"CART 决策树准确率: %.4lf\" % accuracy_score(predict_y, test_y)) 运行结果如下： 123SVM 准确率: 0.9867多项式朴素贝叶斯准确率: 0.8844CART 决策树准确率: 0.8556 这里需要注意的是，我们在做多项式朴素贝叶斯分类的时候，传入的数据不能有负数。因为 Z-Score 会将数值规范化为一个标准的正态分布，即均值为 0，方差为 1，数值会包含负数。因此我们需要采用 Min-Max 规范化，将数据规范化到 [0,1] 范围内。 好了，我们整理下这 4 个分类器的结果。 你能看出来 KNN 的准确率还是不错的，和 SVM 不相上下。 你可以自己跑一遍整个代码，在运行前还需要 import 相关的工具包（下面的这些工具包你都会用到，所以都需要引用）： 123456789from sklearn.model_selection import train_test_splitfrom sklearn import preprocessingfrom sklearn.metrics import accuracy_scorefrom sklearn.datasets import load_digitsfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.svm import SVCfrom sklearn.naive_bayes import MultinomialNBfrom sklearn.tree import DecisionTreeClassifierimport matplotlib.pyplot as plt 代码中，我使用了 train_test_split 做数据集的拆分，使用 matplotlib.pyplot 工具包显示图像，使用 accuracy_score 进行分类器准确率的计算，使用 preprocessing 中的 StandardScaler 和 MinMaxScaler 做数据的规范化。 20.K-Means聚类K-Means 是一种非监督学习，解决的是聚类问题。K 代表的是 K 类，Means 代表的是中心，你可以理解这个算法的本质是确定 K 类的中心点，当你找到了这些中心点，也就完成了聚类。 理解K-Means需要掌握的三个问题： 如何确定 K 类的中心点？ 如何将其他点划分到 K 类中？ 如何区分 K-Means 与 KNN？ 一、K-Means 的工作原理如何确定 K 类的中心点 一开始我们是可以随机指派的，当你确认了中心点后，就可以按照距离将其他的点划分到不同的类别中，这也就是 K-Means 的中心思想，就是这么简单直接。你可能会问：如果一开始中心点选错了怎么办？其实不用担心，K-Means 有自我纠正机制，在不断的迭代过程中，会纠正中心点。中心点在整个迭代过程中，并不是唯一的，只是你需要一个初始值，一般算法会随机设置初始的中心点。 K-Means 的工作原理总结： 选取 K 个点作为初始的类中心点，这些点一般都是从数据集中随机抽取的； 将每个点分配到最近的类中心点，这样就形成了 K 个类，然后重新计算每个类的中心点； 解释一下：计算每个类的中心点就是，分别计算每个类别中的所有点的特征值的平均值，将这个平均值作为新的中心点，这就是为什么叫K-Means 重复第二步，直到类不发生变化，或者你也可以设置最大迭代次数，这样即使类中心点发生变化，但是只要达到最大迭代次数就会结束。 二、如何给亚洲球队做聚类其中 2019 年国际足联的世界排名，2015 年亚洲杯排名均为实际排名。2018 年世界杯中，很多球队没有进入到决赛圈，所以只有进入到决赛圈的球队才有实际的排名。如果是亚洲区预选赛 12 强的球队，排名会设置为 40。如果没有进入亚洲区预选赛 12 强，球队排名会设置为 50。 针对上面的排名，我们首先需要做的是数据规范化。你可以把这些值划分到 [0,1] ，或者按照均值为 0，方差为 1 的正态分布进行规范化。 把数值都规范化到 [0,1] 的空间中，得到了以下的数值表： 如果我们随机选取中国、日本、韩国为三个类的中心点，我们就需要看下这些球队到中心点的距离。 距离有多种计算的方式，有关距离的计算在 KNN 算法中讲过。这里我选择欧氏距离作为距离的标准，计算每个队伍分别到中国、日本、韩国的距离，然后根据距离远近来划分。我们看到大部分的队和中国队聚类到一起。这里我整理了距离的计算过程，比如中国和中国的欧氏距离为 0，中国和日本的欧式距离为 0.732003。如果按照中国、日本、韩国为 3 个分类的中心点，欧氏距离的计算结果如下表所示： 然后我们再重新计算这三个类的中心点，如何计算呢？最简单的方式就是取平均值，然后根据新的中心点按照距离远近重新分配球队的分类，再根据球队的分类更新中心点的位置。计算过程这里不展开，最后一直迭代（重复上述的计算过程：计算中心点和划分分类）到分类不再发生变化，可以得到以下的分类结果： 三、如何使用 sklearn 中的 K-Means 算法sklearn 是 Python 的机器学习工具库，如果从功能上来划分，sklearn 可以实现分类、聚类、回归、降维、模型选择和预处理等功能。这里我们使用的是 sklearn 的聚类函数库，因此需要引用工具包，具体代码如下： 1from sklearn.cluster import KMeans 当然 K-Means 只是 sklearn.cluster 中的一个聚类库，实际上包括 K-Means 在内，sklearn.cluster 一共提供了 9 种聚类方法，比如 Mean-shift，DBSCAN，Spectral clustering（谱聚类）等。这些聚类方法的原理和 K-Means 不同，这里不做介绍。 K-Means 创建： 1KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm='auto') 我们能看到在 K-Means 类创建的过程中，有一些主要的参数： n_clusters : 即 K 值，一般需要多试一些 K 值来保证更好的聚类效果。你可以随机设置一些 K 值，然后选择聚类效果最好的作为最终的 K 值； max_iter ： 最大迭代次数，如果聚类很难收敛的话，设置最大迭代次数可以让我们及时得到反馈结果，否则程序运行时间会非常长； n_init ：初始化中心点的运算次数，默认是 10。程序是否能快速收敛和中心点的选择关系非常大，所以在中心点选择上多花一些时间，来争取整体时间上的快速收敛还是非常值得的。由于每一次中心点都是随机生成的，这样得到的结果就有好有坏，非常不确定，所以要运行 n_init 次, 取其中最好的作为初始的中心点。 如果 K 值比较大的时候，你可以适当增大 n_init 这个值； algorithm ：k-means 的实现算法，有“auto” “full”“elkan”三种。一般来说建议直接用默认的”auto”。简单说下这三个取值的区别，如果你选择”full”采用的是传统的 K-Means 算法，“auto”会根据数据的特点自动选择是选择“full”还是“elkan”。我们一般选择默认的取值，即“auto” 。 在创建好 K-Means 类之后，就可以使用它的方法，最常用的是 fit 和 predict 这个两个函数。你可以单独使用 fit 函数和 predict 函数，也可以合并使用 fit_predict 函数。其中 fit(data) 可以对data 数据进行 k-Means 聚类。 predict(data) 可以针对 data 中的每个样本，计算最近的类。 数据下载 1`# coding: utf-8``from` `sklearn.cluster ``import` `KMeans``from` `sklearn ``import` `preprocessing``import` `pandas as pd``import` `numpy as np``# 输入数据``data ``=` `pd.read_csv(``'data.csv'``, encoding``=``'gbk'``)``train_x ``=` `data[[``\"2019 年国际排名 \"``,``\"2018 世界杯 \"``,``\"2015 亚洲杯 \"``]]``df ``=` `pd.DataFrame(train_x)``kmeans ``=` `KMeans(n_clusters``=``3``)``# 规范化到 [0,1] 空间``min_max_scaler``=``preprocessing.MinMaxScaler()``train_x``=``min_max_scaler.fit_transform(train_x)``# kmeans 算法``kmeans.fit(train_x)``predict_y ``=` `kmeans.predict(train_x)``# 合并聚类结果，插入到原数据中``result ``=` `pd.concat((data,pd.DataFrame(predict_y)),axis``=``1``)``result.rename(&#123;``0``:u``'聚类'``&#125;,axis``=``1``,inplace``=``True``)``print``(result)` `# 运行结果：``国家 ``2019` `年国际排名 ``2018` `世界杯 ``2015` `亚洲杯 聚类``0` `中国 ``73` `40` `7` `2``1` `日本 ``60` `15` `5` `0``2` `韩国 ``61` `19` `2` `0``3` `伊朗 ``34` `18` `6` `0``4` `沙特 ``67` `26` `10` `0``5` `伊拉克 ``91` `40` `4` `2``6` `卡塔尔 ``101` `40` `13` `1``7` `阿联酋 ``81` `40` `6` `2``8` `乌兹别克斯坦 ``88` `40` `8` `2``9` `泰国 ``122` `40` `17` `1``10` `越南 ``102` `50` `17` `1``11` `阿曼 ``87` `50` `12` `1``12` `巴林 ``116` `50` `11` `1``13` `朝鲜 ``110` `50` `14` `1``14` `印尼 ``164` `50` `17` `1``15` `澳洲 ``40` `30` `1` `0``16` `叙利亚 ``76` `40` `17` `1``17` `约旦 ``118` `50` `9` `1``18` `科威特 ``160` `50` `15` `1``19` `巴勒斯坦 ``96` `50` `16` `1` 123456789101112131415161718192021 国家 2019年国际排名 2018世界杯 2015亚洲杯 聚类0 中国 73 40 7 01 日本 60 15 5 22 韩国 61 19 2 23 伊朗 34 18 6 24 沙特 67 26 10 25 伊拉克 91 40 4 06 卡塔尔 101 40 13 17 阿联酋 81 40 6 08 乌兹别克斯坦 88 40 8 09 泰国 122 40 17 110 越南 102 50 17 111 阿曼 87 50 12 112 巴林 116 50 11 113 朝鲜 110 50 14 114 印尼 164 50 17 115 澳洲 40 30 1 216 叙利亚 76 40 17 117 约旦 118 50 9 118 科威特 160 50 15 119 巴勒斯坦 96 50 16 1 如何区分K-Means和KNN这两种算法呢？刚学过K-Means和KNN算法的同学应该能知道两者的区别，但往往过了一段时间，就容易混淆。所以我们可以从三个维度来区分K-Means和KNN这两个算法： 首先，这两个算法解决数据挖掘的两类问题。K-Means是聚类算法，KNN是分类算法。 这两个算法分别是两种不同的学习方式。K-Means是非监督学习，也就是不需要事先给出分类标签，而KNN是有监督学习，需要我们给出训练数据的分类标识。 最后，K值的含义不同。K-Means中的K值代表K类。KNN中的K值代表K个最接近的邻居。 四、用KMeans对图像进行分割图像分割就是利用图像自身的信息，比如颜色、纹理、形状等特征进行划分，将图像分割成不同的区域，划分出来的每个区域就相当于是对图像中的像素进行了聚类。单个区域内的像素之间的相似度大，不同区域间的像素差异性大。这个特性正好符合聚类的特性，所以你可以把图像分割看成是将图像中的信息进行聚类。当然聚类只是分割图像的一种方式，除了聚类，我们还可以基于图像颜色的阈值进行分割，或者基于图像边缘的信息进行分割等。 将微信开屏封面进行分割 我们现在用 K-Means 算法对微信页面进行分割。微信开屏图如下所示： 我们先设定下聚类的流程，聚类的流程和分类差不多，如图所示： 在准备阶段里，我们需要对数据进行加载。 因为处理的是图像信息，我们除了要获取图像数据以外，还需要获取图像的尺寸和通道数，然后基于图像中每个通道的数值进行数据规范化。这里我们需要定义个函数 load_data，来帮我们进行图像加载和数据规范化。代码如下： 1234567891011121314151617181920# 加载图像，并对数据进行规范化def load_data(filePath): # 读文件 f = open(filePath,'rb') data = [] # 得到图像的像素值 img = image.open(f) # 得到图像尺寸 width, height = img.size for x in range(width): for y in range(height): # 得到点(x,y)的三个通道值，存入data c1, c2, c3 = img.getpixel((x, y)) data.append([c1, c2, c3]) f.close() # 采用Min-Max规范化 # np.mat()将[[,,],[,,],...]序列，转化为n*3数组矩阵 mm = preprocessing.MinMaxScaler() data = mm.fit_transform(data) return np.mat(data), width, height 因为 jpg 格式的图像是三个通道 (R,G,B)，也就是一个像素点具有 3 个特征值。这里我们用 c1、c2、c3 来获取平面坐标点 (x,y) 的三个特征值，特征值是在 0-255 之间。 为了加快聚类的收敛，我们需要采用 Min-Max 规范化对数据进行规范化。我们定义的 load_data 函数返回的结果包括了针对 (R,G,B) 三个通道规范化的数据，以及图像的尺寸信息。在定义好 load_data 函数后，我们直接调用就可以得到相关信息，代码如下： 12# 加载图像，得到规范化的结果img，以及图像尺寸img, width, height = load_data('../test_data/kmeans/weixin.jpg') 假设我们想要对图像分割成 2 部分，在聚类阶段，我们可以将聚类数设置为 2，这样图像就自动聚成 2 类。代码如下： 123456789101112131415# 用K-Means对图像进行2聚类kmeans =KMeans(n_clusters=2)kmeans.fit(img)label = kmeans.predict(img)# 将图像聚类结果，转化成图像尺寸的矩阵label = label.reshape([width, height])# 创建个新图像pic_mark，用来保存图像聚类的结果，并设置不同的灰度值pic_mark = image.new(\"L\", (width, height))for x in range(width): for y in range(height): # 根据类别设置图像灰度, 类别0 灰度值为255， 类别1 灰度值为127（label[x][y]=0/1 pic_mark.putpixel((x, y), int(256/(label[x][y]+1))-1)pic_mark.save(\"../test_data/kmeans/weixin_mark.jpg\", \"JPEG\") 代码中有一些参数，下面说一下这些参数的作用和设置方法： 我们使用了 fit 和 predict 这两个函数来做数据的训练拟合和预测，因为传入的参数是一样的，我们可以同时进行 fit 和 predict 操作，这样我们可以直接使用 fit_predict(data) 得到聚类的结果。得到聚类的结果 label 后，实际上是一个一维的向量，我们需要把它转化成图像尺寸的矩阵。label 的聚类结果是从 0 开始统计的，当聚类数为 2 的时候，聚类的标识 label=0 或者 1。 如果你想对图像聚类的结果进行可视化，直接看 0 和 1 是看不出来的，还需要将 0 和 1 转化为灰度值。灰度值一般是在 0-255 的范围内，我们可以将 label=0 设定为灰度值 255，label=1 设定为灰度值 127。具体方法是用 int(256/(label[x][y]+1))-1。可视化的时候，主要是通过设置图像的灰度值进行显示。所以我们把聚类 label=0 的像素点都统一设置灰度值为 255，把聚类 label=1 的像素点都统一设置灰度值为 127。原来图像的灰度值是在 0-255 之间，现在就只有 2 种颜色（也就是灰度为 255，和灰度 127）。 有了这些灰度信息，我们就可以用 image.new 创建一个新的图像，用 putpixel 函数对新图像的点进行灰度值的设置，最后用 save 函数保存聚类的灰度图像。这样你就可以看到聚类的可视化结果了，如下图所示： 如果我们想要分割成 16 个部分，该如何对不同分类设置不同的颜色值呢？这里需要用到 skimage 工具包，它是图像处理工具包。你需要使用 pip install scikit-image 来进行安装。 这段代码可以将聚类标识矩阵转化为不同颜色的矩阵： 12345678from skimage import color# 参数改为16，16聚类# kmeans = KMeans(n_clusters=16)# 将聚类标识矩阵转化为不同颜色的矩阵label_color = (color.label2rgb(label)*255).astype(np.uint8)label_color = label_color.transpose(1,0,2)images = image.fromarray(label_color)images.save('../test_data/kmeans/weixin_mark_color.jpg') 代码中，我使用 skimage 中的 label2rgb 函数来将 label 分类标识转化为颜色数值，因为我们的颜色值范围是[0,255]，所以还需要乘以 255 进行转化，最后再转化为 np.uint8 类型。unit8 类型代表无符号整数，范围是 0-255 之间。 得到颜色矩阵后，你可以把它输出出来，这时你发现输出的图像是颠倒的，原因可能是图像源拍摄的时候本身是倒置的。我们需要设置三维矩阵的转置，让第一维和第二维颠倒过来，也就是使用 transpose(1,0,2)，将原来的 (0,1,2）顺序转化为 (1,0,2) 顺序，即第一维和第二维互换。 最后我们使用 fromarray 函数，它可以通过矩阵来生成图片，并使用 save 进行保存。最后得到的分类标识颜色化图像是这样的： 刚才我们做的是聚类的可视化。如果我们想要看到对应的原图，可以将每个簇（即每个类别）的点的 RGB 值设置为该簇质心点的 RGB 值，也就是簇内的点的特征均为质心点的特征。 我给出了完整的代码，代码中，我可以把范围为 0-255 的数值投射到 1-256 数值之间，方法是对每个数值进行加 1，你可以自己来运行下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# -*- coding: utf-8 -*-# 使用K-means对图像进行聚类，并显示聚类压缩后的图像import numpy as npimport PIL.Image as imagefrom sklearn.cluster import KMeansfrom sklearn import preprocessingimport matplotlib.image as mpimg# 加载图像，并对数据进行规范化def load_data(filePath): # 读文件 f = open(filePath,'rb') data = [] # 得到图像的像素值 img = image.open(f) # 得到图像尺寸 width, height = img.size for x in range(width): for y in range(height): # 得到点(x,y)的三个通道值 c1, c2, c3 = img.getpixel((x, y)) data.append([(c1+1)/256.0, (c2+1)/256.0, (c3+1)/256.0]) f.close() return np.mat(data), width, height # 加载图像，得到规范化的结果imgData，以及图像尺寸img, width, height = load_data('../test_data/kmeans/weixin.jpg')# 用K-Means对图像进行16聚类kmeans =KMeans(n_clusters=16)label = kmeans.fit_predict(img)# 将图像聚类结果，转化成图像尺寸的矩阵label = label.reshape([width, height])# 前面代码和之前的一样，只是保存可视化图片部分不一样# 创建个新图像img，用来保存图像聚类压缩后的结果img=image.new('RGB', (width, height))for x in range(width): for y in range(height): c1 = kmeans.cluster_centers_[label[x, y], 0] c2 = kmeans.cluster_centers_[label[x, y], 1] c3 = kmeans.cluster_centers_[label[x, y], 2] img.putpixel((x, y), (int(c1*256)-1, int(c2*256)-1, int(c3*256)-1))img.save('../test_data/kmeans/weixin_new.jpg') 可以看到没有用到 sklearn 自带的 MinMaxScaler，而是自己写了 Min-Max 规范化的公式。这样做的原因是我们知道 RGB 每个通道的数值在[0,255]之间，所以我们可以用每个通道的数值 +1/256，这样数值就会在[0,1]之间。（用MinMaxScaler效果也是一样的） 对图像做了 Min-Max 空间变换之后，还可以对其进行反变换，还原出对应原图的通道值。对于点 (x,y)，我们找到它们所属的簇 label[x,y]，然后得到这个簇的质心特征，用 c1,c2,c3 表示： 123c1 = kmeans.cluster_centers_[label[x, y], 0]c2 = kmeans.cluster_centers_[label[x, y], 1]c3 = kmeans.cluster_centers_[label[x, y], 2] 因为 c1, c2, c3 对应的是数据规范化的数值，因此我们还需要进行反变换，即： 123c1=int(c1*256)-1c2=int(c2*256)-1c3=int(c3*256)-1 然后用 img.putpixel 设置点 (x,y) 反变换后得到的特征值。最后用 img.save 保存图像。 结果如下： 五、总结好了，写到这关于KMeans，就要结束了。 下面快速的回顾一下： 首先，通过足球队聚类的例子引出了KMeans聚类的工作原理，简单来说两步，你可以回忆回忆。 然后，通过KMeans实现了对图像分割的实战，另外我们还学习了如何在 Python 中如何对图像进行读写，具体的代码如下，上文中也有相应代码，你也可以自己对应下： 12345import PIL.Image as image# 得到图像的像素值img = image.open(f)# 得到图像尺寸width, height = img.size 这里会使用 PIL 这个工具包，它的英文全称叫 Python Imaging Library，顾名思义，它是 Python 图像处理标准库。同时我们也使用到了 skimage 工具包（scikit-image），它也是图像处理工具包。用过 Matlab 的同学知道，Matlab 处理起图像来非常方便。skimage 可以和它相媲美，集成了很多图像处理函数，其中对不同分类标识显示不同的颜色。在 Python 中图像处理工具包，我们用的是 skimage 工具包。 21.EM聚类EM 的英文是 Expectation Maximization，所以 EM 算法也叫最大期望算法。 先看一个简单的场景：假设你炒了一份菜，想要把它平均分到两个碟子里，该怎么分？ 很少有人用称对菜进行称重，再计算一半的分量进行平分。大部分人的方法是先分一部分到碟子 A 中，然后再把剩余的分到碟子 B 中，再来观察碟子 A 和 B 里的菜是否一样多，哪个多就匀一些到少的那个碟子里，然后再观察碟子 A 和 B 里的是否一样多……整个过程一直重复下去，直到份量不发生变化为止。 你能从这个例子中看到三个主要的步骤：初始化参数、观察预期、重新估计。首先是先给每个碟子初始化一些菜量，然后再观察预期，这两个步骤实际上就是期望步骤（Expectation）。如果结果存在偏差就需要重新估计参数，这个就是最大化步骤（Maximization）。这两个步骤加起来也就是 EM 算法的过程。 一、EM 算法的工作原理说到 EM 算法，我们先来看一个概念“最大似然”，英文是 Maximum Likelihood，Likelihood 代表可能性，所以最大似然也就是最大可能性的意思。 举个例子，有一男一女两个同学，现在要对他俩进行身高的比较，谁会更高呢？根据我们的经验，相同年龄下男性的平均身高比女性的高一些，所以男同学高的可能性会很大。这里运用的就是最大似然的概念。 最大似然估计，指的就是一件事情已经发生了，然后反推更有可能是什么因素造成的。还是用一男一女比较身高为例，假设有一个人比另一个人高，反推他可能是男性。最大似然估计是一种通过已知结果，估计参数的方法。 EM 算法和最大似然估计的关系：EM 算法是一种求解最大似然估计的方法，通过观测样本，来找出样本的模型参数。 再回过来看下分菜的这个例子，实际上最终我们想要的是碟子 A 和碟子 B 中菜的份量，你可以把它们理解为想要求得的 模型参数 。然后我们通过 EM 算法中的 E 步来进行观察，然后通过 M 步来进行调整 A 和 B 的参数，最后让碟子 A 和碟子 B 的参数不再发生变化为止。 实际我们遇到的问题，比分菜复杂。举个一个投掷硬币的例子，假设我们有 A 和 B 两枚硬币，我们做了 5 组实验，每组实验投掷 10 次，然后统计出现正面的次数，实验结果如下： 投掷硬币这个过程中存在隐含的数据，即我们事先并不知道每次投掷的硬币是 A 还是 B。假设我们知道这个隐含的数据，并将它完善，可以得到下面的结果： 我们现在想要求得硬币 A 和 B 出现正面次数的概率，可以直接求得： 而实际情况是我不知道每次投掷的硬币是 A 还是 B，那么如何求得硬币 A 和硬币 B 出现正面的概率呢？ 这里就需要采用 EM 算法的思想。 初始化参数。我们假设硬币 A 和 B 的正面概率（随机指定）是θA=0.5 和θB=0.9。 计算期望值。假设实验 1 投掷的是硬币 A，那么正面次数为 5 的概率为： 公式中的 C(10,5) 代表的是 10 个里面取 5 个的组合方式，也就是排列组合公式，0.5 的 5 次方乘以 0.5 的 5 次方代表的是其中一次为 5 次为正面，5 次为反面的概率，然后再乘以 C(10,5) 等于正面次数为 5 的概率。 假设实验 1 是投掷的硬币 B ，那么正面次数为 5 的概率为： 所以实验 1 更有可能投掷的是硬币 A。 然后我们对实验 2~5 重复上面的计算过程，可以推理出来硬币顺序应该是{A，A，B，B，A}。 这个过程实际上是通过假设的参数来估计未知参数，即“每次投掷是哪枚硬币”。 通过猜测的结果{A, A, B, B, A}来完善初始化的参数θA 和θB。 然后一直重复第二步和第三步，直到参数不再发生变化。 简单总结下上面的步骤，你能看出 EM 算法中的 E 步骤就是通过旧的参数来计算隐藏变量。然后在 M 步骤中，通过得到的隐藏变量的结果来重新估计参数。直到参数不再发生变化，得到我们想要的结果。 二、EM 聚类的工作原理上面你能看到 EM 算法最直接的应用就是求参数估计。如果我们把潜在类别当做隐藏变量，样本看做观察值，就可以把聚类问题转化为参数估计问题。这也就是 EM 聚类的原理。 相比于 K-Means 算法，EM 聚类更加灵活，比如下面这两种情况，K-Means 会得到下面的聚类结果。 因为 K-Means 是通过距离来区分样本之间的差别的，且每个样本在计算的时候只能属于一个分类，称之为是硬聚类算法。而 EM 聚类在求解的过程中，实际上每个样本都有一定的概率和每个聚类相关，叫做软聚类算法。 你可以把 EM 算法理解成为是一个框架，在这个框架中可以采用不同的模型来用 EM 进行求解。 常用的 EM 聚类有 GMM 高斯混合模型和 HMM 隐马尔科夫模型。GMM（高斯混合模型）聚类就是 EM 聚类的一种。比如上面这两个图，可以采用 GMM 来进行聚类。 E 步骤：和 K-Means 一样，我们事先知道聚类的个数，但是不知道每个样本分别属于哪一类。通常，我们可以假设样本是符合高斯分布的（也就是正态分布）。每个高斯分布都属于这个模型的组成部分（component），要分成 K 类就相当于是 K 个组成部分。这样我们可以先初始化每个组成部分的高斯分布的参数，然后再看来每个样本是属于哪个组成部分。这也就是 E 步骤。 M 步骤：再通过得到的这些隐含变量结果，反过来求每个组成部分高斯分布的参数，即 M 步骤。 反复 EM 步骤，直到每个组成部分的高斯分布参数不变为止。 这样也就相当于将样本按照 GMM 模型进行了 EM 聚类。 三、 如何使用 EM 工具包在 Python 中有第三方的 EM 算法工具包。由于 EM 算法是一个聚类框架，所以你需要明确你要用的具体算法，比如是采用 GMM 高斯混合模型，还是 HMM 隐马尔科夫模型。 我们主要讲解 GMM 的使用，在使用前你需要引入工具包： 1from sklearn.mixture import GaussianMixture 如何在 sklearn 中创建 GMM 聚类。 首先我们使用 gmm = GaussianMixture(n_components=1, covariance_type=‘full’, max_iter=100) 来创建 GMM 聚类，其中有几个比较主要的参数（GMM 类的构造参数比较多，我筛选了一些主要的进行讲解），我分别来讲解下： n_components：即高斯混合模型的个数，也就是我们要聚类的个数，默认值为 1。如果你不指定 n_components，最终的聚类结果都会为同一个值。 covariance_type：代表协方差类型。一个高斯混合模型的分布是由均值向量和协方差矩阵决定的，所以协方差的类型也代表了不同的高斯混合模型的特征。协方差类型有 4 种取值： covariance_type=full，代表完全协方差，也就是元素都不为 0； covariance_type=tied，代表相同的完全协方差； covariance_type=diag，代表对角协方差，也就是对角不为 0，其余为 0； covariance_type=spherical，代表球面协方差，非对角为 0，对角完全相同，呈现球面的特性。 max_iter：代表最大迭代次数，EM 算法是由 E 步和 M 步迭代求得最终的模型参数，这里可以指定最大迭代次数，默认值为 100。 创建完 GMM 聚类器之后，我们就可以传入数据让它进行迭代拟合。 我们使用 fit 函数，传入样本特征矩阵，模型会自动生成聚类器，然后使用 prediction=gmm.predict(data) 来对数据进行聚类，传入你想进行聚类的数据，可以得到聚类结果 prediction。 能看出来拟合训练和预测可以传入相同的特征矩阵，这是因为聚类是无监督学习，你不需要事先指定聚类的结果，也无法基于先验的结果经验来进行学习。只要在训练过程中传入特征值矩阵，机器就会按照特征值矩阵生成聚类器，然后就可以使用这个聚类器进行聚类了。 四、 如何用 EM 算法对王者荣耀数据进行聚类了解了 GMM 聚类工具之后，我们看下如何对王者荣耀的英雄数据进行聚类。 首先我们知道聚类的原理是“人以群分，物以类聚”。通过聚类算法把特征值相近的数据归为一类，不同类之间的差异较大，这样就可以对原始数据进行降维。通过分成几个组（簇），来研究每个组之间的特性。或者我们也可以把组（簇）的数量适当提升，这样就可以找到可以互相替换的英雄，比如你的对手选择了你擅长的英雄之后，你可以选择另一个英雄作为备选。 我们先看下数据长什么样子： 这里我们收集了 69 名英雄的 20 个特征属性，这些属性分别是最大生命、生命成长、初始生命、最大法力、法力成长、初始法力、最高物攻、物攻成长、初始物攻、最大物防、物防成长、初始物防、最大每 5 秒回血、每 5 秒回血成长、初始每 5 秒回血、最大每 5 秒回蓝、每 5 秒回蓝成长、初始每 5 秒回蓝、最大攻速和攻击范围等。 数据下载： https://github.com/cystanford/EM_data 。 现在我们需要对王者荣耀的英雄数据进行聚类，我们先设定项目的执行流程： 加载数据源； 在准备阶段，我们需要对数据进行探索，包括采用数据可视化技术，让我们对英雄属性以及这些属性之间的关系理解更加深刻，然后对数据质量进行评估，是否进行数据清洗，最后进行特征选择方便后续的聚类算法； 聚类阶段：选择适合的聚类模型，这里我们采用 GMM 高斯混合模型进行聚类，并输出聚类结果，对结果进行分析。 按照上面的步骤，我们来编写下代码。完整的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# -*- coding: utf-8 -*-import pandas as pdimport csvimport matplotlib.pyplot as pltimport seaborn as snsfrom sklearn.mixture import GaussianMixturefrom sklearn.preprocessing import StandardScaler# 数据加载，避免中文乱码问题data_ori = pd.read_csv('../test_data/EM_data/heros.csv', encoding='gb18030')features = [u'最大生命', u'生命成长', u'初始生命', u'最大法力', u'法力成长', u'初始法力', u'最高物攻', u'物攻成长', u'初始物攻',u'最大物防', u'物防成长', u'初始物防', u'最大每5秒回血', u'每5秒回血成长', u'初始每5秒回血', u'最大每5秒回蓝',u'每5秒回蓝成长', u'初始每5秒回蓝', u'最大攻速', u'攻击范围']data = data_ori[features]# 对英雄属性之间的关系进行可视化分析# 设置 plt 正确显示中文(我的matplotlib已经配置过，配置方法见前面可视化蜘蛛图那里)# plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签# plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号# 用热力图呈现 features_mean 字段之间的相关性# corr是DataFrame函数，相关系数，结合热力图使用，SVM分类实例中也有使用corr = data[features].corr()plt.figure(figsize=(14, 14))# annot=True 显示每个方格的数据sns.heatmap(corr, annot=True)plt.show()# 根据相关系数热力图，相关性大的属性保留一个，因此可以对属性进行降维features_remain = [u'最大生命', u'初始生命', u'最大法力', u'最高物攻', u'初始物攻', u'最大物防', u'初始物防', u'最大每 5 秒回血', u'最大每 5 秒回蓝', u'初始每 5 秒回蓝', u'最大攻速', u'攻击范围']data = data_ori[features_remain]# strip可以删除两边空格，这么用可以删除特殊符号data[u'最大攻速'] = data[u'最大攻速'].apply(lambda x: float(x.strip('%'))/100)data[u'攻击范围']=data[u'攻击范围'].map(&#123;'远程':1,'近战':0&#125;)# 采用 Z-Score 规范化数据，保证每个特征维度的数据均值为 0，方差为 1ss = StandardScaler()data = ss.fit_transform(data)# 构造 GMM 聚类gmm = GaussianMixture(n_components=30, covariance_type='full')gmm.fit(data)# 训练数据prediction = gmm.predict(data)print(prediction)# 将分组结果输出到 CSV 文件中# insert增加列，0插入位置data_ori.insert(0, '分组', prediction)data_ori.to_csv('./hero_out.csv', index=False, sep=',') 运行结果如下： 123[28 14 8 9 5 5 15 8 3 14 18 14 9 7 16 18 13 3 5 4 19 12 4 1212 12 4 17 24 2 7 2 2 24 2 2 24 6 20 22 22 24 24 2 2 22 14 2014 24 26 29 27 25 25 28 11 1 23 5 11 0 10 28 21 29 29 29 17] (每次聚类标号可能不同，但分类结果是一样的) 同时你也能看到输出的聚类结果文件 hero_out.csv（它保存在你本地运行的文件夹里，程序会自动输出这个文件，你可以自己看下）。 讲解下程序的几个模块。 数据可视化的探索 你能看到我们将 20 个英雄属性之间的关系用热力图呈现了出来，中间的数字代表两个属性之间的关系系数，最大值为 1，代表完全正相关，关系系数越大代表相关性越大。从图中你能看出来“最大生命”“生命成长”和“初始生命”这三个属性的相关性大，我们只需要保留一个属性即可。同理我们也可以对其他相关性大的属性进行筛选，保留一个。你在代码中可以看到，我用 features_remain 数组保留了特征选择的属性，这样就将原本的 20 个属性降维到了 13 个属性。 关于数据规范化 “最大攻速”这个属性值是百分数，不适合做矩阵运算，因此需要将百分数转化为小数。“攻击范围”这个字段的取值为远程或者近战，也不适合矩阵运算，将取值做个映射，用 1 代表远程，0 代表近战。然后采用 Z-Score 规范化，对特征矩阵进行规范化。 在聚类阶段 我们采用了 GMM 高斯混合模型，并将结果输出到 CSV 文件中。 这里将输出的结果截取了一段（设置聚类个数为 30）： 第一列代表的是分组（簇），我们能看到张飞、程咬金分到了一组，牛魔、白起是一组，老夫子自己是一组，达摩、典韦是一组。 聚类的特点是相同类别之间的属性值相近，不同类别的属性值差异大。因此如果你擅长用典韦这个英雄，不防试试达摩这个英雄。同样你也可以在张飞和程咬金中进行切换。这样就算你的英雄被别人选中了，你依然可以有备选的英雄可以使用。 聚类和分类不一样，聚类是无监督的学习方式，也就是我们没有实际的结果可以进行比对，所以聚类的结果评估不像分类准确率一样直观，那么有没有聚类结果的评估方式呢？这里我们可以采用 Calinski-Harabaz 指标，代码如下： 12from sklearn.metrics import calinski_harabaz_scoreprint(calinski_harabaz_score(data, prediction)) 指标分数越高，代表聚类效果越好，也就是相同类中的差异性小，不同类之间的差异性大。当然具体聚类的结果含义，我们需要人工来分析，也就是当这些数据被分成不同的类别之后，具体每个类表代表的含义。 另外聚类算法也可以作为其他数据挖掘算法的预处理阶段，这样我们就可以将数据进行降维了。 22.关联规则挖掘（Apriori、FP-Growth算法）一、 关联规则中的几个概念关联规则这个概念，最早是由 Agrawal 等人在 1993 年提出的。在 1994 年 Agrawal 等人又提出了基于关联规则的 Apriori 算法，至今 Apriori 仍是关联规则挖掘的重要算法。 关联规则挖掘可以让我们从数据集中发现项与项（item 与 item）之间的关系，它在我们的生活中有很多应用场景，“购物篮分析”就是一个常见的场景，这个场景可以从消费者交易记录中发掘商品与商品之间的关联关系，进而通过商品捆绑销售或者相关推荐的方式带来更多的销售量。所以说，关联规则挖掘是个非常有用的技术。 举一个超市购物的例子，下面是几名客户购买的商品列表： 支持度: 支持度是个百分比，它指的是某个商品组合出现的次数与总次数之间的比例。支持度越高，代表这个组合出现的频率越大。 在这个例子中，我们能看到“牛奶”出现了 4 次，那么这 5 笔订单中“牛奶”的支持度就是 4/5=0.8。 同样“牛奶 + 面包”出现了 3 次，那么这 5 笔订单中“牛奶 + 面包”的支持度就是 3/5=0.6。 置信度: 它指的就是当你购买了商品 A，会有多大的概率购买商品 B，在上面这个例子中： 置信度（牛奶→啤酒）=2/4=0.5，代表如果你购买了牛奶，有多大的概率会购买啤酒？ 置信度（啤酒→牛奶）=2/3=0.67，代表如果你购买了啤酒，有多大的概率会购买牛奶？ 我们能看到，在 4 次购买了牛奶的情况下，有 2 次购买了啤酒，所以置信度 (牛奶→啤酒)=0.5，而在 3 次购买啤酒的情况下，有 2 次购买了牛奶，所以置信度（啤酒→牛奶）=0.67。 所以说置信度是个条件概念，就是说在 A 发生的情况下，B 发生的概率是多少。 提升度: 我们在做商品推荐的时候，重点考虑的是提升度，因为提升度代表的是“商品 A 的出现，对商品 B 的出现概率提升的”程度。 还是看上面的例子，如果我们单纯看置信度 (可乐→尿布)=1，也就是说可乐出现的时候，用户都会购买尿布，那么当用户购买可乐的时候，我们就需要推荐尿布么？ 实际上，就算用户不购买可乐，也会直接购买尿布的，所以用户是否购买可乐，对尿布的提升作用并不大。我们可以用下面的公式来计算商品 A 对商品 B 的提升度： 提升度 (A→B)= 置信度 (A→B)/ 支持度 (B) 这个公式是用来衡量 A 出现的情况下，是否会对 B 出现的概率有所提升。 所以提升度有三种可能： 提升度 (A→B)&gt;1：代表有提升； 提升度 (A→B)=1：代表有没有提升，也没有下降； 提升度 (A→B)&lt;1：代表有下降。 二、 Apriori 的工作原理首先我们把上面案例中的商品用 ID 来代表，牛奶、面包、尿布、可乐、啤酒、鸡蛋的商品 ID 分别设置为 1-6，上面的数据表可以变为： Apriori 算法其实就是查找频繁项集 (frequent itemset) 的过程，所以首先我们需要定义什么是频繁项集。 频繁项集就是支持度大于等于最小支持度 (Min Support) 阈值的项集，所以小于最小值支持度的项目就是非频繁项集，而大于等于最小支持度的项集就是频繁项集。 项集这个概念，英文叫做 itemset，它可以是单个的商品，也可以是商品的组合。 再来看这个例子，假设我随机指定最小支持度是 50%，也就是 0.5，Apriori 算法是如何运算的。 首先，计算单个商品的支持度，也就是得到 K=1 项的支持度： 因为最小支持度是 0.5，所以商品 4、6 是不符合最小支持度的，不属于频繁项集，于是经过筛选商品的频繁项集就变成： 在这个基础上，将商品两两组合，得到 k=2 项的支持度： 再筛掉小于最小值支持度的商品组合，可以得到： 再将商品进行 K=3 项的商品组合，可以得到： 再筛掉小于最小值支持度的商品组合，可以得到： 到这里，模拟了一遍整个 Apriori 算法的流程，总结下 Apriori 算法的递归流程： K=1，计算 K 项集的支持度； 筛选掉小于最小支持度的项集； 如果项集为空，则对应 K-1 项集的结果为最终结果。 否则 K=K+1，重复 1-3 步。 三、 Apriori 的改进算法：FP-Growth 算法Apriori 在计算的过程中有以下几个缺点： 可能产生大量的候选集。因为采用排列组合的方式，把可能的项集都组合出来了； 每次计算都需要重新扫描数据集，来计算每个项集的支持度。 所以 Apriori 算法会浪费很多计算空间和计算时间，为此人们提出了 FP-Growth 算法，它的特点是： 创建了一棵 FP 树来存储频繁项集。在创建前对不满足最小支持度的项进行删除，减少了存储空间。我稍后会讲解如何构造一棵 FP 树； 整个生成过程只遍历数据集 2 次，大大减少了计算量。 所以在实际工作中，我们常用 FP-Growth 来做频繁项集的挖掘，下面我给你简述下 FP-Growth 的原理。 1. 创建项头表（item header table） 创建项头表的作用是为 FP 构建及频繁项集挖掘提供索引。 流程：先扫描一遍数据集，对于满足最小支持度的单个项（K=1 项集）按照支持度从高到低进行排序，这个过程中删除了不满足最小支持度的项。 项头表包括了项目、支持度，以及该项在 FP 树中的链表。初始的时候链表为空。 2. 构造 FP 树 FP 树的根节点记为 NULL 节点。 流程：需要再次扫描数据集，对于每一条数据，按照项头表中项目、支持度从高到低的顺序进行创建节点（也就是第一步中项头表中的排序结果），节点如果存在就将计数 count+1，如果不存在就进行创建。同时在创建的过程中，需要更新项头表的链表。（5个尿布订单中–&gt;4个牛奶订单中–&gt;3个面包订单，还有1个面包订单中–&gt;1个啤酒订单，还有1个啤酒，还有1个啤酒） 3. 通过 FP 树挖掘频繁项集 到这里，我们就得到了一个存储频繁项集的 FP 树，以及一个项头表。我们可以通过项头表来挖掘出每个频繁项集。 具体的操作会用到一个概念，叫“条件模式基”，它指的是以要挖掘的节点为叶子节点，自底向上求出 FP 子树，然后将 FP 子树的祖先节点设置为叶子节点之和。 我以“啤酒”的节点为例，从 FP 树中可以得到一棵 FP 子树，将祖先节点的支持度记为叶子节点之和，得到： 相比于原来的 FP 树，尿布和牛奶的频繁项集数减少了。这是因为我们求得的是以“啤酒”为节点的 FP 子树，也就是说，在频繁项集中一定要含有“啤酒”这个项。你可以再看下原始的数据，其中订单 1{牛奶、面包、尿布}和订单 5{牛奶、面包、尿布、可乐}并不存在“啤酒”这个项，所以针对订单 1，尿布→牛奶→面包这个项集就会从 FP 树中去掉，针对订单 5 也包括了尿布→牛奶→面包这个项集也会从 FP 树中去掉，所以你能看到以“啤酒”为节点的 FP 子树，尿布、牛奶、面包项集上的计数比原来少了 2。 条件模式基不包括“啤酒”节点，而且祖先节点如果小于最小支持度就会被剪枝，所以“啤酒”的条件模式基为空。 同理，我们可以求得“面包”的条件模式基为： 所以可以求得面包的频繁项集为{尿布，面包}，{尿布，牛奶，面包}。同样，我们还可以求得牛奶，尿布的频繁项集，这里就不再计算展示。 四、 使用 Apriori 工具包Apriori 虽然是十大算法之一，不过在 sklearn 工具包中并没有它，也没有 FP-Growth 算法。这里教你个方法，来选择 Python 中可以使用的工具包，你可以通过 https://pypi.org/ 搜索工具包。 这个网站提供的工具包都是 Python 语言的，能找到 8 个 Python 语言的 Apriori 工具包，具体选择哪个呢？建议你使用第二个工具包，即 efficient-apriori。后面会讲到为什么推荐这个工具包。 可以通过 pip install efficient-apriori 安装这个工具包。 （实际上pycharm可以直接安装） 然后看下如何使用它，核心的代码就是这一行： 1itemsets, rules = apriori(data, min_support, min_confidence) data 是我们要提供的数据集，它是一个 list 数组类型 min_support 参数为最小支持度，在 efficient-apriori 工具包中用 0 到 1 的数值代表百分比，比如 0.5 代表最小支持度为 50%。 min_confidence 是最小置信度，数值也代表百分比，比如 1 代表 100%。 接下来我们用这个工具包，跑一下前面讲到的超市购物的例子。下面是客户购买的商品列表： 具体实现的代码如下： 12345678910111213from efficient_apriori import apriori# 设置数据集data = [('牛奶', '面包', '尿布'), ('可乐', '面包', '尿布', '啤酒'), ('牛奶', '尿布', '啤酒', '鸡蛋'), ('面包', '牛奶', '尿布', '啤酒'), ('面包', '牛奶', '尿布', '可乐')]# 挖掘频繁项集和频繁规则itemsets, rules = apriori(data, min_support=0.5, min_confidence=1)print(itemsets)print(rules) 运行结果： 12&#123;1: &#123;(&apos;牛奶&apos;,): 4, (&apos;尿布&apos;,): 5, (&apos;面包&apos;,): 4, (&apos;啤酒&apos;,): 3&#125;, 2: &#123;(&apos;尿布&apos;, &apos;牛奶&apos;): 4, (&apos;尿布&apos;, &apos;面包&apos;): 4, (&apos;牛奶&apos;, &apos;面包&apos;): 3, (&apos;啤酒&apos;, &apos;尿布&apos;): 3&#125;, 3: &#123;(&apos;尿布&apos;, &apos;牛奶&apos;, &apos;面包&apos;): 3&#125;&#125;[&#123;牛奶&#125; -&gt; &#123;尿布&#125;, &#123;面包&#125; -&gt; &#123;尿布&#125;, &#123;啤酒&#125; -&gt; &#123;尿布&#125;, &#123;牛奶, 面包&#125; -&gt; &#123;尿布&#125;] 你能从代码中看出来，data 是个 List 数组类型，其中每个值都可以是一个集合。实际上你也可以把 data 数组中的每个值设置为 List 数组类型，比如： 12345data = [['牛奶','面包','尿布'], ['可乐','面包', '尿布', '啤酒'], ['牛奶','尿布', '啤酒', '鸡蛋'], ['面包', '牛奶', '尿布', '啤酒'], ['面包', '牛奶', '尿布', '可乐']] 两者的运行结果是一样的，efficient-apriori 工具包把每一条数据集里的项式都放到了一个集合中进行运算，并没有考虑它们之间的先后顺序。因为实际情况下，同一个购物篮中的物品也不需要考虑购买的先后顺序。 而其他的 Apriori 算法可能会因为考虑了先后顺序，出现计算频繁项集结果不对的情况。所以这里采用的是 efficient-apriori 这个工具包。 五、 挖掘导演是如何选择演员的在实际工作中，数据集是需要自己来准备的，比如我们要挖掘导演是如何选择演员的数据情况，但是并没有公开的数据集可以直接使用。因此我们需要使用之前讲到的 Python 爬虫进行数据采集。 不同导演选择演员的规则是不同的，因此我们需要先指定导演。数据源我们选用豆瓣电影。 采集的工作流程: 首先我们先在 https://movie.douban.com 搜索框中输入导演姓名，比如“宁浩”。 页面会呈现出来导演之前的所有电影，然后对页面进行观察，你能观察到以下几个现象： 页面默认是 15 条数据反馈，第一页会返回 16 条。因为第一条数据实际上这个导演的概览，你可以理解为是一条广告的插入，下面才是真正的返回结果。 每条数据的最后一行是电影的演出人员的信息，第一个人员是导演，其余为演员姓名。姓名之间用“/”分割。 有了这些观察之后，我们就可以编写抓取程序了。在代码讲解中你能看出这两点观察的作用。抓取程序的目的是为了生成宁浩导演（你也可以抓取其他导演）的数据集，结果会保存在 csv 文件中。完整的抓取代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# -*- coding: utf-8 -*-# 下载某个导演的电影数据集from efficient_apriori import apriorifrom lxml import etreeimport timefrom selenium import webdriverimport csvdriver = webdriver.Edge()# 设置想要下载的导演 数据集director = u'宁浩'# 写 CSV 文件file_name = './' + director + '.csv'base_url = 'https://movie.douban.com/subject_search?search_text='+director+'&amp;cat=1002&amp;start='out = open(file_name,'w', newline='', encoding='utf-8-sig')csv_write = csv.writer(out, dialect='excel')flags=[]# 下载指定页面的数据def download(request_url): driver.get(request_url) time.sleep(1) html = driver.find_element_by_xpath(\"//*\").get_attribute(\"outerHTML\") html = etree.HTML(html) # 设置电影名称，导演演员 的 XPATH movie_lists = html.xpath(\"/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='title']/a[@class='title-text']\") name_lists = html.xpath(\"/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='meta abstract_2']\") # 获取返回的数据个数 num = len(movie_lists) if num &gt; 15: # 第一页会有 16 条数据 # 默认第一个不是，所以需要去掉 movie_lists = movie_lists[1:] name_lists = name_lists[1:] for (movie, name_list) in zip(movie_lists, name_lists): # 会存在数据为空的情况 if name_list.text is None: continue # 显示下演员名称 print(name_list.text) names = name_list.text.split('/') # 判断导演是否为指定的 director if names[0].strip() == director and movie.text not in flags: # 将第一个字段设置为电影名称 names[0] = movie.text flags.append(movie.text) csv_write.writerow(names) print('OK') # 代表这页数据下载成功 print(num) if num &gt;= 14: # 有可能一页会有 14 个电影 # 继续下一页 return True else: # 没有下一页 return False # 开始的 ID 为 0，每页增加 15start = 0while start&lt;10000: # 最多抽取 1 万部电影 request_url = base_url + str(start) # 下载数据，并返回是否有下一页 flag = download(request_url) if flag: start = start + 15 else: breakout.close()print('finished') （此处爬虫未跑通，待学习FileNotFoundError: [Errno 2] No such file or directory: ‘MicrosoftWebDriver.exe’: ‘MicrosoftWebDriver.exe’） 代码中涉及到了几个模块，简单讲解： 在引用包这一段，使用 csv 工具包读写 CSV 文件，用 efficient_apriori 完成 Apriori 算法，用 lxml 进行 XPath 解析，time 工具包可以让我们在模拟后有个适当停留，代码中设置为 1 秒钟，等 HTML 数据完全返回后再进行 HTML 内容的获取。使用 selenium 的 webdriver 来模拟浏览器的行为。 在读写文件这一块，需要事先告诉 python 的 open 函数，文件的编码是 utf-8-sig（对应代码：encoding=‘utf-8-sig’），这是因为会用到中文，为了避免编码混乱。 编写 download 函数，参数传入要采集的页面地址（request_url）。针对返回的 HTML，需要用到之前讲到的 Chrome 浏览器的 XPath Helper 工具，来获取电影名称以及演出人员的 XPath。用页面返回的数据个数来判断当前所处的页面序号。如果数据个数 &gt;15，也就是第一页，第一页的第一条数据是广告，需要忽略。如果数据个数 =15，代表是中间页，需要点击“下一页”，也就是翻页。如果数据个数 &lt;15，代表最后一页，没有下一页。 在程序主体部分，设置 start 代表抓取的 ID，从 0 开始最多抓取 1 万部电影的数据（一个导演不会超过 1 万部电影），每次翻页 start 自动增加 15，直到 flag=False 为止，也就是不存在下一页的情况。 你可以模拟下抓取的流程，获得指定导演的数据，比如我上面抓取的宁浩的数据。这里需要注意的是，豆瓣的电影数据可能是不全的，但基本上够我们用。 有了数据之后，我们就可以用 Apriori 算法来挖掘频繁项集和关联规则，代码如下： 12345678910111213141516171819202122232425# -*- coding: utf-8 -*-from efficient_apriori import aprioriimport csvdirector = u'宁浩'file_name = './'+director+'.csv'lists = csv.reader(open(file_name, 'r', encoding='utf-8-sig'))# 数据加载data = []# 遍历获得[[,,],[,,]]# 遍历得到每一行for names in lists: name_new = [] # 遍历获得新的去除空格的每一行 for name in names: # 去掉演员数据中的空格 name_new.append(name.strip()) # 新的行[,,]存入data，但不要第一项电影名 data.append(name_new[1:]) # 挖掘频繁项集和关联规则itemsets, rules = apriori(data, min_support=0.5, min_confidence=1)print(itemsets)print(rules) 代码中使用的 apriori 方法和开头中用 Apriori 获取购物篮规律的方法类似，比如代码中都设定了最小支持度和最小置信系数，这样我们可以找到支持度大于 50%，置信系数为 1 的频繁项集和关联规则。 这是最后的运行结果： 12&#123;1: &#123;(&apos;徐峥&apos;,): 5, (&apos;黄渤&apos;,): 6&#125;, 2: &#123;(&apos;徐峥&apos;, &apos;黄渤&apos;): 5&#125;&#125;[&#123;徐峥&#125; -&gt; &#123;黄渤&#125;] 能看出来，宁浩导演喜欢用徐峥和黄渤，并且有徐峥的情况下，一般都会用黄渤。也可以用上面的代码来挖掘下其他导演选择演员的规律。 总结：实战最主要的是爬取数据，尤其是环境的搭建和最后编码部分。 算法有现成的包efficient-apriori 可以使用 Apriori 算法中的最小支持度和最小置信度，一般设置为多少比较合理？ 首先，这两个值与数据集大小特征相关。一般来说最小支持度常见的取值有0.5，0.1, 0.05。最小置信度常见的取值有1.0, 0.9, 0.8。可以通过尝试一些取值，然后观察关联结果的方式来调整最小值尺度和最小置信度的取值。 23.PageRank算法(重要性评估)大家一般都有从众心理： 比如，当你某一家饭店，或者理发店，或者小吃店里面的顾客非常多，每天爆满的时候，心理一定会想，这家店想必不错，要不然不可能这么多人，我也进去试试。 或者，在淘宝上买某个商品的时候，肯定是喜欢挑人多的店铺，好评量高的店铺买的放心等等吧。 所以当我们在生活中遇到艰难选择的时候，往往喜欢看看别人是怎么做的，一般都会选大部分人的选择。 这其实就是一种从众。 这些店铺也好，选择也罢，其实都是通过很多人的投票进而提高了自己的影响力，再比如说，微博上如何去衡量一个人的影响力呢？ 我们习惯看他的粉丝，如果他的粉丝多，并且里面都是一些大V，明星的话，很可能这个人的影响力会比较强。 再比如说，职场上如何衡量一个人的影响力呢？ 我们习惯看与他交往的人物， 如果和他交往的都是像马云，王健林，马化腾这样的人物，那么这个人的影响力估计也小不了。 再比如说，如何判断一篇论文好？ 我们习惯看他的引用次数，或者影响因子，高的论文就比较好等等。 但是你只知道吗？ 其实我们的这种方式就在用PageRank算法的思想了，只不过我们没有发觉罢了，所谓的算法来源于生活，并服务于生活就是这个道理。 PageRank原理PageRank来源：想必大家上网的时候，都用过搜索引擎，现在已经非常好用了，基本上输入关键词，都能找到匹配的内容，质量还不错。但在 1998 年之前，搜索引擎的体验并不好。早期的搜索引擎，会遇到下面的两类问题： 返回结果质量不高：搜索结果不考虑网页的质量，而是通过时间顺序进行检索；容易被人钻空子：搜索引擎是基于检索词进行检索的，页面中检索词出现的频次越高，匹配度越高，这样就会出现网页作弊的情况。有些网页为了增加搜索引擎的排名，故意增加某个检索词的频率。 基于这些缺陷，当时 Google 的创始人拉里·佩奇提出了 PageRank 算法，目的就是要找到优质的网页，这样 Google 的排序结果不仅能找到用户想要的内容，而且还会从众多网页中筛选出权重高的呈现给用户。其灵感就是论文影响力因子的启发。 PageRank的简化模型： 假设一共有 4 个网页 A、B、C、D。它们之间的链接信息如图所示： 首先先知道两个概念： 出链指的是链接出去的链接。入链指的是链接进来的链接。比如图中 A 有 2 个入链，3 个出链。 那么我们如何计算一个网页的影响力或者重要程度呢？ 简单来说，一个网页的影响力 = 所有入链集合的页面的加权影响力之和，用公式表示为： u 为待评估的页面，Bu 为页面 u 的入链集合。针对入链集合中的任意页面 v，它能给 u 带来的影响力是其自身的影响力 PR(v) 除以 v 页面的出链数量，即页面 v 把影响力 PR(v) 平均分配给了它的出链，这样统计所有能给 u 带来链接的页面 v，得到的总和就是网页 u 的影响力，即为 PR(u)。 所以你能看到，出链会给被链接的页面赋予影响力，当我们统计了一个网页链出去的数量，也就是统计了这个网页的跳转概率。 在这个例子中，你能看到 A 有三个出链分别链接到了 B、C、D 上。那么当用户访问 A 的时候，就有跳转到 B、C 或者 D 的可能性，跳转概率均为 1/3。 B 有两个出链，链接到了 A 和 D 上，跳转概率为 1/2。 这样，我们可以得到 A、B、C、D 这四个网页的转移矩阵 M： 这个转移矩阵，每一行代表了每个节点入链上的权重（大家浏览别的页面的时候，有多大的概率能跳到我这来）。 每一列代表了每个节点对其他页面的影响力的赋予程度（也就是大家浏览我这，有多大的概率跳到别的页面上去）。 我们假设 A、B、C、D 四个页面的初始影响力都是相同的，即： 当进行第一次转移之后，各页面的影响力 w1 变为： 然后我们再用转移矩阵乘以 w1 得到 w2 结果，直到第 n 次迭代后 wn 影响力不再发生变化，可以收敛到 (0.3333，0.2222，0.2222，0.2222），也就是对应着 A、B、C、D 四个页面最终平衡状态下的影响力。 能看出 A 页面相比于其他页面来说权重更大，也就是 PR 值更高。而 B、C、D 页面的 PR 值相等。 至此，我们模拟了一个简化的 PageRank 的计算过程，也就是PageRank简化模型的原理了。实际情况更复杂，可能有两个问题： 等级泄露（Rank Leak）：如果一个网页没有出链，就像是一个黑洞一样，吸收了其他网页的影响力而不释放，最终会导致其他网页的 PR 值为 0。 等级沉没（Rank Sink）：如果一个网页只有出链，没有入链（如下图所示），计算的过程迭代下来，会导致这个网页的 PR 值为 0（也就是不存在公式中的 V）。 那么如何有效解决呢？ PageRank 的随机浏览模型 为了解决简化模型中存在的等级泄露和等级沉没的问题，拉里·佩奇提出了 PageRank 的随机浏览模型。他假设了这样一个场景：用户并不都是按照跳转链接的方式来上网，还有一种可能是不论当前处于哪个页面，都有概率访问到其他任意的页面，比如说用户就是要直接输入网址访问其他页面，虽然这个概率比较小。 所以他定义了阻尼因子 d，这个因子代表了用户按照跳转链接来上网的概率，通常可以取一个固定值 0.85，而 1-d=0.15 则代表了用户不是通过跳转链接的方式来访问网页的，比如直接输入网址。 其中 N 为网页总数，这样我们又可以重新迭代网页的权重计算了，因为加入了阻尼因子 d，一定程度上解决了等级泄露和等级沉没的问题。 通过数学定理（这里不进行讲解）也可以证明，最终 PageRank 随机浏览模型是可以收敛的，也就是可以得到一个稳定正常的 PR 值。 PageRank实战使用工具实现PageRank算法 PageRank 算法工具在 sklearn 中并不存在，我们需要找到新的工具包。实际上有一个关于图论和网络建模的工具叫 NetworkX，它是用 Python 语言开发的工具，内置了常用的图与网络分析算法，可以方便我们进行网络数据分析。 上面举了一个网页权重的例子，假设一共有 4 个网页 A、B、C、D，它们之间的链接信息如图所示： 针对这个例子，我们看下用 NetworkX 如何计算 A、B、C、D 四个网页的 PR 值，具体代码如下： 12345678910111213import networkx as nx# 创建有向图G = nx.DiGraph() # 有向图之间边的关系edges = [(\"A\", \"B\"), (\"A\", \"C\"), (\"A\", \"D\"), (\"B\", \"A\"), (\"B\", \"D\"), (\"C\", \"A\"), (\"D\", \"B\"), (\"D\", \"C\")]for edge in edges: G.add_edge(edge[0], edge[1])pagerank_list = nx.pagerank(G, alpha=1)print(\"pagerank值是：\\n\", pagerank_list) 结果如下： 12pagerank值是： &#123;&apos;A&apos;: 0.33333396911621094, &apos;B&apos;: 0.22222201029459634, &apos;C&apos;: 0.22222201029459634, &apos;D&apos;: 0.22222201029459634&#125; 关键代码就nx.pagerank(G, alpha=1) 这一句话， 这里的alpha就是我们上面说的阻尼因子，代表用户按照跳转链接的概率。默认是0.85。这里是1，表示我们都是用跳转链接，不直接输入网址的那种。 好了，运行完这个例子之后，来看下 NetworkX 工具都有哪些常用的操作。 关于图的创建 图可以分为无向图和有向图，在 NetworkX 中分别采用不同的函数进行创建。无向图指的是不用节点之间的边的方向，使用 nx.Graph() 进行创建；有向图指的是节点之间的边是有方向的，使用 nx.DiGraph() 来创建。在上面这个例子中，存在 A→D 的边，但不存在 D→A 的边。 关于节点的增加、删除和查询 如果想在网络中增加节点，可以使用 G.add_node(‘A’) 添加一个节点，也可以使用 G.add_nodes_from([‘B’,‘C’,‘D’,‘E’]) 添加节点集合。 如果想要删除节点，可以使用 G.remove_node(node) 删除一个指定的节点，也可以使用 G.remove_nodes_from([‘B’,‘C’,‘D’,‘E’]) 删除集合中的节点。 查询节点：如果你想要得到图中所有的节点，就可以使用 G.nodes()，也可以用 G.number_of_nodes() 得到图中节点的个数。 关于边的增加、删除、查询 增加边与添加节点的方式相同，使用 G.add_edge(“A”, “B”) 添加指定的“从 A 到 B”的边，也可以使用 add_edges_from 函数从边集合中添加。我们也可以做一个加权图，也就是说边是带有权重的，使用add_weighted_edges_from 函数从带有权重的边的集合中添加。在这个函数的参数中接收的是 1 个或多个三元组[u,v,w]作为参数，u、v、w 分别代表起点、终点和权重。 另外，我们可以使用 remove_edge 函数和 remove_edges_from 函数删除指定边和从边集合中删除。 另外可以使用 edges() 函数访问图中所有的边，使用 number_of_edges() 函数得到图中边的个数。 以上是关于图的基本操作，如果我们创建了一个图，并且对节点和边进行了设置，就可以找到其中有影响力的节点，原理就是通过 PageRank 算法，使用 nx.pagerank(G) 这个函数，函数中的参数 G 代表创建好的图。 用 PageRank 揭秘希拉里邮件中的人物关系数据集下载：https://github.com/cystanford/PageRank 先了解下数据集： 整个数据集由三个文件组成：Aliases.csv，Emails.csv 和 Persons.csv，其中 Emails 文件记录了所有公开邮件的内容，发送者和接收者的信息。Persons 这个文件统计了邮件中所有人物的姓名及对应的 ID。因为姓名存在别名的情况，为了将邮件中的人物进行统一，我们还需要用 Aliases 文件来查询别名和人物的对应关系。 整个数据集包括了 9306 封邮件和 513 个人名，数据集还是比较大的。不过这一次我们不需要对邮件的内容进行分析，只需要通过邮件中的发送者和接收者（对应 Emails.csv 文件中的 MetadataFrom 和 MetadataTo 字段）来绘制整个关系网络。因为涉及到的人物很多，因此我们需要通过 PageRank 算法计算每个人物在邮件关系网络中的权重，最后筛选出来最有价值的人物来进行关系网络图的绘制。 了解了数据集和项目背景之后，我们来设计到执行的流程步骤： 首先我们需要加载数据源； 在准备阶段：我们需要对数据进行探索，在数据清洗过程中，因为邮件中存在别名的情况，因此我们需要统一人物名称。另外邮件的正文并不在我们考虑的范围内，只统计邮件中的发送者和接收者，因此我们筛选 MetadataFrom 和 MetadataTo 这两个字段作为特征。同时，发送者和接收者可能存在多次邮件往来，需要设置权重来统计两人邮件往来的次数。次数越多代表这个边（从发送者到接收者的边）的权重越高； 在挖掘阶段：我们主要是对已经设置好的网络图进行 PR 值的计算，但邮件中的人物有 500 多人，有些人的权重可能不高，我们需要筛选 PR 值高的人物，绘制出他们之间的往来关系。在可视化的过程中，我们可以通过节点的 PR 值来绘制节点的大小，PR 值越大，节点的绘制尺寸越大。 最终代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102# -*- coding: utf-8 -*-# 用 PageRank 挖掘希拉里邮件中的重要任务关系import pandas as pdimport networkx as nximport numpy as npfrom collections import defaultdictimport matplotlib.pyplot as plt# 数据加载emails = pd.read_csv(\"./input/Emails.csv\")# 读取别名文件# 得到别名人物字典aliases，别名：人物idfile = pd.read_csv(\"./input/Aliases.csv\")aliases = &#123;&#125;for index, row in file.iterrows(): aliases[row['Alias']] = row['PersonId']# 读取人名文件file = pd.read_csv(\"./input/Persons.csv\")persons = &#123;&#125;for index, row in file.iterrows(): persons[row['Id']] = row['Name']# 针对别名进行转换 def unify_name(name): # 姓名统一小写 name = str(name).lower() # 去掉, 和 @后面的内容 name = name.replace(\",\",\"\").split(\"@\")[0] # 别名转换 if name in aliases.keys(): return persons[aliases[name]] return name # 画网络图def show_graph(graph, layout='spring_layout'): # 使用 Spring Layout 布局，类似中心放射状 if layout == 'circular_layout': positions=nx.circular_layout(graph) else: positions=nx.spring_layout(graph) # 设置网络图中的节点大小，大小与 pagerank 值相关，因为 pagerank 值很小所以需要 *20000 nodesize = [x['pagerank']*20000 for v,x in graph.nodes(data=True)] # 设置网络图中的边长度 edgesize = [np.sqrt(e[2]['weight']) for e in graph.edges(data=True)] # 绘制节点 nx.draw_networkx_nodes(graph, positions, node_size=nodesize, alpha=0.4) # 绘制边 nx.draw_networkx_edges(graph, positions, edge_size=edgesize, alpha=0.2) # 绘制节点的 label nx.draw_networkx_labels(graph, positions, font_size=10) # 输出希拉里邮件中的所有人物关系图 plt.show()# 将寄件人和收件人的姓名进行规范化emails.MetadataFrom = emails.MetadataFrom.apply(unify_name)emails.MetadataTo = emails.MetadataTo.apply(unify_name)# 设置边的权重等于发邮件的次数# defaultdict(list)构建一个默认值为[]的字典edges_weights_temp = defaultdict(list)# zip获得以元组为元素的列表[(F,T,R),(F,T,R),...]# row为一个(F,T,R)，row[0]为F，row[1]为Tfor row in zip(emails.MetadataFrom, emails.MetadataTo, emails.RawText): temp = (row[0], row[1]) if temp not in edges_weights_temp: edges_weights_temp[temp] = 1 else: edges_weights_temp[temp] = edges_weights_temp[temp] + 1 # 转化格式 (from, to), weight =&gt; from, to, weightedges_weights = [(key[0], key[1], val) for key, val in edges_weights_temp.items()]# 创建一个有向图graph = nx.DiGraph()# 使用函数设置有向图中的路径及权重 (from, to, weight)graph.add_weighted_edges_from(edges_weights)# 计算每个节点（人）的 PR 值，并作为节点的 pagerank 属性pagerank = nx.pagerank(graph)# 将 pagerank 数值作为节点的属性nx.set_node_attributes(graph, name = 'pagerank', values=pagerank)# 画网络图show_graph(graph)# 将完整的图谱进行精简# 设置 PR 值的阈值，筛选大于阈值的重要核心节点pagerank_threshold = 0.005# 复制一份计算好的网络图small_graph = graph.copy()# 剪掉 PR 值小于 pagerank_threshold 的节点for n, p_rank in graph.nodes(data=True): if p_rank['pagerank'] &lt; pagerank_threshold: small_graph.remove_node(n)# 画网络图,采用circular_layout布局让筛选出来的点组成一个圆show_graph(small_graph, 'circular_layout')# 画网络图是为了展示，直接输出pagerank字典，不把graph画出来也可：pagerank_small = &#123;&#125;for key, val in pagerank.items(): if val &gt; 0.005: pagerank_small[key] = valprint(pagerank)print(pagerank_small) 整体框架看一下前面实战的小代码 运行结果： 简化前： 简化后： 针对代码中的几个模块个简单的说明： 函数定义 人物的名称需要统一，因此设置了 unify_name 函数，同时设置了 show_graph 函数将网络图可视化。NetworkX 提供了多种可视化布局，这里使用 spring_layout 布局，也就是呈中心放射状。 除了 spring_layout 外，NetworkX 还有另外三种可视化布局，circular_layout（在一个圆环上均匀分布节点），random_layout（随机分布节点 ），shell_layout（节点都在同心圆上）。 计算边权重 邮件的发送者和接收者的邮件往来可能不止一次，我们需要用两者之间邮件往来的次数计算这两者之间边的权重，所以用 edges_weights_temp 数组存储权重。而上面介绍过在 NetworkX 中添加权重边（即使用 add_weighted_edges_from 函数）的时候，接受的是 u、v、w 的三元数组，因此我们还需要对格式进行转换，具体转换方式见代码。 PR 值计算及筛选 使用 nx.pagerank(graph) 计算了节点的 PR 值。由于节点数量很多，我们设置了 PR 值阈值，即 pagerank_threshold=0.005，然后遍历节点，删除小于 PR 值阈值的节点，形成新的图 small_graph，最后对 small_graph 进行可视化（对应运行结果的第二张图）。 24.AdaBoost集成的含义就是集思广益，博取众长，当我们做决定的时候，我们先听取多个专家的意见，再做决定。集成算法通常用两种： 投票选举（bagging）和再学习（boosting）。 投票选举的场景类似把专家召集到一个会议桌前，当做一个决定的时候，让 K 个专家（K 个模型）分别进行分类（做出决定），然后选择出现次数最多的那个类（决定）作为最终的分类结果。（听说过伟大的随机森林吧，就是训练很多棵树，少数服从多数） 再学习相当于把 K 个专家（K 个分类器）进行加权融合，形成一个新的超级专家（强分类器），让这个超级专家做判断。（而伟大的AdaBoost就是这种方式） Boosting 的含义是提升，它的作用是每一次训练的时候都对上一次的训练进行改进提升，在训练的过程中这 K 个“专家”之间是有依赖性的，当引入第 K 个“专家”（第 K 个分类器）的时候，实际上是对前 K-1 个专家的优化。而 bagging 在做投票选举的时候可以并行计算，也就是 K 个“专家”在做判断的时候是相互独立的，不存在依赖性。 AdaBoost的工作原理AdaBoost算法是一种再学习的一种方式，英文全称是 Adaptive Boosting，中文含义是自适应提升算法。它由 Freund 等人于 1995 年提出，是对 Boosting 算法的一种实现。 什么是 Boosting 算法呢？Boosting 算法是集成算法中的一种，同时也是一类算法的总称。这类算法通过训练多个弱分类器，将它们组合成一个强分类器，也就是我们俗话说的“三个臭皮匠，顶个诸葛亮”。为什么要这么做呢？因为臭皮匠好训练，诸葛亮却不好求。因此要打造一个诸葛亮，最好的方式就是训练多个臭皮匠，然后让这些臭皮匠组合起来，这样往往可以得到很好的效果。这就是 Boosting 算法的原理。 可以用多个弱分类器来组合一个强分类器，这些弱分类器是根据不同的权重组合而成的。 假设弱分类器为 Gi(x)，它在强分类器中的权重 αi，那么就可以得出强分类器 f(x)： 这里有两个问题： 如何得到这些弱分类器，也就是在每次迭代训练的过程中，如何得到最优的弱分类器？ 每个弱分类器的权重是如何计算的？我们先来看一下第二个问题，如何计算权重？ 那第一感觉肯定是谁表现好，权重就越高啊。哈哈，还真是这样 实际上在一个由 K 个弱分类器中组成的强分类器中，如果弱分类器的分类效果好，那么权重应该比较大，如果弱分类器的分类效果一般，权重应该降低。所以我们需要基于这个弱分类器对样本的分类错误率来决定它的权重，用公式表示就是： 其中 ei 代表第 i 个分类器的分类错误率。 然后我们再来看下第一个问题，如何在每次训练迭代的过程中选择最优的弱分类器？ Adaboost是通过改变样本的数据分布来实现的，AdaBoost 会判断每次训练的样本是否正确分类，对于正确分类的样本，降低它的权重，对于被错误分类的样本，增加它的权重。再基于上一次得到的分类准确率，来确定这次训练样本中每个样本的权重。 然后将修改过权重的新数据集传递给下一层的分类器进行训练。这样做的好处就是，通过每一轮训练样本的动态权重，可以让训练的焦点集中到难分类的样本上，最终得到的弱分类器的组合更容易得到更高的分类准确率。 过程理解就是这样， 我的训练样本在开始的时候啊，都会有一个概率分布，也就是权重。比如n个样本，我假设每个样本的权重都是1/n，意味着同等重要， 但是我们训练出一个分类器A之后，如果这个分类器A能把之前的样本正确的分类，就说明这些正确分类的样本由A来搞定就可以了。 我们下一轮训练分类器B的时候就不需要太多的关注了，让B更多的去关注A分类错误的样本？ 那怎么做到这一点呢？ 那就把A分类正确的样本的权重减小，分类错误的样本的权重增大。这样，B在训练的时候，就能更加的关注这些错误样本了，因为一旦把这些样本分类错误，损失就会快速涨（权重大呀），为了使损失降低，B就尽可能的分类出这些A没有分出的样本，问题解决。那如果训练出来的B已经很好了，误差很小了，仍然有分不出来的怎么办？ 那同样的道理，把这些的权重增大，交给下一轮的C。 每一轮的分类器各有专长的。 怎么计算着每个样本的权重吧： 我们可以用 Dk+1 代表第 k+1 轮训练中，样本的权重集合，其中 Wk+1,1 代表第 k+1 轮中第一个样本的权重，以此类推 Wk+1,N 代表第 k+1 轮中第 N 个样本的权重，因此用公式表示为： 第 k+1 轮中的样本权重，是根据该样本在第 k 轮的权重以及第 k 个分类器的准确率而定，具体的公式为： 这个公式保证的就是，如果当前分类器把样本分类错误了，那么样本的w就会变大，如果分类正确了，w就会减小。 这里的Zk是归一化系数。就是∑ (wk,i exp(-αkyiGk(xi)) AdaBoost算法示例回忆一下，AdaBoost里面的两个问题： 如何得到这些弱分类器，也就是在每次迭代训练的过程中，如何得到最优的弱分类器？ — 改变样本的权重或者叫数据分布 每个弱分类器（士兵）的权重是如何计算的？ — 通过误差率和那个公式 看下面的例子，假设有10个训练样本： 想通过AdaBoost构建一个强分类器，怎么做呢？ 模拟一下： 首先，我得先给这10个样本划分重要程度，也就是权重，由于是一开始，那就平等，都是1/10。即初始权重D1=(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)。 假设我训练的3个基础分类器如下： 当然，这个是一次迭代训练一个，这里为了解释这个过程，先有这三个。 然后，我们进行第一轮的训练, 我们可以知道： 分类器 f1 的错误率为 0.3，也就是 x 取值 6、7、8 时分类错误； 分类器 f2 的错误率为 0.4，即 x 取值 0、1、2、9 时分类错误； 分类器 f3 的错误率为 0.3，即 x 取值为 3、4、5 时分类错误。 根据误差率最小，选择f1或者f3，我训练出一个分类器来如下(选择f1)： 这个分类器的错误率是0.3（x取值6, 7，8的时候分类错误），是误差率最低的了（怎么训练的？ 可以用一个决策树训练就可以啊）， 即e1 = 0.3 那么根据权重公式得到第一个弱分类器的权重： 然后，我们就得根据这个分类器，来更新我们的训练样本的权重了 根据这个公式，就可以计算权重矩阵为：D2=(0.0715, 0.0715, 0.0715, 0.0715, 0.0715, 0.0715, 0.1666, 0.1666, 0.1666, 0.0715)。 你会发现，6, 7, 8样本的权重变大了，其他的权重变小（这就意味着，下一个分类器训练的时候，重点关注6, 7, 8这三个样本，） 接着我们进行第二轮的训练，继续统计三个分类器的准确率，可以得到： 分类器 f1 的错误率为 0.1666 * 3，也就是 x 取值为 6、7、8 时分类错误。 分类器 f2 的错误率为 0.0715 * 4，即 x 取值为 0、1、2、9 时分类错误。 分类器 f3 的错误率为 0.0715 * 3，即 x 取值 3、4、5时分类错误。 在这 3 个分类器中，f3 分类器的错误率最低，因此我们选择 f3 作为第二轮训练的最优分类器，即： 根据分类器权重公式得到： 同样，我们对下一轮的样本更新求权重值 可以得到 D3=(0.0455,0.0455,0.0455,0.1667, 0.1667,0.01667,0.1060, 0.1060, 0.1060, 0.0455)。 你会发现， G2分类错误的3，4， 5这三个样本的权重变大了，说明下一轮的分类器重点在上三个样本上面。 接下来我们开始第三轮的训练, 我们继续统计三个分类器的准确率，可以得到：分类器 f1 的错误率为 0.1060 * 3，也就是 x 取值 6、7、8 时分类错误；分类器 f2 的错误率为 0.0455 * 4，即 x 取值为 0、1、2、9 时分类错误；分类器 f3 的错误率为 0.1667 * 3，即 x 取值 3、4、5 时分类错误。 在这 3 个分类器中，f2 分类器的错误率最低，因此我们选择 f2 作为第三轮训练的最优分类器，即： 我们根据分类器权重公式得到： 假设我们只进行 3 轮的训练，选择 3 个弱分类器，组合成一个强分类器，那么最终的强分类器 G(x) = 0.4236G1(x) + 0.6496G2(x)+0.7514G3(x)。 简单梳理就是： 确定初始样本的权重，然后训练分类器，根据误差最小，选择分类器，得到误差率，计算该分类器的权重然后根据该分类器的误差去重新计算样本的权重 进行下一轮训练，若不停止，就重复上述过程。 实际上AdaBoost算法是一个框架，你可以指定任意的分类器，通常我们可以采用CART分类器作为弱分类器。 AdaBoost算法的原理，可以把它理解为一种集成算法，通过训练不同的弱分类器，将这些弱分类器集成起来形成一个强分类器。在每一轮的训练中都会加入一个新的弱分类器，直到达到足够低的错误率或者达到指定的最大迭代次数为止。实际上每一次迭代都会引入一个新的弱分类器（这个分类器是每一次迭代中计算出来的，是新的分类器，不是事先准备好的）。 在弱分类器的集合中，你不必担心弱分类器太弱了。实际上它只需要比随机猜测的效果略好一些即可。如果随机猜测的准确率是50%的话，那么每个弱分类器的准确率只要大于50%就可用。AdaBoost的强大在于迭代训练的机制，这样通过K个“臭皮匠”的组合也可以得到一个“诸葛亮” （强分类器）。 当然在每一轮的训练中，我们都需要从众多“臭皮匠”中选择一个拔尖的，也就是这一轮训练评比中的最优“臭皮匠”，对应的就是错误率最低的分类器。当然每一轮的样本的权重都会发生变化，这样做的目的是为了让之前错误分类的样本得到更多概率的重复训练机会。 AdaBoost工具使用AdaBoost不仅可以用于分类问题，还可以用于回归问题。这个例子是一个回归问题。 如何使用AdaBoost工具 我们可以直接在 sklearn 中使用 AdaBoost。如果我们要用 AdaBoost 进行分类，需要在使用前引用代码： 1from sklearn.ensemble import AdaBoostClassifier 如果你看到了 Classifier 这个类，一般都会对应着 Regressor 类。AdaBoost 也不例外，回归工具包的引用代码如下： 1from sklearn.ensemble import AdaBoostRegressor 如何在sklearn中创建AdaBoost分类器： 分类的时候，需要这样的函数： 1AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None) 下面看看这些参数的含义： base_estimator：代表的是弱分类器。在 AdaBoost 的分类器和回归器中都有这个参数，在 AdaBoost 中默认使用的是决策树，一般我们不需要修改这个参数，当然你也可以指定具体的分类器。 n_estimators：算法的最大迭代次数，也是分类器的个数，每一次迭代都会引入一个新的弱分类器来增加原有的分类器的组合能力。默认是 50。 learning_rate：代表学习率，取值在 0-1 之间，默认是 1.0。如果学习率较小，就需要比较多的迭代次数才能收敛，也就是说学习率和迭代次数是有相关性的。当你调整 learning_rate 的时候，往往也需要调整 n_estimators 这个参数。 algorithm：代表我们要采用哪种 boosting 算法，一共有两种选择：SAMME 和 SAMME.R。默认是 SAMME.R。这两者之间的区别在于对弱分类权重的计算方式不同。 random_state：代表随机数种子的设置，默认是 None。随机种子是用来控制随机模式的，当随机种子取了一个值，也就确定了一种随机规则，其他人取这个值可以得到同样的结果。如果不设置随机种子，每次得到的随机数也就不同。 如何创建AdaBoost回归： 1AdaBoostRegressor(base_estimator=None, n_estimators=50, learning_rate=1.0, loss=‘linear’, random_state=None) 回归和分类的参数基本是一致的，不同点在于回归算法里没有 algorithm 这个参数，但多了一个 loss 参数。 loss 代表损失函数的设置，一共有 3 种选择，分别为 linear、square 和 exponential，它们的含义分别是线性、平方和指数。默认是线性。一般采用线性就可以得到不错的效果。 创建好 AdaBoost 分类器或回归器之后，我们就可以输入训练集对它进行训练。 我们使用 fit 函数，传入训练集中的样本特征值 train_X 和结果 train_y，模型会自动拟合。使用 predict 函数进行预测，传入测试集中的样本特征值 test_X，然后就可以得到预测结果。 用AdaBoost对房价进行预测我们使用sklearn自带的波士顿房价数据集，用AdaBoost对房价进行预测: 数据集 这个数据集一共包括了 506 条房屋信息数据，每一条数据都包括了 13 个指标，以及一个房屋价位。 13 个指标的含义，可以参考下面的表格： 处理思路（还是之前的处理套路）： 首先加载数据，将数据分割成训练集和测试集，然后创建 AdaBoost 回归模型，传入训练集数据进行拟合，再传入测试集数据进行预测，就可以得到预测结果。最后将预测的结果与实际结果进行对比，得到两者之间的误差。 代码如下： 123456789101112131415161718from sklearn.model_selection import train_test_splitfrom sklearn.metrics import mean_squared_errorfrom sklearn.datasets import load_bostonfrom sklearn.ensemble import AdaBoostRegressor# 加载数据data=load_boston()# 分割数据，样本特征值 train_X 、结果 train_ytrain_x, test_x, train_y, test_y = train_test_split(data.data, data.target, test_size=0.25, random_state=33)# 使用AdaBoost回归模型regressor=AdaBoostRegressor()regressor.fit(train_x,train_y)pred_y = regressor.predict(test_x)mse = mean_squared_error(test_y, pred_y)print(\"房价预测结果 \", pred_y)print(\"均方误差 = \",round(mse,2)) 运行结果： 1234567891011121314151617181920212223房价预测结果 [19.5862069 10.36744186 13.8556962 17.01666667 24.83653846 21.57818182 30.08265306 18.39166667 30.10983607 19.64464286 30.08265306 32.53333333 11.72571429 24.6871345 11.81971831 24.83653846 17.66141304 16.88518519 27.9 26.12291667 17.66141304 17.9525 18.32222222 19.15945946 31.02606061 18.32222222 21.57818182 24.83653846 11.81971831 30.45185185 17.66141304 26.638 10.36744186 20.55242718 26.638 30.94375 26.638 11.77142857 13.83246753 25.07005076 14.15901639 12.56393443 30.08265306 17.1 27.12684211 19.15945946 18.39166667 19.15260417 26.97983539 19.5862069 17.01666667 32.47894737 14.61836735 17.1 25.45376344 20.41842105 25.45376344 17.01666667 26.12291667 21.91229947 18.6962963 16.88518519 44.09285714 20.55242718 17.66141304 26.638 26.43482587 11.77142857 18.41923077 28.12891566 21.39473684 18.41923077 17.66141304 27.4728 19.32111111 45.16666667 15.78985507 11.72571429 18.32222222 24.51157895 19.80408163 14.93108108 12.56393443 26.43482587 20.55242718 20.76607143 46.96666667 17.1 44.10952381 31.2862069 30.10983607 19.15260417 18.6962963 17.9525 15.78985507 32.74782609 24.6 21.91229947 18.39166667 18.39166667 15.78985507 19.5862069 27.15679012 26.43482587 12.12727273 14.61836735 11.72571429 27.12684211 12.12727273 26.638 50. 12.69545455 17.26136364 26.43482587 30.94375 24.6871345 21.77692308 19.80408163 27.7 20.76607143 19.80408163 18.0516129 11.81971831 20.14333333 21.2 17.26136364 42.44 ]均方误差 = 17.89 这个数据集比较规范，不需要在数据清洗、规范化上花太多精力，代码简单 AdaBoost与回归分析模型比较下面对比一下决策树回归和KNN回归 12345678910111213# 使用决策树回归模型dec_regressor=DecisionTreeRegressor()dec_regressor.fit(train_x,train_y)pred_y = dec_regressor.predict(test_x)mse = mean_squared_error(test_y, pred_y)print(\"决策树均方误差 = \",round(mse,2))# 使用KNN回归模型knn_regressor=KNeighborsRegressor()knn_regressor.fit(train_x,train_y)pred_y = knn_regressor.predict(test_x)mse = mean_squared_error(test_y, pred_y)print(\"KNN均方误差 = \",round(mse,2)) 运行结果： 12决策树均方误差 = 23.84KNN均方误差 = 27.87 这里就会发现，AdaBoost 的均方误差更小，也就是结果更优。虽然 AdaBoost 使用了弱分类器，但是通过 50 个甚至更多的弱分类器组合起来而形成的强分类器，在很多情况下结果都优于其他算法。因此 AdaBoost 也是常用的分类和回归算法之一。 AdaBoost与决策树模型的比较在 sklearn 中 AdaBoost 默认采用的是决策树模型，我们可以随机生成一些数据，然后对比下 AdaBoost 中的弱分类器（也就是决策树弱分类器）、决策树分类器和 AdaBoost 模型在分类准确率上的表现。 如果想要随机生成数据，我们可以使用 sklearn 中的 make_hastie_10_2 函数生成二分类数据。假设我们生成 12000 个数据，取前 2000 个作为测试集，其余作为训练集。 设置AdaBoost迭代次数为200，错误率可视化： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import numpy as npimport matplotlib.pyplot as pltfrom sklearn import datasetsfrom sklearn.metrics import zero_one_lossfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.ensemble import AdaBoostClassifier# 设置AdaBoost迭代次数n_estimators=200# 数据X,y=datasets.make_hastie_10_2(n_samples=12000,random_state=1)# 从12000个数据中取前2000行作为测试集，其余作为训练集train_x, train_y = X[2000:],y[2000:]test_x, test_y = X[:2000],y[:2000]# AdaBoost 中的弱分类器（也就是决策树弱分类器）dt_stump = DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)dt_stump.fit(train_x, train_y)dt_stump_err = 1.0-dt_stump.score(test_x, test_y)# 决策树分类器dt = DecisionTreeClassifier()dt.fit(train_x, train_y)dt_err = 1.0-dt.score(test_x, test_y)# AdaBoost分类器ada = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=n_estimators)ada.fit(train_x, train_y)# 三个分类器的错误率可视化fig = plt.figure()# 设置plt正确显示中文plt.rcParams['font.sans-serif'] = ['SimHei']ax = fig.add_subplot(111)ax.plot([1,n_estimators],[dt_stump_err]*2, 'k-', label=u'决策树弱分类器 错误率')ax.plot([1,n_estimators],[dt_err]*2,'k--', label=u'决策树模型 错误率')ada_err = np.zeros((n_estimators,))# 遍历每次迭代的结果 i为迭代次数, pred_y为预测结果for i,pred_y in enumerate(ada.staged_predict(test_x)): # 统计错误率 ada_err[i]=zero_one_loss(pred_y, test_y)# 绘制每次迭代的AdaBoost错误率 ax.plot(np.arange(n_estimators)+1, ada_err, label='AdaBoost Test 错误率', color='orange')ax.set_xlabel('迭代次数')ax.set_ylabel('错误率')leg=ax.legend(loc='upper right',fancybox=True)plt.show() 运行结果： 从图中你能看出来，弱分类器的错误率最高，只比随机分类结果略好，准确率稍微大于 50%。决策树模型的错误率明显要低很多。而 AdaBoost 模型在迭代次数超过 25 次之后，错误率有了明显下降，经过 125 次迭代之后错误率的变化形势趋于平缓。 因此我们能看出，虽然单独的一个决策树弱分类器效果不好，但是多个决策树弱分类器组合起来形成的 AdaBoost 分类器，分类效果要好于决策树模型。 AdaBoost现在用的不多了，无论是打比赛还是日常应用，都喜欢用xgboost，lightgbm，catboost这些算法了。 当然，虽然学习的深入，这些算法肯定也会大白话出来。 但是出来之前，还是先搞懂AdaBoost的原理吧，这样也好对比，而对比，印象也就越深刻。 25.曲线拟合12345678910111213141516171819202122232425262728293031323334import numpy as npimport matplotlib.pyplot as plt# 定义x、y散点坐标x = np.arange(3200, 35000, 3200)num1 = [0.472, 0.469, 0.447, 0.433, 0.418, 0.418, 0.418, 0.418, 0.418, 0.418]num2 = [0.337, 0.327, 0.325, 0.316, 0.312, 0.311, 0.308, 0.305, 0.295, 0.290]y1 = np.array(num1)y2 = np.array(num2)# 用3次多项式拟合f1 = np.polyfit(x, y1, 3)p1 = np.poly1d(f1)print(p1) # 打印出拟合函数yvals1 = p1(x) # 拟合y值f2 = np.polyfit(x, y2, 3)p2 = np.poly1d(f2)print(p2)# 也可使用yvals=np.polyval(f1, x)yvals2 = p2(x)# 绘图plot1 = plt.plot(x, y1, 's', label='original values')plot2 = plt.plot(x, yvals1, 'r', label='polyfit values')plot3 = plt.plot(x, y2, 's', label='original values2')plot4 = plt.plot(x, yvals2, 'r', label='polyfit values2')plt.xlabel('x')plt.ylabel('y')plt.legend(loc=2, bbox_to_anchor=(1.05, 1.0), borderaxespad=0.)plt.title('polyfitting')plt.savefig('nihe1.png')plt.show() 26.DBSCAN聚类DBSCAN(Density-Based Spatial Clustering of Applications with Noise，具有噪声的基于密度的聚类方法)是一种很典型的密度聚类算法，和K-Means，BIRCH这些一般只适用于凸样本集的聚类相比，DBSCAN既可以适用于凸样本集，也可以适用于非凸样本集。下面我们就DBSCAN算法的原理做一个总结。 一、密度聚类原理DBSCAN是一种基于密度的聚类算法，这类密度聚类算法一般假定：类别可以通过样本分布的紧密程度决定。同一类别的样本，他们之间的紧密相连的，也就是说，在该类别任意样本周围不远处一定有同类别的样本存在。 通过将紧密相连的样本划为一类，这样就得到了一个聚类类别。通过将所有各组紧密相连的样本划为各个不同的类别，则我们就得到了最终的所有聚类类别结果。 二、DBSCAN密度定义DBSCAN是如何描述密度聚类的。 DBSCAN是基于一组邻域来描述样本集的紧密程度的，参数(ϵ, MinPts)用来描述邻域的样本分布紧密程度。其中，ϵ描述了某一样本的邻域距离阈值，MinPts描述了某一样本的距离为ϵ的邻域中样本个数的阈值。 假设样本集是D=(x1,x2,…,xm)，则DBSCAN具体的密度描述定义如下： ϵ-邻域：对于xj∈D，其ϵ-邻域包含样本集D中，与xj的距离不大于ϵ的子样本集，即Nϵ(xj)={xi∈D|distance(xi,xj)≤ϵ}, 这个子样本集的个数记为|Nϵ(xj)| 核心对象：对于某一样本xj∈D，如果其ϵ-邻域对应的Nϵ(xj)至少包含MinPts个样本，即如果|Nϵ(xj)|≥MinPts，则xj是核心对象。 密度直达：如果xi位于xj的ϵ-邻域中，且xj是核心对象，则称xi由xj密度直达。注意反之不一定成立，即此时不能说xj由xi密度直达, 除非且xi也是核心对象。 密度可达：对于xi和xj,如果存在样本样本序列p1,p2,…,pT,满足p1=xi,pT=xj, 且pt+1由pt密度直达，则称xj由xi密度可达。也就是说，密度可达满足传递性。此时序列中的传递样本p1,p2,…,pT−1均为核心对象，因为只有核心对象才能使其他样本密度直达。注意密度可达也不满足对称性，这个可以由密度直达的不对称性得出。 密度相连：对于xi和xj，如果存在核心对象样本xk，使xi和xj均由xk密度可达，则称xi和xj密度相连。注意密度相连关系是满足对称性的。 从下图可以很容易看出理解上述定义，图中MinPts=5，红色的点都是核心对象，因为其ϵ-邻域至少有5个样本。黑色的样本是非核心对象。所有核心对象密度直达的样本在以红色核心对象为中心的超球体内，如果不在超球体内，则不能密度直达。图中用绿色箭头连起来的核心对象组成了密度可达的样本序列。在这些密度可达的样本序列的ϵ-邻域内所有的样本相互都是密度相连的。 三、DBSCAN密度聚类思想DBSCAN的聚类定义很简单：由密度可达关系导出的最大密度的相连样本集合，即为我们最终聚类的一个类别，或者说一个簇。 这个DBSCAN的簇里面可以有一个或者多个核心对象。如果只有一个核心对象，则簇里其他的非核心对象样本都在这个核心对象的ϵ-邻域里；如果有多个核心对象，则簇里的任意一个核心对象的ϵ-邻域中一定有一个其他的核心对象，否则这两个核心对象无法密度可达。这些核心对象的ϵ-邻域里所有的样本的集合组成的一个DBSCAN聚类簇。 那么怎么才能找到这样的簇样本集合呢？DBSCAN使用的方法很简单，它任意选择一个没有类别的核心对象作为种子，然后找到所有这个核心对象能够密度可达的样本集合，即为一个聚类簇。接着继续选择另一个没有类别的核心对象去寻找密度可达的样本集合，这样就得到另一个聚类簇。一直运行到所有核心对象都有类别为止。 基本上这就是DBSCAN算法的主要内容了，是不是很简单？但是我们还是有三个问题没有考虑： 第一个是一些异常样本点或者说少量游离于簇外的样本点，这些点不在任何一个核心对象在周围，在DBSCAN中，我们一般将这些样本点标记为噪音点。 第二个是距离的度量问题，即如何计算某样本和核心对象样本的距离。在DBSCAN中，一般采用最近邻思想，采用某一种距离度量来衡量样本距离，比如欧式距离。这和KNN分类算法的最近邻思想完全相同。对应少量的样本，寻找最近邻可以直接去计算所有样本的距离，如果样本量较大，则一般采用KD树或者球树来快速的搜索最近邻。概念参考KNN算法 第三种问题比较特殊，某些样本可能到两个核心对象的距离都小于ϵ，但是这两个核心对象由于不是密度直达，又不属于同一个聚类簇，那么如果界定这个样本的类别呢？一般来说，此时DBSCAN采用先来后到，先进行聚类的类别簇会标记这个样本为它的类别。也就是说DBSCAN的算法不是完全稳定的算法。 四、DBSCAN聚类算法下面对DBSCAN聚类算法的流程做一个总结： 输入：样本集D=(x1,x2,…,xm)，邻域参数(ϵ,MinPts), 样本距离度量方式 输出： 簇划分C. 初始化核心对象集合Ω=∅, 初始化聚类簇数k=0，初始化未访问样本集合Γ = D, 簇划分C = ∅ 对于j=1,2,…m, 按下面的步骤找出所有的核心对象： a) 通过距离度量方式，找到样本xj的ϵ-邻域子样本集Nϵ(xj) b) 如果子样本集样本个数满足|Nϵ(xj)|≥MinPts， 将样本xj加入核心对象样本集合：Ω=Ω∪{xj} 如果核心对象集合Ω=∅，则算法结束， 否则转入步骤4。 在核心对象集合Ω中，随机选择一个核心对象o，初始化当前簇核心对象队列Ωcur={o}, 初始化类别序号k=k+1，初始化当前簇样本集合Ck={o}，更新未访问样本集合Γ=Γ−{o} 如果当前簇核心对象队列Ωcur=∅，则当前聚类簇Ck生成完毕, 更新簇划分C={C1,C2,…,Ck}, 更新核心对象集合Ω=Ω−Ck， 转入步骤3。 否则更新核心对象集合Ω=Ω−Ck。 在当前簇核心对象队列Ωcur中取出一个核心对象o′，通过邻域距离阈值ϵ找出所有的ϵ-邻域子样本集Nϵ(o′)，令Δ=Nϵ(o′)∩Γ, 更新当前簇样本集合Ck=Ck∪Δ, 更新未访问样本集合Γ=Γ−Δ, 更新Ωcur=Ωcur∪(Δ∩Ω)−o′，转入步骤5. 输出结果为： 簇划分C={𝐶1,𝐶2,…,𝐶𝑘} 五、小结优缺点和传统的K-Means算法相比，DBSCAN较大的不同就是不需要输入类别数k，当然它较大的优势是可以发现任意形状的聚类簇，而不是像K-Means，一般仅仅使用于凸的样本集聚类。同时它在聚类的同时还可以找出异常点，这点和BIRCH算法类似。 那么我们什么时候需要用DBSCAN来聚类呢？一般来说，如果数据集是稠密的，并且数据集不是凸的，那么用DBSCAN会比K-Means聚类效果好很多。如果数据集不是稠密的，则不推荐用DBSCAN来聚类。 下面对DBSCAN算法的优缺点做一个总结。 DBSCAN的主要优点有： 1） 可以对任意形状的稠密数据集进行聚类，相对的，K-Means之类的聚类算法一般只适用于凸数据集。 2） 可以在聚类的同时发现异常点，对数据集中的异常点不敏感。 3） 聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。 DBSCAN的主要缺点有： 1）如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。 2） 如果样本集较大时，聚类收敛时间较长，此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改进。 3） 调参相对于传统的K-Means之类的聚类算法稍复杂，主要需要对距离阈值ϵϵ，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响。 要判断样本集是不是凸样本集比较难。一般的做法是对kmeans，使用不同的k和不同的初始值进行聚类如果效果总是很差，很可能就是因为不是凸集的原因。这是可以换dbscan之类的方法做尝试，如果效果比较好基本就是这个问题了。 六、scikit-learn中的DBSCANscikit-learn中的DBSCAN类在scikit-learn中，DBSCAN算法类为sklearn.cluster.DBSCAN。要熟练的掌握用DBSCAN类来聚类，除了对DBSCAN本身的原理有较深的理解以外，还要对最近邻的思想有一定的理解。集合这两者，就可以玩转DBSCAN了。 DBSCAN类重要参数DBSCAN类的重要参数也分为两类，一类是DBSCAN算法本身的参数，一类是最近邻度量的参数，下面对这些参数做一个总结。 eps： DBSCAN算法参数，即ϵ-邻域的距离阈值，和样本距离超过ϵ的样本点不在ϵ-邻域内。默认值是0.5.一般需要通过在多组值里面选择一个合适的阈值。eps过大，则更多的点会落在核心对象的ϵ-邻域，此时我们的类别数可能会减少， 本来不应该是一类的样本也会被划为一类。反之则类别数可能会增大，本来是一类的样本却被划分开。 min_samples： DBSCAN算法参数，即样本点要成为核心对象所需要的ϵ-邻域的样本数阈值。默认值是5。一般需要通过在多组值里面选择一个合适的阈值。通常和eps一起调参。在eps一定的情况下，min_samples过大，则核心对象会过少，此时簇内部分本来是一类的样本可能会被标为噪音点，类别数也会变多。反之min_samples过小的话，则会产生大量的核心对象，可能会导致类别数过少。 metric：最近邻距离度量参数。可以使用的距离度量较多，一般来说DBSCAN使用默认的欧式距离（即p=2的闵可夫斯基距离）就可以满足我们的需求。可以使用的距离度量参数有： a) 欧式距离 “euclidean”: $\\sqrt{\\sum\\limits_{i=1}^{n}(x_i-y_i)^2}$ b) 曼哈顿距离 “manhattan”： $\\sum\\limits_{i=1}^{n}|x_i-y_i|$ c) 切比雪夫距离“chebyshev”: $max|x_i-y_i| (i = 1,2,…n)$ d) 闵可夫斯基距离 “minkowski”: $\\sqrt[p]{\\sum\\limits_{i=1}^{n}(|x_i-y_i|)^p}$ p=1为曼哈顿距离， p=2为欧式距离。 e) 带权重闵可夫斯基距离 “wminkowski”: $\\sqrt[p]{\\sum\\limits_{i=1}^{n}(w*|x_i-y_i|)^p}$ 其中w为特征权重 f) 标准化欧式距离 “seuclidean”: 即对于各特征维度做了归一化以后的欧式距离。此时各样本特征维度的均值为0，方差为1。 g) 马氏距离“mahalanobis”：$\\sqrt{(x-y)^TS^{-1}(x-y)}$ 其中，𝑆−1S−1为样本协方差矩阵的逆矩阵。当样本分布独立时， S为单位矩阵，此时马氏距离等同于欧式距离。 还有一些其他不是实数的距离度量，一般在DBSCAN算法用不上，这里也就不列了。 algorithm：最近邻搜索算法参数，算法一共有三种，第一种是蛮力实现，第二种是KD树实现，第三种是球树实现。这三种方法在K近邻法(KNN)原理小结中都有讲述，如果不熟悉可以去复习下。对于这个参数，一共有4种可选输入，‘brute’对应第一种蛮力实现，‘kd_tree’对应第二种KD树实现，‘ball_tree’对应第三种的球树实现， ‘auto’则会在上面三种算法中做权衡，选择一个拟合最好的最优算法。需要注意的是，如果输入样本特征是稀疏的时候，无论我们选择哪种算法，最后scikit-learn都会去用蛮力实现‘brute’。个人的经验，一般情况使用默认的 ‘auto’就够了。 如果数据量很大或者特征也很多，用”auto”建树时间可能会很长，效率不高，建议选择KD树实现‘kd_tree’，此时如果发现‘kd_tree’速度比较慢或者已经知道样本分布不是很均匀时，可以尝试用‘ball_tree’。而如果输入样本是稀疏的，无论你选择哪个算法最后实际运行的都是‘brute’。 leaf_size：最近邻搜索算法参数，为使用KD树或者球树时， 停止建子树的叶子节点数量的阈值。这个值越小，则生成的KD树或者球树就越大，层数越深，建树时间越长，反之，则生成的KD树或者球树会小，层数较浅，建树时间较短。默认是30. 因为这个值一般只影响算法的运行速度和使用内存大小，因此一般情况下可以不管它。 p: 最近邻距离度量参数。只用于闵可夫斯基距离和带权重闵可夫斯基距离中p值的选择，p=1为曼哈顿距离， p=2为欧式距离。如果使用默认的欧式距离不需要管这个参数。 以上就是DBSCAN类的主要参数介绍，其实需要调参的就是两个参数eps和min_samples，这两个值的组合对最终的聚类效果有很大的影响。 scikit-learn DBSCAN聚类实例完整代码参见:https://github.com/ljpzzz/machinelearning/blob/master/classic-machine-learning/dbscan_cluster.ipynb 首先，生成一组随机数据，为了体现DBSCAN在非凸数据的聚类优点，生成了三簇数据，两组是非凸的。代码如下： 123456789101112import numpy as npimport matplotlib.pyplot as pltfrom sklearn import datasets%matplotlib inlineX1, y1=datasets.make_circles(n_samples=5000, factor=.6, noise=.05)X2, y2 = datasets.make_blobs(n_samples=1000, n_features=2, centers=[[1.2,1.2]], cluster_std=[[.1]], random_state=9)X = np.concatenate((X1, X2))plt.scatter(X[:, 0], X[:, 1], marker='o')plt.show() 数据输出： 首先看看K-Means的聚类效果，代码如下： 1234from sklearn.cluster import KMeansy_pred = KMeans(n_clusters=3, random_state=9).fit_predict(X)plt.scatter(X[:, 0], X[:, 1], c=y_pred)plt.show() 输出： 那么如果使用DBSCAN效果如何呢？我们先不调参，直接用默认参数，看看聚类效果,代码如下： 1234from sklearn.cluster import DBSCANy_pred = DBSCAN().fit_predict(X)plt.scatter(X[:, 0], X[:, 1], c=y_pred)plt.show() 输出： 全部分为一类了。 看来我们需要对DBSCAN的两个关键的参数eps和min_samples进行调参。 从上图我们可以发现，类别数太少，我们需要增加类别数，那么我们可以减少𝜖ϵ-邻域的大小，默认是0.5，我们减到0.1看看效果。代码如下： 123y_pred = DBSCAN(eps = 0.1).fit_predict(X)plt.scatter(X[:, 0], X[:, 1], c=y_pred)plt.show() 输出： 可以看到聚类效果有了改进，至少边上的那个簇已经被发现出来了。此时我们需要继续调参增加类别，有两个方向都是可以的，一个是继续减少eps，另一个是增加min_samples。我们现在将min_samples从默认的5增加到10，代码如下： 123y_pred = DBSCAN(eps = 0.1, min_samples = 10).fit_predict(X)plt.scatter(X[:, 0], X[:, 1], c=y_pred)plt.show() 输出： 可见现在聚类效果基本已经可以让我们满意了。 上面这个例子只是理解DBSCAN调参的一个基本思路，在实际运用中可能要考虑很多问题，以及更多的参数组合。","categories":[{"name":"python","slug":"python","permalink":"http://mangosTeeN96.github.io/categories/python/"}],"tags":[{"name":"数据分析","slug":"数据分析","permalink":"http://mangosTeeN96.github.io/tags/数据分析/"}]},{"title":"python数据分析","slug":"python数据分析","date":"2019-12-28T01:27:08.000Z","updated":"2020-07-05T10:51:20.995Z","comments":true,"path":"2019/12/28/python数据分析/","link":"","permalink":"http://mangosTeeN96.github.io/2019/12/28/python数据分析/","excerpt":"","text":"python数据分析1. 数据分析全景图 2.数据挖掘的最佳路径数据挖掘的基本流程 数据挖掘的十大算法 3.Python基础语法见另一个笔记 4.Numpy快速处理数据简介它不仅是Python中使用最多的第三方库，而且还是SciPy、Pandas等数据科学的基础库。它所提供的数据结构比Python自身的“更高级、更高效”，可以这么说，NumPy所提供的数据结构是Python数据分析的基础。 我上次讲到了Python数组结构中的列表list，它实际上相当于一个数组的结构。而NumPy中一个关键数据类型就是关于数组的，那为什么还存在这样一个第三方的数组结构呢？ 实际上，标准的Python中，用列表list保存数组的数值。由于列表中的元素可以是任意的对象，所以列表中list保存的是对象的指针。虽然在Python编程中隐去了指针的概念，但是数组有指针，Python的列表list其实就是数组。这样如果我要保存个简单的数组[0,1,2]，就需要有3个指针和3个整数的对象，这样对于Python来说是非常不经济的，浪费了内存和计算时间。 列表list的元素在系统内存中是分散存储的，而NumPy数组存储在一个均匀连续的内存块中。这样数组计算遍历所有的元素，不像列表list还需要对内存地址进行查找，从而节省了计算资源。 另外在内存访问模式中，缓存会直接把字节块从RAM加载到CPU寄存器中。因为数据连续的存储在内存中，NumPy直接利用现代CPU的矢量化指令计算，加载寄存器中的多个连续浮点数。另外NumPy中的矩阵计算可以采用多线程的方式，充分利用多核CPU计算资源，大大提升了计算效率。 当然除了使用NumPy外，你还需要一些技巧来提升内存和提高计算资源的一个重要的规则就是：避免采用隐式拷贝，而是采用就地操作的方式。举个例子，如果我想让一个数值x是原来的两倍，可以直接写成x*=2，而不要写成y=x*2。这样速度能快到2倍甚至更多。 在NumPy里有两个重要的对象：ndarray（N-dimensional arrayobject）解决了多维数组问题，而ufunc（universal function object）则是解决对数组进行处理的函数。 ndarray对象 ndarray实际上是多维数组的含义。在NumPy数组中，维数称为秩（rank），一维数组的秩为1，二维数组的秩为2，以此类推。在NumPy中，每一个线性的数组称为一个轴（axes），其实秩就是描述轴的数量。 ndarray对象创建数组，处理结构数组。 ufunc运算 ufunc是universal function的缩写，它能对数组中每个元素进行函数操作。NumPy中很多ufunc函数计算速度非常快，因为都是采用C语言实现的。 numpy数组 numpy 处理数值型数据 创建数组 import numpy as npa = np.array([1,2,3]) [1 2 3]a = np.array(range(1,6)) [1 2 3 4 5] a = np.array(range(5)) [0 1 2 3 4]a=np.array([1,2,3],[4,5,6],[7,8,9])a = np.arange(start,stop,step) 数组的类名 type（a） 数据的类型 a.dtype 在创建数组时指定数据类型 a = np.array([1,2,3]，dtype=’’) 修改数据类型 a.astype(‘’) 保留几位小数 np.round(数组，位数）random.random() 生成随机小数 数组操作 查看数组的形状 a.shape shape[0] 多少行shape[1] 多少列 修改 a.reshape（3，4） 一维（3，） 三维（3，3，2）三块、三行、两列 a.reshape（-1） 转换为1行，自动匹配列数 a.reshape（-1，1）转换为1列，自动匹配行数a.reshape（-1，2）2列，匹配行数 二维展开为一维 a.flatten（） 数组计算 a+2数组内所有数+2其他运算相同 数组间计算 a*b两数组形状一样，对应位置计算；若形状不一样，但某一个数组与另一个数组的一列或一行形状相同，会对应计算 数组拼接 竖直拼接 np.vstack((t1,t2)) 水平拼接 np.hstack((t1,t2)) 行交换 a[[1,2],:] = a[[2,1],:] 列交换 a[:,[0,2]] = t[:,[2,0]] numpy中定义的数据类型及类型代码 类型 类型代码 描述 int8、uint8 i1、u1 有符号和无符号的8位整型（1个字节） int16、uint16 i2、u2 有符号和无符号的16位整型（2个字节） int32、uint32 i4、u4 有符号和无符号的32位整型（4个字节） int64、uint64 i8、u8 有符号和无符号的64位整型（8个字节） float16 f2 半精度浮点数 float32 f4或f 标准的单精度浮点数 float64 f8或d 标准的双精度浮点数 float128 f16或g 扩展精度浮点数 complex64、complex128 c8、c16 分别用两个32位、64位或128位浮点数表示的复数 complex256 c32 复数 bool ？ True和False布尔类型 object O Python对象类型 string_ S 固定长度的字符串类型。例如，创建一个长度为10的字符串，应使用S10 unicode_ U 固定长度的Unicode类型，跟字符串定义方式一样，比如U10 numpy结构化数组——structured array“结构化数组”这一称呼来源于C语言，在C语言中，如果我们需要创建一个“ 学生 ”的数组，每一个学生包括 姓名、年龄、性别、体重 四个信息，我们需要先构造一个结构体，然后使用结构体数组。得到的数组的形式如下所示： name age weight 0 张三 22 68 1 李四 27 56 2 王五 25 62 比如有一个numpy数组 a=np.array([1,2,3,4,5],dtype=np.int32) #创建数组时，每一个元素的“ 类型 ”都是相同的， 也就是说，如果要创建类似于上面的“ 结构体数组 ”，第一件事情是需要定义一个 全新的dtype。参见下面的代码： 12345678910111213141516171819# -*- coding: utf-8 -*-import numpy as np student_type=&#123;'names':('name', 'age', 'sex','weight'), 'formats':('U10', 'i4','U6', 'f8')&#125; #U可以用Sstudents=np.array([('袁菲',25,'女',55),('张三',22,'女',65),('李四',28,'男',70),('赵二',21,'女',49),('王五',29,'男',85)],dtype=student_type) print(students)print(students.shape) #数组形状print(students.dtype) #数组元素类型print('========================================================================')row1=students[0] #返回某一行，依然使用索引indexprint(row1)name=students['name'] #返回某一列，print(name)sex=students['sex']print(sex)print('========================================================================')element=students[1]['age'] #返回某一行的某一列，即返回某一个 单元格 元素，等价于students[1][1]print(element) 1234567891011121314151617[(&apos;袁菲&apos;, 25, &apos;女&apos;, 55.) (&apos;张三&apos;, 22, &apos;女&apos;, 65.) (&apos;李四&apos;, 28, &apos;男&apos;, 70.) (&apos;赵二&apos;, 21, &apos;女&apos;, 49.) (&apos;王五&apos;, 29, &apos;男&apos;, 85.)](5,)[(&apos;name&apos;, &apos;&lt;U10&apos;), (&apos;age&apos;, &apos;&lt;i4&apos;), (&apos;sex&apos;, &apos;&lt;U6&apos;), (&apos;weight&apos;, &apos;&lt;f8&apos;)]======================================================(&apos;袁菲&apos;, 25, &apos;女&apos;, 55.)[&apos;袁菲&apos; &apos;张三&apos; &apos;李四&apos; &apos;赵二&apos; &apos;王五&apos;][&apos;女&apos; &apos;女&apos; &apos;男&apos; &apos;女&apos; &apos;男&apos;]======================================================22 从上面的例子可以看出，numpy的结构化数组有点类似于pandas的使用，如果熟悉pandas的dataframe结构，就很简单了，但也有区别，比如我们不能通过这样的方式同时访问多个列： name=students[‘name’,’weight’] #会显示错误 columns=students[[‘name’,’weight’]] #这样就正确了 核心–如何创建自定义的dtype 创建dtype的几种方式：字符串、列表、元组、字典 （1）方法一：使用字符串创建dtype类型 123mytype='int,float,int's=np.zeros(5,dtype=mytype) #等价于s=np.zeros(5,dtype='int,float,int') 运行的结果是包含5个元素的结构体数组，这里结构体元素都是以单一的数字，我们还可以给结构体元素指定特定的形状，如下代码： 12345x = np.zeros(3, dtype='3int8, float32, (2,3)float64')# 3int8 表示的是结构体的第一个元素是包含 3 个int元素的# float 就表示第二个元素只是单纯的一个float值# (2,3)float64 表示的是第三个元素是（2，3）的形状的 float元素print x 123[([0, 0, 0], 0.0, [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]) ([0, 0, 0], 0.0, [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]) ([0, 0, 0], 0.0, [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])] 总结：字符串创建自定义的“ 结构体元素 ”的方式为 ‘（形状）类型一，（形状）类型二，（形状）类型三’ 的形式 （2）方法二：使用元组创建dtype类型 （3）方法三：使用列表创建dtype类型 12345678910x = np.zeros(5, dtype=[('age','int'), ('height','i8'), ('weight',np.float), ('width','float',(2,3))]) # 第一个字段为age ，可以直接使用 int、float等等 # 第二个参数为height ，可以使用 i4、i8、f8等形式的参数 # 第三个参数为weight ，可以使用np的定义的类型 # 第四个参数为width ，还可以给参数指定形状（2，3) 12345[(0, 0, 0.0, [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]) (0, 0, 0.0, [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]) (0, 0, 0.0, [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]) (0, 0, 0.0, [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]) (0, 0, 0.0, [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])] 总结：使用列表定义dtype的一般格式为： [ (‘ 字段一 ‘，’类型一‘，（形状一）),(‘ 字段二 ‘，’类型二，（形状二）),(‘ 字段三 ‘，’类型三‘，（形状三）)] （4）方法四：使用字典创建dtype类型 student_type={‘names’:(‘name’, ‘age’, ‘sex’,’weight’), ‘formats’:(‘U10’, ‘i4’,’U6’, ‘f8’)}通过指定字典的 names和formats 去实现。 numpy读取本地文件轴axis 一维0轴，二维0，1轴，三维0，1，2轴 并不会经常用numpy读取，pandas有更强大的方法 np.loadtxt(frame,dtype= ,delimiter= ,skiprows= ,usecols= ,unpack= ) numpy索引和切片 操作（查找、修改值） 符号 取一行 a[1] 取多行 a[1:3] 取不连续的多行 a[[2,4,6]] 取一列 a[:,2] 取多列 a[:,2:4] 取不连续的多列 a[:,[0,2]] 一个值 a[2,3] a[2:3,3:4] 修改值直接取出来赋值即可还可以调节查找然后赋值 a[a&lt;10]=3 a&lt;10替换为0，否则10 np.where(a&lt;10,0,10) a&lt;10替换为10，a&gt;18替换为18 a.clip(10,18) 生成随机数 操作 符号 获取最大值最小值的位置 np.argmax(a,axis=0) min 创建全0数组 np.zeros((3,4)) 全1 ones 对角线为1的方阵 np.eye(3) numpy生成随机数 np.random.xxx a=b 完全不复制，ab互相影响 a=b[:] 视图的操作，一种切片，会创建新的对象a，a的数据完全由b保管，ab数据变化一致 a=b.copy() 复制，ab互不影响 nan、inf nan not a number 出现：数据有缺失，不合适的计算 inf 正无穷，-inf负无穷 比如一个数字除以0，python报错，numpy是inf = np.nannp.inf注意二者都是float nan注意点 把nan替换为列的平均值 123456789for i in range(t1.shape[1]): #遍历每一列 temp_col=t1[:,i] #当前一列 nan_num=np.count_nonzero(temp_col!=temp_col) #nan个数，np.count_nonzero（）判断非0元素个数。temp_col为数组，返回的应是一个布尔值数组 if nan_num!=0: temp_not_nan_col = temp_col[temp_col==temp_col] #当前列不为nan的array #选中当前为nan的位置，把值赋值为不为nan的数的均值 temp_col[np.isnan(temp_col)] = temp_not_nan_col.mean() numpy常用函数大全基本情况.ndim ：维度 .shape ：各维度的尺度 （2，5） .size ：元素的个数 10 .dtype ：元素的类型 dtype(‘int32’) .itemsize ：每个元素的大小，以字节为单位 ，每个元素占4个字节 ndarray数组的创建np.arange(n) ; 元素从0到n-1的ndarray类型 np.ones(shape): 生成全1 np.zeros((shape)， ddtype = np.int32) ： 生成int32型的全0 np.full(shape, val): 生成全为val np.eye(n) : 生成单位矩阵 np.ones_like(a) : 按数组a的形状生成全1的数组 np.zeros_like(a): 同理 np.full_like (a, val) : 同理 np.linspace（1,10,4）： 根据起止数据等间距地生成数组 np.linspace（1,10,4, endpoint = False）：endpoint 表示10是否作为生成的元素 np.concatenate()：连接，连接后ndim不变，a和b可以有一维size不同，但size不同的维度必须是要连接的维度 1234567891011121314151617181920&gt;&gt;&gt; a = np.array([[1, 2], [3, 4]])&gt;&gt;&gt; b = np.array([[5, 6]]) #b是一个二维array&gt;&gt;&gt; np.concatenate((a, b), axis=0)array([[1, 2], [3, 4], [5, 6]])&gt;&gt;&gt; np.concatenate((a, b.T), axis=1)array([[1, 2, 5], [3, 4, 6]])&gt;&gt;&gt; a = np.array([[1, 2], [3, 4]]) #a、b的shape为（2,2），连接第一维就变成（4,2），连接第二维就变成（2,4）&gt;&gt;&gt; b = np.array([[5, 6], [7, 8]])&gt;&gt;&gt; np.concatenate((a,b),axis=0)array([[1, 2], [3, 4], [5, 6], [7, 8]])&gt;&gt;&gt; np.concatenate((a,b),axis=1)array([[1, 2, 5, 6], [3, 4, 7, 8]]) 数组的维度变换.reshape(shape) : 不改变当前数组，依shape生成 .resize(shape) : 改变当前数组，依shape生成 .swapaxes(ax1, ax2) : 将两个维度调换 .flatten() : 对数组进行降维，返回折叠后的一位数组 数组的类型变换数据类型的转换 ：a.astype(new_type) : eg, a.astype (np.float) 数组向列表的转换： a.tolist() 数组的索引和切片 一维数组切片 a = np.array ([9, 8, 7, 6, 5, ]) a[1:4:2] –&gt; array([8, 6]) ： a[起始编号：终止编号（不含）： 步长] 多维数组索引 a = np.arange(24).reshape((2, 3, 4)) a[1, 2, 3] 表示 3个维度上的编号， 各个维度的编号用逗号分隔 多维数组切片 a [：，：，：：2 ] 缺省时，表示从第0个元素开始，到最后一个元素 数组的运算np.abs(a) np.fabs(a) : 取各元素的绝对值 np.sqrt(a) : 计算各元素的平方根 np.square(a): 计算各元素的平方 np.log(a) np.log10(a) np.log2(a) : 计算各元素的自然对数、10、2为底的对数 np.ceil(a) np.floor(a) : 计算各元素的ceiling 值， floor值（ceil向上取整，floor向下取整） np.rint(a) : 各元素 四舍五入 np.modf(a) : 将数组各元素的小数和整数部分以两个独立数组形式返回 np.exp(a) : 计算各元素的指数值 np.sign(a) : 计算各元素的符号值 1（+），0，-1（-） np.maximum(a, b) np.fmax() : 比较（或者计算）元素级的最大值 np.minimum(a, b) np.fmin() : 取最小值 np.mod(a, b) : 元素级的模运算 np.copysign(a, b) : 将b中各元素的符号赋值给数组a的对应元素 数据的CSV文件存取CSV (Comma-Separated Value,逗号分隔值) 只能存储一维和二维数组 np.savetxt(frame, array, fmt=’% .18e’, delimiter = None): frame是文件、字符串等，可以是.gz .bz2的压缩文件； array 表示存入的数组； fmt 表示元素的格式 eg： %d % .2f % .18e ; delimiter： 分割字符串，默认是空格 eg： np.savetxt(‘a.csv’, a, fmt=%d, delimiter = ‘,’ ) np.loadtxt(frame, dtype=np.float, delimiter = None, unpack = False) : frame是文件、字符串等，可以是.gz .bz2的压缩文件； dtype：数据类型，读取的数据以此类型存储； delimiter: 分割字符串，默认 是空格; unpack: 如果为True， 读入属性将分别写入不同变量。 多维数据的存取 a.tofile(frame, sep=’’, format=’%s’ ) : frame: 文件、字符串； sep: 数据分割字符串，如果是空串， 写入文件为二进制 ； format:： 写入数据的格式 eg: a = np.arange(100).reshape(5, 10, 2) a.tofile(“b.dat”, sep=”,”, format=’%d’) np.fromfile(frame, dtype = float, count=-1, sep=’’)： frame： 文件、字符串 ； dtype： 读取的数据以此类型存储； count：读入元素个数， -1表示读入整个文件； sep: 数据分割字符串，如果是空串，写 入文件为二进制 PS: a.tofile() 和np.fromfile（）要配合使用，要知道数据的类型和维度。 np.save(frame, array) : frame: 文件名，以.npy为扩展名，压缩扩展名为.npz ； array为数组变量 np.load(fname) : frame: 文件名，以.npy为扩展名，压缩扩展名为 np.save() 和np.load() 使用时，不用自己考虑数据类型和维度。 numpy随机数函数numpy 的random子库 rand(d0, d1, …,dn) : 各元素是[0, 1）的浮点数，服从均匀分布 randn(d0, d1, …,dn)：标准正态分布 random.randint(a,b)：用于生成一个指定范围内的整数。[a，b] randint(low， high,（ shape）): 依shape创建随机整数或整数数组，范围是[ low, high） seed(s) ： 随机数种子 shuffle(a) : 根据数组a的第一轴进行随机排列，改变数组a permutation(a) : 根据数组a的第一轴进行随机排列， 但是不改变原数组，将生成新数组 choice(a[, size, replace, p]) : 从一维数组a中以概率p抽取元素， 形成size形状新数组，replace表示是 否可以重用元素，默认为False。 eg： replace = False时，选取过的元素将不会再选取 uniform(low, high, size) : 产生均匀分布的数组，起始值为low，high为结束值，size为形状 normal(loc, scale, size) : 产生正态分布的数组， loc为均值，scale为标准差，size为形状 poisson(lam, size) : 产生泊松分布的数组， lam随机事件发生概率，size为形状 eg: a = np.random.uniform(0, 10, (3, 4)) a = np.random.normal(10, 5, (3, 4)) numpy的统计函数sum(a, axis = None) : 依给定轴axis计算数组a相关元素之和，axis为整数或者元组 mean(a, axis = None) : 同理，计算平均值 average(a, axis =None, weights=None) : 依给定轴axis计算数组a相关元素的加权平均值 std（a, axis = None） ：同理，计算标准差 var（a, axis = None）: 计算方差 eg： np.mean(a, axis =1) ： 对数组a的第二维度的数据进行求平均 a = np.arange(15).reshape(3, 5) np.average(a, axis =0, weights =[10, 5, 1]) : 对a第一各维度加权求平均，weights中为权重，注意要 和a的第一维匹配 min(a) max(a) : 计算数组a的最小值和最大值 argmin(a) argmax(a) : 计算数组a的最小、最大值的下标（注：是一维的下标） unravel_index(index, shape) : 根据shape将一维下标index转成多维下标 ptp(a) : 计算数组a最大值和最小值的差 median(a) : 计算数组a中元素的中位数（中值） eg：a = [[15, 14, 13], [12, 11, 10] ] np.argmax(a) –&gt; 0 np.unravel_index( np.argmax(a), a.shape) –&gt; (0,0) numpy的梯度函数np.gradient(a) ： 计算数组a中元素的梯度，f为多维时，返回每个维度的梯度 离散梯度： xy坐标轴连续三个x轴坐标对应的y轴值：a, b, c 其中b的梯度是（c-a）/2 而c的梯度是： (c-b)/1 当为二维数组时，np.gradient(a) 得出两个数组，第一个数组对应最外层维度的梯度，第二个数组对应第二 层维度的梯度。 图像的表示和变换PIL， python image library 库 from PIL import Image Image是PIL库中代表一个图像的类（对象） im = np.array(Image.open(“.jpg”)) im = Image.fromarray(b.astype(‘uint8’)) # 生成 im.save(“路径.jpg”) # 保存 im = np.array(Image.open(“.jpg”).convert(‘L’)) # convert(‘L’)表示转为灰度图 ※ numpy重点函数 ※简略，前几节有对应的详细内容 1. 创建数组12345678a = np.array([1,2,3])b = np.array([[1,2,3],[4,5,6],[7,8,9]])b[1,1] = 10print a.shapeprint b.shapeprint a.dtypeprint b 123456(3,)(3, 3)int64[[ 1 2 3] [ 4 10 6] [ 7 8 9]] 2. 结构数组3. 连续数组的创建12x1 = np.arange(1,11,2)x2 = np.linspace(1,9,5) 12[1 3 5 7 9][ 1. 3. 5. 7. 9.] np.arange和np.linspace起到的作用是一样的，都是创建等差数组。 arange()类似内置函数range()，通过指定初始值、终值、步长来创建等差数列的一维数组，默认是不包括终值的。 linspace是linear space的缩写，代表线性等分向量的含义。linspace()通过指定初始值、终值、元素个数来创建等差数列的一维数组，默认是包括终值的。 4. 算数运算加、减、乘、除、求n次方和取余数 12345678x1 = np.arange(1,11,2)x2 = np.linspace(1,9,5)print np.add(x1,x2)print np.subtract(x1,x2)print np.multiply(x1,x2)print np.divide(x1,x2)print np.power(x1,x2) #power求n次方，x2可以是数或者数组，数组列数要相同print np.mod(x1,x2) #mod和remainder一样 1234567[ 2. 6. 10. 14. 18.][ 0. 0. 0. 0. 0.][ 1. 9. 25. 49. 81.][ 1. 1. 1. 1. 1.][ 1.00000000e+00 2.70000000e+01 3.12500000e+03 8.23543000e+05 3.87420489e+08][ 0. 0. 0. 0. 0.] 5. 统计函数 计数组/矩阵中的最大值函数amax()，最小值函数amin() 1234567a = np.array([[1,2,3],[4,5,6],[7,8,9]])print np.amin(a)print np.amin(a,0)print np.amin(a,1)print np.amax(a)print np.amax(a,0)print np.amax(a,1) 1234561[1 2 3][1 4 7]9[7 8 9][3 6 9] amin()用于计算数组中的元素沿指定轴的最小值。对于一个二维数组a，amin(a）指的是数组中全部元素的最小值 amin(a,0)是延着axis=0轴的最小值，axis=0轴是把元素看成了[1,4,7]，[2,5,8]，[3,6,9]三个元素，所以最小值为[1,2,3]。 amin(a,1)是延着axis=1轴的最小值，axis=1轴是把元素看成了[1,2,3], [4,5,6]，[7,8,9]三个元素，所以最小值为[1,4,7]。 同理amax()是计算数组中元素沿指定轴的最大值。 统计最大值与最小值之差 ptp() 1234a = np.array([[1,2,3],[4,5,6],[7,8,9]])print np.ptp(a)print np.ptp(a,0)print np.ptp(a,1) 1238[6 6 6][2 2 2] 统计数组的百分位数 percentile() 12345a = np.array([[1,2,3],[4,5,6],[7,8,9]])print np.percentile(a,50)print np.percentile(a,50,axis=0)print np.percentile(a,50,axis=1) 1235.0[ 4. 5. 6.][ 2. 5. 8.] percentile()代表着第p个百分位数，这里p的取值范围是0-100，如果p=0 ，就是求最小值，如果p=50就是求 平均值，如果p=100就是求最大值。同样你也可以求得在axis=0 和 axis=1 上的p％的百分位数。 median()和mean()求数组的中位数、平均值 同样也可以求得在axis=0和1两个轴上的中位数、平均值。 average()函数可以求加权平均 加权平均的意思就是每个元素可以设置个权重，默认情况下每个元素的权重是相同的。也可以指定权重数组 12345a = np.array([1,2,3,4])wts = np.array([1,2,3,4])print np.average(a)print np.average(a,weights = wts) 122.53.0 统计数组中的标准差std()、方差var() 方差的计算是指每个数值与平均值之差的平方求和的平均值，即mean（（ x-x.mean() )^2 ）。标准差是方差的算术平方根。 6. Numpy排序sort函数，sort(a,axis=-1,kind=‘quicksort’,order=None） axis默认是-1，即沿着数组的最后一个轴进行排序，也可以取不同的axis轴，或者axis=None代表采用扁平化的方式作为一个向量进行排序。 kind默认quicksort；在kind里，可以指定quicksort、mergesort、heapsort分别表示快速排序、合并排序、堆排序。 另外order字段，对于结构化的数组可以指定按照某个字段进行排序。 123456a = np.array([[4,3,2],[2,4,1]])print np.sort(a)print np.sort(a,axis = -1) #此处最后一个轴即1print np.sort(a,axis = None)print np.sort(a,axis = 0)print np.sort(a,axis = 1) 123456789[[2 3 4] [1 2 4]][[2 3 4] [1 2 4]][1 2 2 3 4 4][[2 3 1] [4 4 2]][[2 3 4] [1 2 4]] 总结在NumPy学习中，要掌握的就是对数组的使用，这是NumPy和标准Python最大的区别。 在NumPy中重新对数组进行了定义，同时提供了算术和统计运算，可以使用NumPy自带的排序功能，一句话就搞定各种排序算法。 理解NumPy提供的数据结构为什么比Python自身的“更高级、更高效”，要从对数据指针的引用角度进行理解。 5.Pandaspandas之字符串方法 方法 说明 cat 实现元素级的字符串连接操作，可指定分隔符 contains 返回表示各字符串是否含有指定模式的布尔型数组 count 模式的出现次数 endswith, startswith 相当于对各个元素执行x.endswith(pattern)或x.startswith(pattern) findall 计算各字符串的模式列表 get 获取各元素的第i个字符 join 根据指定的分隔符将Series中各元素的字符串连接起来 len 计算各字符串的长度 lower、upper 转换大小写。相当于对各个元素执行x.lower()或x.upper() match 根据指定的正则表达式对各个元素执行re.match pad 在字符串的左边、右边或左右两边添加空白符 center 相当于pad(side=’both’) repeat 重复值。例如，s.str.repeat(3)相当于对各个字符串执行x*3 replace 用指定字符串替换找到的模式 slice 对Series中的各个字符串进行子串截取 split 根据分隔符或正则表达式对字符串进行拆分expend = True 返回dataframeFalse 返回Series strip、rstrip、Istrip 去除空白符，包括换行符。相当于对各个元素执行x.strip()、x.rstrip()、x.Istrip() series在数据分析工作中，Pandas的使用频率是很高的，一方面是因为Pandas提供的基础数据结构DataFrame与json的契合度很高，转换起来就很方便。另一方面，如果我们日常的数据清理工作不是很复杂的话，通常用几句Pandas代码就可以对数据进行规整。 Pandas可以说是基于 NumPy 构建的含有更高级数据结构和分析能力的工具包。在NumPy中数据结构是围绕ndarray展开的，Pandas中的核心数据结构是什么Series和 DataFrame，他们分别代表着一维的序列和二维的表结构。 基于这两种数据结构，Pandas可以对数据进行导入、清洗、处理、统计和输出。 常见数据结构 series 一维，带标签数组 dataframe 二维，series容器 Series是个定长的字典序列。说是定长是因为在存储的时候，相当于两个ndarray，这也是和字典结构最大的不同。因为在字典的结构里，元素的个数是不固定的。 import pandas as pd series创建 Series两个基本属性：index和values在Series结构中，index默认是0,1,2……..递增的整数序列，也可以自己指定索引 t = pd.Series(data=[1, 2, 3, 4], index=[‘a’, ‘b’, ‘c’, ‘d’])一个例子：index =list(string.ascii_uppercase[5:15])键为大写字母第6到16个 方法2：通过一维数组创建序列 a = np.arange(2, 9) #索引默认0，1，2… t1 = pd.Series(a) 方法3：通过字典的方式创建序列 t2 = pd.Series({‘a’: 10, ‘b’: 20, ‘c’: 30, ‘d’: 40, ‘e’: 50}) t.indext.values type()、len()、list() print(type(t2.index)) #&lt;class ‘pandas.core.indexes.base.Index’&gt;print(len(t2.index)) #5print(list(t2.index)) #[‘a’, ‘b’, ‘c’, ‘d’, ‘e’] t.tolist() series转换为list，返回value list set() 去重查看某一列都有哪些种数据时，（）内写对应列即可 读取数据 读取数据 读取csv文件 t = pd.read_csv(‘./xxx.csv’) 读取时可以规范数据类型 ,dtype={‘列名’: int}增加列头column_names = [‘’, ‘’, …],names = column_names 网络读取 data_url = “https://raw.githubusercontent.com/.csv&quot; #填写url读取 df = pd.read_csv(data_url) 读取Mysql数据 假设数据库安装在本地，用户名为myusername,密码为mypassword,要读取mydb数据库中的数据 import MySQLdbmysql_cn= MySQLdb.connect(host=’localhost’, port=3306,user=’myusername’, passwd=’mypassword’, db=’mydb’)df = pd.read_sql(‘select * from test;’, con=mysql_cn) mysql_cn.close()` 数据导出为csv文件 df.to_csv(‘./demo.csv’, encoding=’utf-8’, index=False) #index=False表示导出时去掉行名称，如果数据中含有中文，一般encoding指定为‘utf-8’ 导出为json文件 df . to_json(‘ ‘ , orient= ‘ ‘ ) orient可以决定输出格式为records时，输出列表嵌套字典其他可见官网demoto_json参数官网demo xlsx文件 pd.read_excel(‘’)df.to_excel(‘’) 将excel文件处理为列表嵌套字典 123456df=pd.read_excel('lemon.xlsx')test_data=[]for i in df.index.values: #获取行号的索引，并对其进行遍历 row_data=df.loc[i,['列名', '列名'...]].to_dict() #根据i获取每一行指定的数据,利用to_dict转成字典 test_data.append(row_data)df = '&#123;0&#125;'.format(test_data) #format 拼接 ###DataFrame 行索引 index，axis=0 列索引 columns，axis=1 创建DataFrame t=pd.DataFrame（np.arange(12).reshape((3,4))，index= , columns= ） 也可以由字典、列表嵌套字典创建 12a = pd.DataFrame(&#123;'a': range(7), 'b': range(7, 0, -1), 'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'], 'd': list(\"hjklmno\")&#125;)print(a) 12345678 a b c d0 0 7 one h1 1 6 one j2 2 5 one k3 3 4 two l4 4 3 two m5 5 2 two n6 6 1 two o 获得数据可以先用 info(）、head（1）、describe（） 看一下数据情况 DataFrame的一些操作去重 去重 df.drop_duplicates(subset=None, keep=’first’, inplace=False) df.drop_duplicates()df中一行元素全部相同时才去除 df.drop_duplicates([‘a’,’b’])df根据’a’,’b’组合列删除重复项，默认保留第一个出现的值组合。传入参数keep=’last’则保留最后一个 set（df[‘列名’]） 去重（仅结果），看这一列有哪些不同值 df[‘’].value_counts() 查看表格某列中有多少个不同值并计算每个不同值有在该列中有多少重复值返回Series，index值，value有几个 遍历1234567df = pd.DataFrame(&#123;'a': [1, 2, 3, 4], 'b': [5, 6, 7, 8], 'c': [9, 10, 11, 12]&#125;)print(df)for index, row in df.iterrows(): print(index) print(row) 这里的iterrows()返回值为元组,(index,row)上面的代码里，for循环定义了两个变量，index，row，那么返回的元组，index=index，row=row. index行索引0、1、2、3，row此行内容 12345678910111213141516171819202122232425 a b c0 1 5 91 2 6 102 3 7 113 4 8 120a 1b 5c 9Name: 0, dtype: int641a 2b 6c 10Name: 1, dtype: int642a 3b 7c 11Name: 2, dtype: int643a 4b 8c 12Name: 3, dtype: int64 如果for循环时，只定义一个变量： 12for row in df.iterrows(): print(row) 那么row就是整个元组。输出结果可以看出： 123456789101112131415161718192021 a b c0 1 5 91 2 6 102 3 7 113 4 8 12(0, a 1b 5c 9Name: 0, dtype: int64)(1, a 2b 6c 10Name: 1, dtype: int64)(2, a 3b 7c 11Name: 2, dtype: int64)(3, a 4b 8c 12Name: 3, dtype: int64) 列操作 对列操作 对某一列数据进行修改 df[‘列名’] = df[‘列名’].map（lambda x：操作） 直接把索引值赋给某列 df[‘列名’] = df . index 类型转换 df[‘列名’] = df[‘列名’] . astype(‘’) ‘’内int… ，也可以直接改整个dataframe的类型 重命名 df.rename(columns={‘A’:’a’, ‘B’:’b’, ‘C’:’c’}, inplace = True) df[‘c’] = ‘0’ 给df增加一个全为0的列，列名为c df[‘列名’] = 值 会warning，但可以直接加进一列 + 列名相同，DataFrame的值可以直接对应相加 行列操作 取行取列 df.loc通过行列名称 df.loc[‘A’，[‘W’，’Z’]]行索引A，列W，Zdf.loc[‘A’]df.loc[:, ‘w’] df.iloc通过行数列数 df.iloc[0:3] loc、iloc只有一位时，都是指行 df.ix混合 行名称列名称/行数列数混合如果是行/列的名称是int类型时，只能根据行/列名称选，不能根据行数/列数选 df[] 可以接收行名称或者行数，但必须是切片df[0:1]行数切片时，如果行索引类型为int，则会根据行数来切片，不会根据行名称切片只能接收列名称，可以是单个或列表df[[‘A’, ‘C’]] df.x列 df.AA列 df.at取值 df.at[0,’A’]0行A列的值 df.corr(method=’pearson’, min_periods=1) 相关系数 method：可选值为{‘pearson’, ‘kendall’, ‘spearman’}，默认pearsonpearson：Pearson相关系数来衡量两个数据集合是否在一条线上面，即针对线性数据的相关系数计算，针对非线性数据便会有误差。线性关系、连续变量、正态分布spearman：非线性的，非正态分析的连续数据的相关系数kendall：用于反映分类变量相关性的指标，即针对有序分类序列的相关系数，非正态分布的数据min_periods：样本最少的数据量 返回值：各类型之间的相关系数DataFrame表格 筛选操作 筛选 Series筛选 即取行取列 接收参数为单个标签或索引的筛选，返回的都是Series，例如：df.iloc[1] df.iloc[:, 2] df.loc[&#39;5&#39;] df.loc[:, &#39;B&#39;] df[&#39;A&#39;] df.A 接收参数为切片或列表的筛选，即使只有一行/一列数据，返回的都是DataFramedf[0:1] df[&#39;5&#39;: &#39;5&#39;] df.iloc[[1]] df.loc[:, [&#39;B&#39;]] df[[&#39;A&#39;]]如果想获取单行/单列数据的DataFrame，只需要将输入的单个标签或索引改为切片或列表 bool值列表 [True, False, True, False]DataFrame或者Series可以接受切片/列表参数的地方，都可以接受bool列表，保留bool列表中真值对应的项目（下方代码） bool值Series pd.Series([True, False, True, False], index=df.index)根据bool Series筛选，保留bool Series真值对应的项目（下方代码）1. 按列生成的Series，index是原df的index，可以对行方向操作进行筛选2. 按行生成的Series，index是原df的columns，可以对列方向操作进行筛选 bool值 DataFrame 保留bool DataFrame真值对应的值，其余值置为NaNchooses =df &gt; 5df[chooses] reindex 对行/列进行筛选，它不会修改原DataFramedf.reindex(index=list(‘67’)) # 筛选出行名称为6和7的行 df.reindex(columns=list(‘BC’)) # 筛选出列名称为B和C的列 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647df = pd.DataFrame(np.arange(16).reshape(4, 4), columns=list('ABCD'), index=list('5678'))# bool列表# 1.生成bool列表chooses = [True, False, True, False]chooses = [i == 0 or i == 8 for i in df['A']] # 结果是[True, False, True, False]# 2.筛选df.iloc[chooses] # 只留第1第3行df.loc[:, chooses] # 只留第1第3列df.ix[chooses] # 只留第1第3行df[chooses] # 只留第1第3行df['A'][chooses] # 只留A列中第1第3个值# bool Series# 1.生成列方向的bool Serieschooses = pd.Series([True, False, True, False], index=df.index)chooses = df.loc[:, 'A'] &gt; 1chooses = df.iloc[:, 0] &gt; 1chooses = df['A'] &gt; 1chooses = df['A'] == 4chooses1 = ~(df.A == 4) # 可以直接取反，等效df.A != 4chooses2 = ~(df['A'] &gt; 1)chooses = df['A'].isin(range(9)) # A列的值是否在range(9)中chooses = (df['A'].isin(range(9))) &amp; (df['B'] &gt; 1) # bool Series的&amp;运算，即同时满足A列range(9)内，B列大于1# 2.在行方向筛选（iloc用不了）print(chooses.index) # Index(['1', '2', '3', '4'], dtype='object')df[chooses] # DataFrame[]df.A[chooses] # Series[]df.loc[chooses] # locdf.iloc[chooses] # 应用在iloc会报错，ValueErrordf = df.ix[chooses] # ixdf = df.loc[:, chooses] # 应用在列方向会报错，pandas.core.indexing.IndexingErrordf[(chooses1) | (chooses2)]# 1.生成行方向的bool Serieschooses = pd.Series([True, False, True, False], index=df.columns)chooses = df.loc['1'] &gt; 1chooses = df.iloc[0] &gt; 1# 2.在列方向筛选print(choose.index) # Index(['A', 'B', 'C', 'D'], dtype='object')df.loc[:, chooses] # locdf.iloc[:, chooses] # 应用在iloc会报错，ValueErrordf.ix[:, chooses] # ixdf.loc[chooses] # 应用在行方向报错，pandas.core.indexing.IndexingError 12345 A B C D5 0 1 2 36 4 5 6 77 8 9 10 118 12 13 14 15 删除操作 删除行列 删除行 df.drop() 行名称df.drop([‘1’, ‘2’])默认axis=0（行操作）inplace=False（不在原表操作） 行号df.drop(df.index[0]) 筛选方法 通过判断等筛选方法实现删除行，上面的笔记有，此处举个例子去重drop_duplicates()，见下方代码 删除列 del del df[‘A’]就地修改 df.drop() 列名称df.drop([&#39;B&#39;, &#39;C&#39;], axis=1, inplace=True)列数df.drop(df.columns[0:3], axis=1, inplace=True) 1234567# 对某行数据去重，可以获取去重后的index列表后，使用loc方法df = pd.DataFrame(np.arange(16).reshape(4, 4), columns=list('ABCD'), index=list('1234'))df.loc['2','B']=9print(df)chooses = df['B'].drop_duplicates().indexprint(df.loc[chooses]) 123456789 A B C D1 0 1 2 32 4 9 6 73 8 9 10 114 12 13 14 15 A B C D1 0 1 2 32 4 9 6 74 12 13 14 15 增加操作 增加行 loc df.loc[‘5’] =[16, 17, 18, 19] # 后面的序列是Iterable就行 at df.at[‘5’] =[16, 17, 18, 19] set_value df.set_value(&#39;5&#39;, df.columns, [16, 17, 18, 19], takeable=False)# warning，set_value会被取消 append 添加有name的Series：s =pd.Series([16, 17, 18, 19], index=df.columns, name=‘5’) df = df.append(s) 添加没有name的Series，必须ignore_indexs =pd.Series([16, 17, 18, 19], index=df.columns) df =df.append(s, ignore_index=True) 可以 append字典列表，同样需要必须ignore_index：ls =[{‘A’:16,‘B’:17,‘C’:18,‘D’:19}, {‘A’:20,‘B’:21,‘C’:22,‘D’:23}] df =df.append(ls, ignore_index=True) 逐行增加 df.loc[len(df)] =[16,17,18,19]len(df)生成的是int，如果生成的int，df已经存在了，会覆盖该行数据，而不会新增 插入行 增加行没找到类似insert这种可以插入的方法，暂时替代方法可以先reindex，再赋值：df =df.reindex(index=df.index.insert(2, ‘5’))df.loc[‘5’] =[16, 17, 18, 19] 增加列 一般涉及到增加列项时，经常会对现有的数据进行遍历运算，获得新增列项的值例如，想增加一列’E’，值等于’A’和’C’列对应值之和。 遍历DataFrame获取序列s见下方代码 df[‘E’ ] df.loc[:, ‘E’] df.loc[条件,新增列] = 赋初始值 df.insert(0,’E’,s) 指定插入位置，和插入列名称，插入内容 pd.concat() 逐列增加 df[len(df)] =[16,17,18,19] 12345678910111213s = [a + c for a, c in zip(df['A'], df['C'])] # 通过遍历获取序列s = [row['A'] + row['C'] for i, row in df.iterrows()] # 通过iterrows()获取序列，s为lists = df.apply(lambda row: row['A'] + row['C'], axis=1) # 通过apply获取序列，s为Seriess = df['A'] + df['C'] # 通过Series矢量相加获取序列s = df['A'].values + df['C'].values # 通过Numpy矢量相加获取序列df.loc[:, 'E'] = sdf['E'] = sdf.insert(0, 'E', s)s = pd.Series([16, 17, 18, 19], name='E', index=df.index)df = pd.concat([df, s], axis=1) 代码运行行列展示时，更改默认显示： 123456#显示所有列pd.set_option('display.max_columns',None)#显示所有行pd.set_option('display.max_rows',None)#设置value的显示长度为100，默认为50pd.set_option('max_colwidth',100) 排序、缺失值处理 排序 df.sort_values(by=’ ‘, ascending= ) ascending= True升序 False降序 想对相等值在排序时分配相同序号（series和df皆可） df . rank( ) axis:{0 or ‘index’,1 or ‘columns’} default 0即默认按沿着index方向排名 method:{‘average’,’min’,’max’,’first’,’dense’}指定排名时用于破坏平级关系的method选项（注：值相同的位同一个分组）‘average’：默认：在相等分组中，为各个值分配平均排名‘min’：使用整个分组的最小排名‘max’：使用整个分组的最大排名‘first’：按值在原始数据中的出现顺序分配排名‘dense’：与’min’类似，但是排名每次只会增加1，即并列的数据只占据一个名次 ascending 是否为升序，默认为True升序 na_option用于处理NaN值 ‘keep’：leave NA values where they are ‘top’：smallest rank if ascending ‘bottom’：smallest rank if dscending rank的一些demo 缺失数据的处理 NaN、0 NaN 判断是否为NaN pd.isnull(df)pd.notnull(df)（bool类型） 处理方式1：删除NaN所在的行列 t.dropna（axis=0，how=’ ‘，inplace=False）axis=默认0，删除列传入1how=’any’当前行只要有NaN就删除how=’all’ 全为则删inplace 是否在原表删除,True 在thresh=n 保留至少有n个非NaN数据的行/列subset=[‘’]选择要检查的列，多个用列名的list作为参数 2:填充数据 t.fillna（ ） 把NaN填充为（）内的值 还可以填充均值什么的t.mean() 0 t[t==0]=np.nan 常用统计函数 统计方法 d1.count() 非空元素个数计算 d1.min() 最小值 d1.max() 最大值 d1.idxmin() 最小值的索引值，类似于R中的which.min函数 d1.idxmax() 最大值的索引值，类似于R中的which.max函数 d1.quantile(0.1) 10%分位数 d1.sum() 求和 d1.mean() 均值 d1.median() 中位数 d1.mode() 众数 d1.var() 方差 d1.std() 标准差 d1.mad() 平均绝对偏差 d1.skew() 偏度 d1.kurt() 峰度 d1.describe() 一次性输出多个描述性统计指标，包括：count,mean,std,min,max等 数据合并、分组 合并 df1.join(df2) 默认情况下是把行索引相同的数据合并到一起 pd.merge（df1，df2） 按照指定的列把数据按照一定的方式合并到一起 默认情况取交集参数：on=’ ‘ 合并哪些列left_on=’ ‘ 按左侧的哪列合并right_on=’ ‘ 右 how=’ ‘ 默认情况是inner，即交集 outer，并集，NaN补全 left，以左边为准，NaN补全 right，右，NaN补全 pd.concat（[，]） 级联，默认沿列方向拼接 axis 默认为0jion 默认outer 分组 groupby（by=’ ‘） .mean().count() 使用聚合方法得到的数据默认是把分组的列当成索引，有时候需要将分组索引也当成一列,此时就可以使用groupby方法中的 as_index=False 修改（代码在下面） count 计算分组中非NA值的数量 sum mean median std、var 标准差、方差 min、max prod 积 first、last 定义自己的聚合函数 agg（） 12345678910111213141516171819&gt;&gt;&gt;df = pd.DataFrame(&#123;'k1': list('aabba'), 'k2': ['one', 'two', 'one', 'two', 'one'], 'value1': np.random.randn(5), 'value2': np.random.randn(5)&#125;)&gt;&gt;&gt;df k1 k2 value1 value20 a one 0.487768 3.1941551 a two -1.798654 1.0032572 b one 0.195446 -1.4206043 b two -0.958120 -0.4774214 a one -2.135973 0.239011 &gt;&gt;&gt;g1 = df.groupby('k1')&gt;&gt;&gt;def cal_size(x): return x.max() - x.min() &gt;&gt;&gt;g1.agg(cal_size) value1 value2k1a 2.623741 2.955143b 1.153565 0.943184 还可以传入多个函数： 12345678910111213&gt;&gt;&gt;data = g1.agg(['mean', 'std', cal_size])&gt;&gt;&gt;data value1 value2 mean std cal_size mean std cal_sizek1a -1.148953 1.427441 2.623741 1.478807 1.533894 2.955143b -0.381337 0.815694 1.153565 -0.949012 0.666931 0.943184 &gt;&gt;&gt;data['value1'] mean std cal_sizek1a -1.148953 1.427441 2.623741b -0.381337 0.815694 1.153565 当传入多个函数时，得到的列会以这个函数命名。如果想更改列名的话，我们可以传入一个 (name,function) 元组组成的列表。比如： 1234567&gt;&gt;&gt;data1 = g1.agg([('average', 'mean'), ('error', 'std'), ('size', cal_size)])&gt;&gt;&gt;data1 value1 value2 average error size average error sizek1a -1.148953 1.427441 2.623741 1.478807 1.533894 2.955143b -0.381337 0.815694 1.153565 -0.949012 0.666931 0.943184 除此之外，我们还可以针对不同的列使用不同的函数，只需要传入一个字典包含列名到函数的映射： 12345&gt;&gt;g1.agg(&#123;'value1': 'sum', 'value2': 'mean'&#125;) value1 value2k1a -3.446859 1.478807b -0.762674 -0.949012 as_index=False: 1234&gt;&gt;&gt;df.groupby('k1', as_index=False).agg(&#123;'value1': 'sum', 'value2': 'mean'&#125;) k1 value1 value20 a -3.446859 1.4788071 b -0.762674 -0.949012 df.as_matrix()：转换数组 1234567891011121314df = pd.DataFrame(np.arange(12).reshape(3, 4))dfOut[10]: 0 1 2 30 0 1 2 31 4 5 6 72 8 9 10 11df.as_matrix()Out[11]: array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) 不过此方法已经快要被淘汰，会warning。 df.values 用法结果相同，注意没有（）。 索引 操作 符号 获取index df.index 指定index df.index = [‘x’,’y’] 重新设置index df.reindex( [‘x’,’y’] )若原本的index中有x，则是取原本的x的值，若没有，则x的值全为NaN 返回index的不重复的值 df.set_index(‘a’).index.unique()返回列a中不重复的值 指定某一列作为index df.set_index(‘a’，drop=False)把a列设为索引，False则原本的列也不删除默认只是返回值更改，原表未改（inplace true改） 可以指定多列，得到复合索引取的时候可以指定顺序 index转换为列 df.reset_index() 默认将所有索引转换为列level=’ ‘ 设置哪些索引转换，’ ‘内索引名称，若没有可用整数表示，多层索引外侧为0 交换多层索引位置 df.swaplevel()常用于想从里层索引取值 series取值 b[] [] dataframe取值 b.loc[ ].loc[ ] 将第一列中所有大于4的数修改成0 df[0] [df[0] &gt; 4] = 0 对层次索引进行交换排序等操作 https://www.jianshu.com/p/3ab1554fe6f3 12345678910111213df = pd.DataFrame(&#123;'a': range(7), 'b': range(7, 0, -1), 'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'], 'd': list(\"hjklmno\")&#125;)print(df.index)df.index = ['10', '11', '12', '13', '14', '15', '16']print(df)print(df.set_index('c').index.unique())df.set_index('a', drop=True, inplace=True)print(df)df.reset_index()print(df) 12345678910111213141516171819202122232425262728RangeIndex(start=0, stop=7, step=1) a b c d10 0 7 one h11 1 6 one j12 2 5 one k13 3 4 two l14 4 3 two m15 5 2 two n16 6 1 two oIndex([&apos;one&apos;, &apos;two&apos;], dtype=&apos;object&apos;, name=&apos;c&apos;) b c da 0 7 one h1 6 one j2 5 one k3 4 two l4 3 two m5 2 two n6 1 two o b c da 0 7 one h1 6 one j2 5 one k3 4 two l4 3 two m5 2 two n6 1 two o 时间序列 生成一段时间范围 pd.date_range(start= ,end= ,periods= ,freq= ) start和end以及freq配合：生成 start和end范围内以频率freq的一组时间索引 start和periods以及freq配合：能够生成从start开始的频率为freq的periods个时间索引eg: start=’20171230’, end=’20180131’, freq=’10D’periods表示生成多少个时间D：一天M：月 在DataFrame中使用时间序列 index=pd.date_range(‘20170101’,periods=10)df=pd.DataFrame(np.random.rand(10),index=index) 把时间字符串转换为时间序列 df[‘ ‘] = pd.to_datetime(df[‘ ‘], format=’ ‘) format参数大部分情况可以不用写，但是对于pandas无法格式化的时间字符串，可以使用 重采样 重采样:指的是将时间序列从一个频率转化为另一个频率进行处理的过程将高频率数据转化为低频率数据为降采样,低频率转化为高频率为升采样 t.resample(‘M’)t.resample(‘M’).mean()t.resample(‘M’).count() 一些笔记 https://www.cnblogs.com/zhangyafei/p/10513893.htmlhttps://blog.csdn.net/qq_40587575/article/details/81205873 datetime.strptime()，strftime() from datetime import datetime ：datetime是模块，datetime模块还包含一个datetime类 strptime(): 用户输入的日期和时间是字符串，要处理日期和时间，首先必须把str转换为datetime。 转换方法是通过datetime.strptime()实现，字符串前后格式要对应，需要一个日期和时间的格式化字符串： 1234&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; cday = datetime.strptime('2017-8-1 18:20:20', '%Y-%m-%d %H:%M:%S')&gt;&gt;&gt; print(cday)2017-08-01 18:20:20 strftime(): 后台提取到datetime对象后，要把它格式化为字符串显示给用户，就需要转换为str，转换方法是通过strftime()实现的，同样需要一个日期和时间的格式化字符串： 1234&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; now = datetime.now()&gt;&gt;&gt; print(now.strftime('%a, %b %d %H:%M'))Mon, May 08 20:22 datetime加减： 对日期和时间进行加减实际上就是把datetime往后或往前计算，得到新的datetime。加减可以直接用+和-运算符，不过需要导入timedelta这个类： 12345678910&gt;&gt;&gt; from datetime import datetime, timedelta&gt;&gt;&gt; now = datetime.now()&gt;&gt;&gt; nowdatetime.datetime(2017, 5, 18, 16, 57, 3, 540997)&gt;&gt;&gt; now + timedelta(hours=10)datetime.datetime(2017, 5, 19, 2, 57, 3, 540997)&gt;&gt;&gt; now - timedelta(days=1)datetime.datetime(2017, 5, 17, 16, 57, 3, 540997)&gt;&gt;&gt; now + timedelta(days=2, hours=12)datetime.datetime(2017, 5, 21, 4, 57, 3, 540997) 返回特定部分 dt.date() 只返回日期 .time() 时间 .year() 年份 .month() 月 .weekday() 某天是一个星期的第几天星期一：0星期日：6 格式化字符串 %a 星期几的简写;如 星期三为Web %A 星期几的全称;如 星期三为Wednesday %b 月份的简写; 如4月份为Apr %B 月份的全称; 如4月份为April %c 标准的日期的时间串;（如： 04/07/10 10:43:39） %C 年份的后两位数字 %d 十进制表示的每月的第几天 %D 月/天/年 %e 在两字符域中，十进制表示的每月的第几天 %F 年-月-日 %g 年份的后两位数字，使用基于周的年 %G 年分，使用基于周的年 %h 简写的月份名 %H 24小时制的小时 %I 12小时制的小时 %j 十进制表示的每年的第几天 %m 十进制表示的月份 %M 十时制表示的分钟数 %n 新行符 %p 本地的AM或PM的等价显示 %r 12小时的时间 %R 显示小时和分钟：hh:mm %S 十进制的秒数 %t 水平制表符 %T 显示时分秒：hh:mm:ss %u 每周的第几天，星期一为第一天 （值从0到6，星期一为0） %U 第年的第几周，把星期日做为第一天（值从0到53） %V 每年的第几周，使用基于周的年 %w 十进制表示的星期几（值从0到6，星期天为0） %W 每年的第几周，把星期一做为第一天（值从0到53） %x 标准的日期串 %X 标准的时间串 %y 不带世纪的十进制年份（值从0到99） %Y 带世纪部分的十制年份 %z，%Z 时区名称，如果不能得到时区名称则返回空字符。 %% 百分号 ※ pandas 重点 ※简略，前几节有对应的详细内容 1. 数据结构Series、DataFrame 2. 数据导入与输出3. 数据清洗 数据清洗常用操作 删除不必要的列、行 drop、dropna 重命名列名 df.rename(columns={‘o’=’n’,…}, inlace=True) 去重 df.drop_duplicates() 格式问题 df[‘’] = df[‘’].astype(‘str’) (np.int64) 数据间的空格 有时先把格式转换为str，以方便数据操作 df[‘’] = df[‘’].str.strip() #删除两边空格lstrip左边、rstrip右边删除特定符号(只能是最两边的)df[‘’].str.strip(‘$’) 大小写转换 .str.upper() #大写.str.lower() #小写.str.title() #首字母大写 查找空值(NaN) 哪个地方存在，返回bool值DataFramedf.isnull()哪列存在，返回bool Seriesdf.isnull.any() apply函数 DataFrame.apply(func, axis=0, broadcast=False, raw=False, reduce=None, args=(), **kwds) axis = 0以行为轴操作，1 列args传参 12345678910111213141516171819202122def double_df(x): return 2*xdef plus(df, n, m): df['news1'] = (df['English'] + df['Chinese'])*m df['news2'] = (df['English'] + df['Chinese'])*n return dfdf = pd.DataFrame(&#123;'name': ['ZhangFei', 'GuanYu', 'ZhaoYun', 'Caocao', 'LiuBei'], 'Chinese': [65, 95, 93, 90, 80],'English': [88, 92, 72, 82, 90], 'Math': [68, 73, 69, 84, 80]&#125;)print(df)# 直接调用原有函数df['name'] = df['name'].apply(str.upper)print(df)# 列调用，列的数值分别传入def函数df['Chinese'] = df['Chinese'].apply(double_df)print(df)# DataFrame调用，df传入def函数df = df.apply(plus, axis=1, args=(2, 3))print(df) 123456789101112131415161718192021222324 name Chinese English Math0 ZhangFei 65 88 681 GuanYu 95 92 732 ZhaoYun 93 72 693 Caocao 90 82 844 LiuBei 80 90 80 name Chinese English Math0 ZHANGFEI 65 88 681 GUANYU 95 92 732 ZHAOYUN 93 72 693 CAOCAO 90 82 844 LIUBEI 80 90 80 name Chinese English Math0 ZHANGFEI 130 88 681 GUANYU 190 92 732 ZHAOYUN 186 72 693 CAOCAO 180 82 844 LIUBEI 160 90 80 name Chinese English Math news1 news20 ZHANGFEI 130 88 68 654 4361 GUANYU 190 92 73 846 5642 ZHAOYUN 186 72 69 774 5163 CAOCAO 180 82 84 786 5244 LIUBEI 160 90 80 750 500 4. 数据统计5. 数据表合并merge 总结 6.学数据分析要掌握的基本概念商业智能BI、数据仓库DW、数据挖掘DM商业智能的英文是Business Intelligence，缩写是BI。相比于数据仓库、数据挖掘，它是一个更大的概念。 商业智能可以说是基于数据仓库，经过了数据挖掘后，得到了商业价值的过程。所以说数据仓库是个金矿，数据挖掘是炼金术，而商业报告则是黄金。 数据仓库的英文是Data Warehouse，缩写是DW。数据仓库可以说是数据库的升级概念。从逻辑上理解，数据库和数据仓库没 什么区别，都是通过数据库技术来存储数据的。不过从数量上来讲，数据仓库的量更庞大，适用于数据挖掘和数据分析。 数据仓库将原有的多个数据来源中的数据进行汇总， 整理而得。数据进入数据仓库前，必须消除数据中的不一致性，方便后续进行数据分析和挖掘。 数据挖掘的英文是Data Mining，缩写是DM。在商业智能BI中经常会使用到数据挖掘技术。数据挖掘的核心包括分类、聚类、预测、关联分析等任务，通过这些炼金术，我们可以从数据仓库中得到宝藏，比如商业报告。 元数据 VS 数据元我们前面提到了数据仓库，在数据仓库中，还有一类重要的数据是元数据，那么它和数据元有什么区别呢？ 元数据（MetaData）：描述其它数据的数据，也称为“中介数据”。 数据元（Data Element）：就是最小数据单元。 在生活中，只要有一类事物，就可以定义一套元数据。举个例子，比如一本图书的信息包括了书名、作者、出版社、ISBN、出版时间、页数和定价等多个属性的信息，我们就可以把这些属性定义成一套图书的元数据。 在图书这个元数据中，书名、作者、出版社就是数据元。你可以理解是最的数据单元。元数据最大的好处是使信息的描述和分类实现了结构化，让机器处理起来很方便。 元数据可以很方便地应用于数据仓库。比如数据仓库中有数据和数据之间的各种复杂关系，为了描述这些关系，元数据可以对数据仓库的数据进行定义，刻画数据的抽取和转换规则，存储与数据仓库主题有关的各种信息。而且整个数据仓库的运行都是基于元数据的，比如抽取调度数据、获取历史数据等。通过元数据，可以很方便地帮助我们管理数据仓库。 数据挖掘的流程数据挖掘的一个英文解释叫Knowledge Discovery in Database，简称KDD，也就是数据库中的知识发现。 在数据挖掘中，有几个非常重要的任务，就是分类、聚类、预测和关联分析。 分类 就是通过训练集得到一个分类模型，然后用这个模型可以对其他数据进行分类。 这里需要说明下训练集和测试集的概念。一般来说数据可以划分为训练集和测试集。训练集是用来给机器做训练的，通常是人们整理好训练数据，以及这些数据对应的分类标识。通过训练，机器就产生了自我分类的模型，然后机器就可以拿着这个分类模型，对测试集中的数据进行分类预测。同样如果测试集中，人们已经给出了测试结果，我们就可以用测试结果来做验证，从而了解分类器在测试环境下的表现。 聚类 人以群分，物以类聚。聚类就是将数据自动聚类成几个类别，聚到一起的相似度大，不在一起的差异性大。我们往往利用聚类来做数据划分。 预测 顾名思义，就是通过当前和历史数据来预测未来趋势，它可以更好地帮助我们识别机遇和风险。 关联分析 就是发现数据中的关联规则，它被广泛应用在购物篮分析，或事务数据分析中。比如我们开头提到的那个案例。 数据挖掘要怎么完成这些任务呢？它需要将数据库中的数据经过一系列的加工计算，最终得出有用的信息。 这个过程可以用以下步骤来描述。 数据预处理中，我们会对数据进行几个处理步骤：数据清洗，数据集成，以及数据变换。 数据清洗 主要是为了去除重复数据，去噪声（即干扰数据）以及填充缺失值。 数据集成 是将多个数据源中的数据存放在一个统一的数据存储中。 数据变换 就是将数据转换成适合数据挖掘的形式。比如，通过归一化将属性数据按照比例缩放，这样就可以将数值落入一个特定的区间内，比如0~1之间。 我会在后面的几节课给你讲解如何对数据进行预处理。 数据后处理是将模型预测的结果进一步处理后，再导出。比如在二分类问题中，一般能得到的是0~1之间的概率值，此时把数据以0.5为界限进行四舍五入就可以实现后处理。 7. 用户画像：标签化就是数据的抽象能力如果说互联网的上半场是粗狂运营，因为有流量红利不需要考虑细节。那么在下半场，精细化运营将是长久的主题。有数据，有数据分析能力才能让用户得到更好的体验。 用户是根本，也是数据分析的出发点。 假如你进入到一家卖羊肉串的餐饮公司，老板说现在竞争越来越激烈，要想做得好就要明白顾客喜欢什么。于是上班第一天，老板问你：“你能不能分析下用户数据，给咱们公司的业务做个赋能啊？”你可以这么和老板说：“老板啊，用户画像建模是个系统的工程，我们要解决三个问题。第一呢，就是用户从哪里来，这里我们需要统一标识用户ID，方便我们对用户后续行为进行跟踪。我们要了解这些羊肉串的用户从哪里来，他们是为了聚餐，还是自己吃宵夜，这些场景我们都要做统计分析。第二呢，这些用户是谁？我们需要对这些用户进行标签化，方便我们对用户行为进行理解。第三呢，就是用户要到哪里去？我们要将这些用户画像与我们的业务相关联，提升 )的转化率，或者降低我们的流失率。” 用户画像建模 第一步 用户唯一标识是整个用户画像的核心。我们以一个App为例，它把“从用户开始使用APP到下单到售后整个所有的用户行为”进行串联，这样就可以更好地去跟踪和分析一个用户的特征。 设计唯一标识可以从这些项中选择：用户名、注册手机号、联系人手机号、邮箱、设备号、CookielD等。 第二步 其次，给用户打标签。标签有很多，且不同的产品，标签的选择范围也不同，这么多的标签，怎样划分才能既方便记忆，又能保证用户画像的全面性呢？ 总结八个字，叫“用户消费行为分析”，可以从这4个维度来进行标签划分。 用户标签：它包括了性别、年龄、地域、收入、学历、职业等。这些包括了用户的基础属性。 消费标签：消费习惯、购买意向、是否对促销敏感。这些统计分析用户的消费习惯。 行为标签：时间段、频次、时长、访问路径。这些是通过分析用户行为，来得到他们使用App的习惯。 内容分析：对用户平时浏览的内容，尤其是停留时间长，浏览次数多的内容进行分析，分析出用户对哪些内容感兴趣，比如，金融、娱乐、教育、体育、时尚、科技等。 可以说，用户画像是现实世界中的用户的数学建模，我们正是将海量数据进行标签化，来得到精准的用户画像，从而为企业更精准地解决问题。 第三步 最后， 当有了用户画像，可以为企业带来什么业务价值呢？ 我们可以从用户生命周期的三个阶段来划分业务价值，包括：获客、粘客和留客。 获客：如何进行拉新，通过更精准的营销获取客户。 粘客：个性化推荐，搜索排序，场景运营等。 留客：流失率预测，分析关键节点降低流失率。 如果按照数据流处理的阶段来划分用户画像建模的过程，可以分为数据层、算法层和业务层。你会发现在不同的层，都需要打上不同的标签。 数据层指的是用户消费行为里的标签。我们可以打上“事实标签” ，作为数据客观的记录。 算法层指的是透过这些行为算出的用户建模。我们可以打上“模型标签”，作为用户画像的分类标识。 业务层指的是获客、粘客、留客的手段。我们可以打上“预测标签”，作为业务关联的结果。 所以这个标签化的流程，就是通过数据层的“事实标签”，在算法层进行计算，打上“模型标签”的分类结果，最后指导业务层，得出“预测标签”。 例；美团外卖的用户画像该如何设计？ 刚才讲的是用户画像的三个阶段，以及每个阶段的准则。下面，我们来使用这些准则做个练习。 如果你是美团外卖的数据分析师，你该如何制定用户标识ID，制定用户画像，以及基于用户画像可以做哪些业务关联？ 首先，我们先回顾下美团外卖的产品背景。美团已经和大众点评进行了合并，因此在大众点评和美团外卖上都可以进行外卖下单。另外美团外卖针对的是高频O2O的场景，美团外卖是美团的核心产品，基本上有一半的市值都是由外卖撑起来的。 基于用户画像实施的三个阶段，首先需要统一用户的唯一标识，那么究竟哪个字段可以作为用户标识呢？先看下美团和大众点评都是通过哪些方式登录的。 美团采用的是手机号、微信、微博、美团账号的登录方式。大众点评采用的是手机号、微信、 QQ、微博的登录方式。这里面两个APP共同的登录方式都是手机号、微信和微博。那么究竟哪个可以作为用户的唯一标识呢？当然主要是以用户的注册手机号为标准。 大众点评的账号体系就可以相通。 当然，大家知道在集团内部，各部门之间的协作，尤其是用户数据打通是非常困难的，所以这里建议，如果希望大数据对各个部门都能赋能，一定要在集团的战略高度上，尽早就在最开始的顶层架构上，将用户标识进行统一，这样在后续过程中才能实现用户数据的打通。 然后思考，有了用户，用户画像都可以统计到哪些标签。按照“用户消费行为分析”的准则来进行设计。 用户标签：性别、年龄、家乡、居住地、收货地址、婚姻、宝宝信息、通过何种渠道进行的注册。 消费标签：餐饮口味、消费均价、团购等级、预定使用等级、排队使用等级、外卖等级。 行为标签：点外卖时间段、使用频次、平均点餐用时、访问路径。 内容分析：基于用户平时浏览的内容进行统计，包括餐饮口味、优惠敏感度等。 当你有了“用户消费行为分析”的标签之后，你就可以更好地理解业务了。 比如一个经常买沙拉的人，一般很少吃夜宵。同样，一个经常吃夜宵的人，吃小龙虾的概率可能远高于其他人。这些结果都是通过数据挖掘中的关联分析得出的。有了这些数据，我们就可以预测用户的行为。比如一个用户购买了“月子餐”后，更有可能购买婴儿水，同样婴儿相关的产品比如婴儿湿巾等的购买概率也会增大。 具体在业务层上，可以基于标签产生哪些业务价值呢？ 在获客上，我们可以找到优势的宣传渠道，如何通过个性化的宣传手段，吸引有潜在需求的用户，并刺激其转化。 在粘客上，如何提升用户的单价和消费频次，方法可以包括购买后的个性化推荐、针对优质用户进行优质高价商品的推荐、以及重复购买，比如通过红包、优惠等方式激励对优惠敏感的人群，提升购买频次。 在留客上，预测用户是否可能会从平台上流失。在营销领域，关于用户留存有一个观点——如果将顾客流失率降低5%，公司利润将提升25%~85%。可以看出留存率是多么的重要。用户流失可能会包括多种情况，比如用户体验、竞争对手、需求变化等，通过预测用户的流失率可以大幅降低用户留存的运营成本。 锻炼自己的抽象能力，将繁杂的事务简单化 上面我们讲到的“用户消费行为标签”都是基于一般情况考虑的，除此之外，用户的行为也会随着营销的节奏产生异常值，比如双十一的时候，如果商家都在促销就会产生突发的大量订单。因此在做用户像的时候，还要考虑到异常值的处理。 总之，数据量是庞大的，会存在各种各样的使用情况。光是分析EB级大数据，我们就要花很长的时间。但我们的最终目的不是处理这些数据，而是理解、使用这些数据挖掘的结果。对数据的标签化能让我们快速理解一个用户，一个商品，乃至一个视频内容的特征，从而方便我们去理解和使用数据。 对数据的标签化其实考验的是我们的抽象能力，在日常工作中，我们也要锻炼自己的抽象能力，它可以让我们很快地将一个繁杂的事物简单化，不仅方便理解，还有益后续的使用。 8.数据采集从数据采集角度，把数据源分成以下四类 这四类数据源包括了：开放数据源、爬虫抓取、传感器和日志采集。它们各有特点。 开放数据源一般是针对行业的数据库。比如美国人口调查局开放了美国的人口信息、地区分布和教育情况数据。除了政府外，企业和高校也会开放相应的大数据，这方面北美相对来说做得好一些。国内，贵州做了不少大胆尝试，搭建了云平台，逐年开放了旅游、交通、商务等领域的数据量。 要知道很多研究都是基于开放数据源进行的，否则每年不会有那么多论文发表，大家需要相同的数据集才能对比出算法的好坏。 爬虫抓取，一般是针对特定的网站或App。如果我们想要抓取指定的 ，比如购物网站上的购物评价等，就需要我们做特定的爬虫抓取。 第三类数据源是传感器，它基本上采集的是物理信 图像、视频、或者某个物体的速度、热度、压强等。 最后是日志采集，这个是统计用户的操作。 升 可以在前端进行埋点，在后端进行脚本收集、统计，来分析网站的访问情况，以及使用瓶颈等。 开放数据源开放数据源可以从两个维度来考虑，一个是单位的维度，比如政府、企业、高校；一个就是行业维度，比如交通、金融、能源等领域。这方面，国外的开放数据源比国内做得好一些，当然近些年国内的政府和高校做开放数据源的也越来越多。一方面服务社会，另一方面自己的影响力也会越来越大。 比如，下面这张表格列举的就是单位维度的数据源。 所以如果想找某个领域的数据源，比如金融领域，基本上可以看下政府、高校、企业是否有开放的数据源。当然你也可以直接搜索金融开放数据源。 爬虫抓取爬虫抓取应该属于最常见的需求，比如你想要餐厅的评价数据。当然这里要注重版权问题，而且很多网站也是有反爬机制的。 最直接的方法就是使用Python编写爬虫代码，当然前提是你需要会Python的基本语法。除此之外，PHP也可以做爬虫，只是功能不如Python完善，尤其是涉及到多线程的操作。 在Python爬虫中，基本上会经历三个过程。 使用 Requests 爬取内容。我们可以使用 Requests库来抓取网页信息。Requests库可以说是 Python爬虫的利器，也就是Python的HTTP 库，通过这个库爬取网页中的数据，非常方便，可以帮我们节约大量的时间。 使用 XPath 解析内容。XPath 是XML Path的缩写，也就是XML 路径语言。它是一种用来确定 XML 文档中某部分位置的语言，在开发中经常用来当作小型查询语言。XPath可以通过元素和属性进行位置索引。 使用 Pandas 保存数据。Pandas 是让数据分析工作变得更加简单的高级数据结构，我们可以用 Pandas保存爬取的数据， 最后通过Pandas再写入到XLS或者MySQL等数据库中。 Requests、XPath、Pandas是Python的三个利器。当然做Python爬虫还有很多利器，比如Selenium，PhantomJS，或者用Puppteteer这种无头模式。 另外我们也可以不编程就抓取到网页信息，这里介绍三款常用的抓取工具。 火车采集器 火车采集器已经有13年历史了，是老牌的采集工具。它不仅可以做抓取工具，也可以做数据清洗、数据分析、数据挖掘和可视化等工作。数据源适用于绝大部分的网页，网页中能看到的内容都可以通过采集规则进行抓取。 八爪鱼 八爪鱼也是知名的采集工具，它有两个版本，一个就是免费的采集模板，还有一个就是云采集（付费）。 免费的采集模板实际上就是内容采集规则，包括了电商类、生活服务类、 社 和论坛类的网站都可以采集，用起来非常方便。当然你也可以自己来自定义任务。 那什么是云采集呢？就是当你配置好采集任务，就可以交给八爪鱼的云端进行采集。八爪鱼一共有5000台服务器，通过云端多节点并发采集，采集速度远远超过本地采集，此外还可以自动切换多个IP，避免IP被封，影响采集。 做过工程项目的同学应该能体会到，云采集这个功能太方便了，很多时候自动切换IP以及云采集才是自动化采集的关键。 集搜客 这个工具的特点是完全可视化操作，无需编程。整个采集过程也是所见即所得，抓取结果信息、错误信息等都反应在软件中。相比于八爪鱼来说，集搜客没有流程的概念，用户只需要关注抓取什么数据，而流程细节完全交给集搜客来处理。 但是集搜客的缺点是没有云采集功能，所有爬虫都是在用户自己电脑上跑的。 日志采集工具日志采集最大的作用，就是通过分析用户访问情况，提升系统的性能，从而提高系统承载量。及时发现系统承载瓶颈，也可以方便技术人员基于用户实际的访问情况进行优化。日志采集也是运维人员的重要工作之一。 日志就是日记的意思，它记录了用户访问网站的全过程：哪些人在什么时间，通过什么渠道（比如搜索引擎、网址输入）来过，都执行了哪些操作；系统是否产生了错误；甚至包括用户的IP、HTTP请求的时间，用户代理等。这些日志数据可以被写在一个日志文件中，也可以分成不同的日志文件，比如访问日志、错误日志等。 日志采集可以分两种形式。 通过Web服务器采集，例如 httpd、Nginx、Tomcat 都自带日志记录功能。同时很多互联网企业都有自己的海量数据采集工具，多用于系统日志采集，如Hadoop的Chukwa、Cloudera的Flume、Facebook的Scril 这些工具均采用分布式架构，能够满足每秒数百MB的日志数据采集和传输需求。 自定义采集用户行为，例如用JavaScript代码监听用户的行为、AJAX异步请求后台记录日志等。 埋点 埋点是日志采集的关键步骤。埋点就是在有需要的位置采集相应的信息，进行上报。比如某页面的访问情况，包括用户信息、设备信息；或者用户在页面上的操作行为，包括时间长短等。这就是埋点，每一个埋点就像一台摄像头，采集用户行为数据，将数据进行多维度的交叉分析，可真实还原出用户使用场景，和用户使用需求。 如何进行埋点： 埋点就是在你需要统计数据的地方植入统计代码，当然植入代码可以自己写，也可以使用第三方统计工具。按照“不重复造轮子”的原则，一般来说需要自己写的代码，一般是主营核心业务，对于埋点这类监测性的工具，市场上已经比较成熟，这里推荐使用第三方的工具，比如友盟、GoogleAnalysis、Talkingdata等。他们都是采用前端埋点的方式，然后在第三方工具里就可以看到用户的行为数据。但如果我们想要看到更深层的用户操作行为，就需要进行自定义埋点。 总结一下，日志采集有助于我们了解用户的操作数据，适用于运维监控、安全审计、业务数据分析等场景。一般Web服务器会自带日志功能，也可以使用Flume从不同的服务器集群中采集、汇总和传输大容量的日志数据。当然我们也可以使用第三方的统计工具或自定义埋点得到自己想要的统计内容。 总结 数据采集是数据分析的关键，很多时候我们会想到Python网络爬虫，实际上数据采集的方法、渠道很广，有些可以直接使用开放的数据源，比如想获取比特币历史的价格及交易数据，可以直接从Kaggle上下载，不需要自己爬取。另一方面根据我们的需求，需要采集的数据也不同，比如交通行业，数据采集会和摄像头或者测速仪有关。对于运维人员，日志采集和分析则是关键。所以我们需要针对特定的业务场景，选择适合的采集工具。 9.数据采集：使用八爪鱼采集微博上的D&amp;G评论（八爪鱼，竟然没有mac版） 10.Python爬虫11.数据清洗整个数据分析过程中，不管时间还是功夫，数据清洗都占到了80% 数据清洗规则完整性：单条数据是否存在空值，统计的字段是否完善。 全面性：观察某一列的全部数值，比如在Excel表中，我们选中一列，可以看到该列的平均值、最大值、最小值。我们可以通过常识来判断该列是否有问题，比如：数据定义、单位标识、数值本身、列名。 合法性：数据的类型、内容、大小的合法性。比如数据中存在非ASCII字符，性别存在了未知，年龄超过了150岁等。 唯一性：数据是否存在重复记录，因为数据通常来自不同渠道的汇总，重复的情况是常见的。行数据、列数据都需要是唯一的，比如一个人不能重复记录多次，且一个人的体重也不能在列指标中重复记录多次。 按照以上的原则，我们能解决数据清理中遇到的大部分问题，使得数据标准、干净、连续，为后续数据统计、数据挖掘做好准备。如果想要进一步优化数据质量，还需要在实际案例中灵活使用。 Pandas举例以Pandas为例，如图数据表为例，应用数据清洗准则，给出可能遇到的问题中的一些举例。 （部分参数详细用法见前面Pandas章节） 完整性 问题1：缺失值 在数据中有些年龄、体重数值是缺失的，这往往是因为数据量较大，在过程中，有些数值没有采集到。通常我们可以采用以下三种方法： 删除：删除数据缺失的记录； 均值：使用当前列的均值； 高频：使用当前列出现频率最高的数据。 123456# 均值df['Age'].fillna(df['Age'].mean(), inplace=True)# 高频age_max = df['Age'].value_counts().index[0]df['Age'].fillna(age_max, inplace=True) 问题2：空行/列 我们发现数据中有一个空行，除了index之外，全部的值都是NaN，Pandas的read_csv并没有可选参数来忽略空行，这样，我们就需要在数据被读入之后再使用 dropna()进行处理，删除空行。 全面性 问题1：没有列头 可以使用read_csv()的names参数 1234# 增加列头column_names= ['id', 'name', 'age', 'weight','m0006','m0612','m1218','f0006','f0612','f1218']df = pd.read_csv('../data/patient_heart_rate.csv', names = column_names)df.head() 问题2：列数据的单位不统一 weight列的单位不统一，有的单位是千克（kgs），有的单位是磅（Ibs） 12345# 获取 weight 数据列中单位为 lbs 的数据# rows_with_lbs得到的是bool Series，包含lbs为true，否则falserows_with_lbs = df['weight'].str.contains('lbs')df[rows_with_lbs] 这里我使用千克作为统一的度量单位，将磅（Ibs）转化为千克（kgs）： 12345678910# 将 lbs 的数据转换为 kgs 数据# 遍历for i,lbs_row in df[rows_with_lbs].iterrows(): # i每次循环分别是1、4、5、9 # lbs_row是每个i的列名-value # 字符串转float，计算后转int weight = int(float(lbs_row['weight'][:-3])/2.2) # 拼接、赋值 df.at[i,'weight'] = '&#123;&#125;kgs'.format(weight) 问题3：一列有多个参数 Name 列包含了两个参数 Firtname 和 Lastname 123# 切分名字，删除源数据列df[['first_name','last_name']] = df['name'].str.split(expand=True)df.drop('name', axis=1, inplace=True) 例1：规范化数据类型 read_csv()的dtype参数 例2：大小写不统一、删除额外空格 data[‘’].str.upper()data[‘’].str.strip() 例3：重命名列名 rename() 合理性 问题1：非ASCII字符 在数据集中 Fristname 和 Lastname 有一些非 ASCII ，可以删除、替换、或者仅仅提示一下 这里使用删除方法： 123# 删除非 ASCII 字符df['first_name'].replace(&#123;r'[^\\x00-\\x7F]+':''&#125;, regex=True, inplace=True)df['last_name'].replace(&#123;r'[^\\x00-\\x7F]+':''&#125;, regex=True, inplace=True) 唯一性 问题1：重复数据 我们校验一下数据中是否存在重复记录。如果存在重复记录，就使用 Pandas 提供的 drop_duplicates(）来删除重复数据。 12# 删除重复数据行df.drop_duplicates(['first_name','last_name'],inplace=True) 12.数据集成我们采集的数据经常会有冗余重复的情况。举个简单的例子，假设你是一个网络综艺节目的制片人，一共有12期节目，你一共打算邀请30位明星作为节目的嘉宾。你知道这些明星影响力都很大，具体在微博上的粉丝数都有标记。于是你想统计下，这些明星一共能直接影响到微博上的多少粉丝，能产生多大的影响力。 然后你突然发现，这些明星的粉丝数总和超过了20亿。那么他们一共会影响到中国20亿人口么？显然不是的，那么如何统计这30位明星真实的影响力总和呢？这里就需要用到数据集成的概念了。 数据集成就是将多个数据源合并存放在一个数据存储中（如数据仓库），从而方便后续的数据挖掘工作。 据统计，大数据项目中80%的工作都和数据集成有关，这里的数据集成有更广泛的意义，包括了数据清洗、数据抽取、数据集成和数据变换等操作。这是因为数据挖掘前，我们需要的数据往往分布在不同的数据源中，需要考虑字段表达是否一样，以及属性是否冗余。 数据集成的两种架构：ELT和ETLETL：Extract、Transform和Load的缩写，顾名思义它包括了数据抽取、转换、加载三个过程。ETL可以说是进行数据挖掘这项工作前的“备菜”过程。 抽取：将数据从已有的数据源中提取出来。 转换：对原始数据进行处理，例如将表输入1和表输入2进行连接形成一张新的表。 根据转换发生的顺序和位置，数据集成可以分为ETL和ELT两种架构。 ETL 的过程为提取（Extract)- -转换(Transform)— -加载(Load)，在数据源抽取后首先进行转换，然后将转换的结果写入目的地。 ELT 的过程则是提取(Extract)——加载(Load)——变换(Transform)，在抽取后将结果先写入目的地，然后利用数据库的聚合分析能力或者外部计算框架，如Spark来完成转换的步骤。 目前数据集成的主流架构是ETL，但未来使用ELT作为数据集成架构的将越来越多。这样做会带来多种好处： ELT 和 ETL 相比，最大的区别是“重抽取和加载，轻转换”，从而可以用更轻量的方案搭建起一个数据集成平台。使用ELT方法，在提取完成之后，数据加载会立即开始。一方面更省时，另一方面ELT允许BI分析人员无限制地访问整个原始数据，为分析师提供了更大的灵活性，使之能更好地支持业务。 在ELT架构中，数据变换这个过程根据后续使用的情况，需要在 SQL中进行，而不是在加载阶段进行。这样做的好处是你可以从数据源中提取数据，经过少量预处理后进行加载。这样的架构更简单，使分析人员更好地了解原始数据的变换过程。 ETL工具典型的ETL工具有： 商业软件：Informatica PowerCenter、IBM InfoSphere DataStage、Oracle Data Integrator、Microsoft SQL Server、Integration Services等 开源软件：Kettle、Talend、Apatar、Scriptella、DataX、Sqoop等 相对于传统的商业软件，Kettle是一个易于使用的，低成本的解决方案。国内很多公司都在使用Kettle用来做数据集成。 Kettle工具的使用 Kettle是一款国外开源的ETL工具，纯Java编写，可以在Window和Linux上运行，不需要安装就可以使用。Kettle 中文名称叫水壶，该项目的目标是将各种数据放到一个壶里，然后以一种指定的格式流出。 Kettle的控件比较多，一个Kettle的开源社区：http://www.ukettle.org. Kettle相比其他工具上手简单，而且是开源工具，有问题可以在社群里咨询。因此推荐使用Kettle作为你的第一个ETL工具。 当然除了Kettle工具，实际工作中，你可能也会接触到其他的ETL工具，比如阿里巴巴的开源工具DataX和Apache的Sqoop. （具体这几个工具的使用待学习） 13.数据变换考试成绩基本上都会满足正态分布的情况。为了让成绩符合正态分布，出题老师通常可以把考题分成三类：第一类：基础题，占总分70%，基本上属于送分题；第二类：灵活题，基础范围内+一定的灵活性，占20%；第三类：难题，涉及知识面较广的难题，占10%。如果一个出题老师没有按照上面的标准来出题，而是将第三类难题比重占到了70%，也就是“超纲”，结果会是大部分人成绩都“不及格” ，最后在大家激烈的讨论声中，老师会将考试成绩做规范化处理，从而让成绩满足正态分布的情况。 再举个例子，假设A考了80分，B也考了80分，但前者是百分制，后者500分是满分，如果我们把从这两个渠道收集上来的数据进行集成、挖掘，就算使用效率再高的算法，结果也不是正确的。因为这两个渠道的分数代表的含义完全不同。 所以说，有时候数据变换比算法选择更重要，数据错了，算法再正确也是错的。 如何让不同渠道的数据统一到一个目标数据库里呢？这样就用到了数据变换。 在数据变换前，我们需要先对字段进行筛选，然后对数据进行探索和相关性分析，接着是选择算法模型（这里暂时不需要进行模型计算），然后针对算法模型对数据的需求进行数据变换，从而完成数据挖掘前的准备工作。 所以你从整个流程中可以看出，数据变换是数据准备的重要环节，它通过数据平滑、数据聚集、数据概化和规范化等方式将数据转换成适用于数据挖掘的形式。 常见的变换方法数据平滑：去除数据中的噪声，将离散数据连续化。这里可以采用分箱、聚类和回归的方式进行数据平滑。（后面会有聚类和回归这两个算法） 数据聚集：对数据进行汇总，在SQL中有一些聚集函数可以供我们操作，比如Max()反馈某个字段的数值最大值，Sum()返回某个字段的数值总和； 数据概化：将数据由较低的概念抽象成为较高的概念，减少数据复杂度，即用更高的概念替代更低的概念。比如说上海、杭州、深圳、北京可以概化为中国。 数据规范化：使属性数据按比例缩放，这样就将原来的数值映射到一个新的特定区域中。常用的方法有最小一最大规范化、Z—score 规范化、按小数定标规范化等。（后面会有这些方法的使用） 属性构造：构造出新的属性并添加到属性集中。这里会用到特征工程的知识，因为通过属性与属性的连接构造新的属性，其实就是特征工程。比如说，数据表中统计每个人的英语、语文和数学成绩，可以构造“总和”这个属性，来作为新属性，用到后续的数据挖掘计算中。 在这些变换方法中，最简单易用的就是对数据进行规范化处理。下面我来给你讲下如何对数据进行规范化处理。 数据规范化的几种方法 Min-max规范化 Min-max规范化方法是将原始数据变换到[0,1]的空间中。公式： 新数值=（原数值-极小值）/（极大值-极小值）。 Z-Score 规范化 假设A与B的考试成绩都为80分，A的考卷满分是100分（及格60分），B的考卷满分是500分（及格300分）。虽然两个人都考了80分，但是A的80分与B的80分代表完全不同的含义。 Z-Score就是用来可以解决这一问题的。公式： 新数值=（原数值-均值）/标准差。 假设A所在的班级平均分为80，标准差为10。B所在的班级平均分为400，标准差为100。那么A的新数值=(80-80)/10=0，B的新数值=(80-400)/100=-3.2。那么在Z-Score标准下，A的成绩会比B的成绩好。 我们能看到Z-Score的优点是算法简单，不受数据量级影响，结果易于比较。不足在于，它需要数据整体的平均值和方差，而且结果没有实际意义，只是用于比较。 小数定标规范化 小数定标规范化就是通过移动小数点的位置来进行规范化。小数点移动多少位，取决于属性A的取值中的最大绝对值。 举个例子，比如属性A的取值范围是-999到88，那么最大绝对值为999，小数点就会移动3位，即新数值=原数值/1000。那么A的取值范围就被规范化为-0.999到0.088。 Python的SciKit-Learn库使用SciKit-Learn是Python的童要机器学习库，它帮我们封装了大量的机器学习算法，比如分类、聚类、回归、降维等。此外，它还包括了数据变换模块。我现在来讲下如何使用SciKit-Learn进行数据规范化。 Min-max 规范化 SciKit-Learn库中 preprocessing.MinMaxScaler()：给定参数一个最大值与最小值，feature_range=（min,max），然后将原数据投射到[min, max]中。默认情况下[min,max]是[0,1]，也就是把原始数据投放到[0,1]范围内。 1234567891011121314from sklearn import preprocessingimport numpy as np# 初始化数据，每一行表示一个样本，每一列表示一个特征x = np.array([[ 0., -3., 1.], [ 3., 1., 2.], [ 0., 1., -1.]])# 将数据进行[0,1]规范化minmax_x = preprocessing.MinMaxScaler().fit_transform(x)print (minmax_x)# [2,3]minmax_x = preprocessing.MinMaxScaler(feature_range=(2, 3)).fit_transform(x) 运行结果： 123[[0. 0. 0.66666667] [1. 1. 1. ] [0. 1. 0. ]] z-Score规范化 123456789# 将数据进行Z-Score规范化scaled_x = preprocessing.scale(x)print (scaled_x)# 另一种方法from sklearn.preprocessing import StandardScalerss = StandardScaler()scaled_x = ss.fit_transform(x) 运行结果： 123[[-0.70710678 -1.41421356 0.26726124] [ 1.41421356 0.70710678 1.06904497] [-0.70710678 0.70710678 -1.33630621]] 这个结果实际上就是将每行每列的值减去了平均值，再除以方差的结果。 我们看到Z-Score规范化将数据集进行了规范化，数值都符合均值为0，方差为1的正态分布。 小数定标规范化 需要用NumPy库来计算小数点的位数。 这里我们看下运行代码： 12345# 小数定标规范化# max(abs(x)）得最大绝对值，log10后 ceil 向上取整，得到位数，**为python取幂j = np.ceil(np.log10(np.max(abs(x))))scaled_x = x/(10**j)print (scaled_x) 运行结果： 123[[ 0. -0.3 0.1] [ 0.3 0.1 0.2] [ 0. 0.1 -0.1]] 14.数据可视化常用的可视化视图超过 20 种，分别包括：文本表、热力图、地图、符号地图、饼图、水平条、堆叠条、并排条、树状图、圆视图、并排圆、线、双线、面积图、双组合、散点图、直方图、盒须图、甘特图、靶心图、气泡图等。 数据可视化的工具： 商业智能分析：Tableau 和、PowerBI、FineBI 可视化大屏类：DataV 和 FineReport 前端可视化组件：Canvas、SVG 和 WebGL，Echarts、D3、Three.js 和 AntV 编程语言：Python （Matplotlib、Seaborn、Bokeh、Plotly、Pyecharts、Mapbox 和 Geoplotlib）， R （自带的绘图包 Graphics 以及工具包ggplot2、ggmap、timevis 和 plotly ） 15.Python数据可视化的10种技能如果想要用Python进行数据分析，就需要在项目初期开始进行探索性的数据分析，这样方便对数据有一定的了解。其中最直观的就是采用数据可视化技术，这样，数据不仅一目了然，而且更容易被解读。同样在数据分析得到结果之后，我们还需要用到可视化技术，把最终的结果呈现出来。 可视化视图有哪些按照数据之间的关系，我们可以把可视化视图划分为4类，它们分别是比较、联系、构成和分布： 比较：比较数据间各类别的关系，或者是它们随着时间的变化趋势，比如折线图； 联系：查看两个或两个以上变量之间的关系，比如散点图； 构成：每个部分占整体的百分比，或者是随着时间的百分比变化，比如饼图； 分布：关注单个变量，或者多个变量的分布情况，比如直方图。 按照变量的个数，我们可以把可视化视图划分为单变量分析和多变量分析。 单变量分析：一次只关注一个变量 多变量分析：一张图上可以查看两个以上变量的关系。从而分析出变量之间是否存在某种联系。 可视化的视图可以说是分门别类，多种多样，介绍常用的10种视图，这些视图包括了散点图、折线图、直方图、条形图、箱线图、饼图、热力图、蜘蛛图、二元变量分布和成对关系。 散点图散点图的英文叫做scatter plot，它将两个变量的值显示在二维坐标中，非常适合展示两个变量之间的关系。当然，除了二维的散点图，我们还有三维的散点图。 工具 解释 Matplotlib工具 pyplot 它包括了很多绘图函数，类似Matlab的绘图框架 import matplotlib.pyplot as plt plt.scatter() (x, y, marker=None)x、y 是坐标，marker代表了标记的符号。比如“x”、“&gt;”或者“o”。选择不同的marker，呈现出来的符号样式也会不同 Seaborn工具 import seaborn as sns sns.jointplot() (x, y, data=None, kind=‘scatter’)x、y是data中的下标。data就是我们要传入的数据，一般是DataFrame类型。kind这类我们取scatter，代表散点的意思。当然kind还可以取其他值 好了，让我们来模拟下，假设我们的数据是随机的1000个点。 12345678910111213# 数据准备N = 1000x = np.random.randn(N)y = np.random.randn(N)# 用Matplotlib画散点图plt.scatter(x, y,marker='x')plt.show()# 用Seaborn画散点图df = pd.DataFrame(&#123;'x': x, 'y': y&#125;)sns.jointplot(x=\"x\", y=\"y\", data=df, kind='scatter');plt.show() Matplotlib和Seaborn的视图呈现还是有差别的。Matplotlib默认情况下呈现出来的是个长方形。而Seaborn呈现的是个正方形，而且不仅显示出了散点图，还给了这两个变量的分布情况。 Matplotlib绘制： Seaborn绘制： 折线图折线图可以用来表示数据随着时间变化的趋势。 工具 解释 Matplotlib plt.plot() 需要提前把数据按照x轴的大小进行排序，要不画出来的折线图就无法按照x轴递增的顺序展示 Seaborn sns.lineplot() (x, y, data=None)x、y是data中的下标。data就是我们要传入的数据，一般是DataFrame类型。 这里我们设置了x、y的数组。x数组代表时间（年），y数组随便设置几个取值。下面是详细的代码。 123456789101112# 数据准备x = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]y = [5, 3, 6, 20, 17, 16, 19, 30, 32, 35]# 使用Matplotlib画折线图plt.plot(x, y)plt.show()# 使用Seaborn画折线图df = pd.DataFrame(&#123;'x': x, 'y': y&#125;)sns.lineplot(x=\"x\", y=\"y\", data=df)plt.show() 这两个图示的结果是完全一样的，只是在seaborn中标记了x和y轴的含义。 Matplotlib绘制： Seaborn绘制： 直方图直方图是比较常见的视图，它是把横坐标等分成了一定数量的小区间，这个小区间也叫作“箱子”，然后在每个“箱子”内用矩形条（bars）展示该箱子的箱子数（也就是y值），这样就完成了对数据集的直方图分布的可视化 工具 解释 Matplotlib plt.hist() (x, bins=10)x是一维数组，bins代表直方图中的箱子数量，默认是10直方图纵坐标为区间内分布个数 Seaborn sns.distplot() (x, bins=10, kde=True)x是一维数组bins：直方图中的箱子数量kde：显示核密度估计，默认是True，我们也可以把kde设置为False，不进行显示。显示kde时，直方图高度显示默认为密度（且不能更改），kde为False时，默认高度显示为计数（可更改）hist：是否显示直方图，默认Truenorm_hist：若为True, 则直方图高度显示密度而非计数rag：控制是否生成观测数值的小细条fit：控制拟合的参数分布图形，能够直观地评估它与观察数据的对应关系(黑色线条为确定的分布) 1234567891011# 数据准备a = np.random.randn(100)s = pd.Series(a) # 用Matplotlib画直方图plt.hist(s)plt.show()# 用Seaborn画直方图sns.distplot(s, bins=10, kde=True)plt.show() Matplotlib绘制： Seaborn绘制： 核密度估计图 工具 解释 Seaborn sns.kdeplot() (x,cumulative=) cumulative ：是否绘制累积分布，默认falseshade：若为True，则在kde曲线下面的区域中进行阴影处理，默认falsecolor：控制曲线及阴影的颜色vertical：表示以X轴进行绘制还是以Y轴进行绘制，默认False，x轴 (x,y, ) 二元cbar：参数若为True，则会添加一个颜色棒，默认False(颜色帮在二元kde图像中才有) 12345678x=np.random.randn(100) #随机生成100个符合正态分布的数sns.kdeplot(x)# sns.kdeplot(x,cumulative=True)sns.kdeplot(x,shade=True,color=\"g\")y=np.random.randn(100)sns.kdeplot(x,y,shade=True,cbar=True) 条形图如果说通过直方图可以看到变量的数值分布，那么条形图可以帮我们查看类别的特征。 在条形图中，长条形的长度表示类别的频数，宽度表示类别。 工具 解释 Matplotlib plt.bar() (x, height)函数，其中参数x代表x轴的位置序列，height是y轴的数值序列，也就是柱子的高度。 Seaborn sns.barplot() (x=None, y=None, data=None)data为DataFrame类型，x、y是data中的变量。 1234567891011# 数据准备x = ['Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5']y = [5, 4, 8, 12, 7]fig,axes=plt.subplots(1,2)# 用Matplotlib画条形图axes[0].bar(x, y)# 用Seaborn画条形图sns.barplot(x, y, ax=axes[1])plt.show() 箱线图箱线图，又称盒式图，它是在1977年提出的，由五个数值点组成：最大值(max)、最小值(min)、中位数(median)和上下四分位数(Q3, Q1)。它可以帮我们分析出数据的差异性、离散程度和异常值等。 工具 解释 Matplotlib plt.boxplot() (x, labels=None)x：要绘制箱线图的数据labels：缺省值，可以为箱线图添加标签。(标签类似于列名) Seaborn sns.boxplot() (x=None, y=None, data=None)data为DataFrame类型x、y是data中的变量。 12345678910111213# 数据准备# 生成0-1之间的10*4维度数据(每一维度10个数，四个维度)data=np.random.normal(size=(10,4)) lables = ['A','B','C','D']fig,axes=plt.subplots(1,2)# 用Matplotlib画箱线图axes[0].boxplot(data,labels=lables)# 用Seaborn画箱线图df = pd.DataFrame(data, columns=lables)sns.boxplot(data=df, ax=axes[1])plt.show() 关于箱线图检测异常值 123456789101112131415161718192021222324252627# -*- coding: utf-8 -*-import pandas as pdcatering_sale = '../data/catering_sale.xls' # 餐饮数据data = pd.read_excel(catering_sale, index_col = u'日期') # 读取数据，指定“日期”列为索引列print(data)import matplotlib.pyplot as plt # 导入图像库# plt.rcParams['font.sans-serif'] = ['SimHei'] # 用来正常显示中文标签# plt.rcParams['axes.unicode_minus'] = False # 用来正常显示负号plt.figure() # 建立图像p = data.boxplot(return_type='dict') # 画箱线图，直接使用DataFrame的方法x = p['fliers'][0].get_xdata() # 'flies'即为异常值的标签y = p['fliers'][0].get_ydata()y.sort() # 从小到大排序，该方法直接改变原对象#用annotate添加注释#其中有些相近的点，注解会出现重叠，难以看清，需要一些技巧来控制。#以下参数都是经过调试的，需要具体问题具体调试。for i in range(len(x)): if i&gt;0: plt.annotate(y[i], xy = (x[i],y[i]), xytext=(x[i]+0.05 -0.8/(y[i]-y[i-1]),y[i])) else: plt.annotate(y[i], xy = (x[i],y[i]), xytext=(x[i]+0.08,y[i]))plt.show() #展示箱线图 1 饼图饼图是常用的统计学模块，可以显示每个部分大小与总和之间的比例。在Python数据可视化中，它用的不算多。我们主要采用Matplotlib的pie函数实现它。 Matplotlib plt.pie(x, labels=None) x代表要绘制饼图的数据，labels是缺省值，可以为饼图添加标签 这里设置了lables数组，分别代表高中、本科、硕士、博士和其他几种学历的分类标签。nums代表这些学历对应的人数。 123456# 数据准备nums = [25, 37, 33, 37, 6]labels = ['High-school','Bachelor','Master','Ph.d', 'Others']# 用Matplotlib画饼图plt.pie(x = nums, labels=labels)plt.show() 热力图热力图，英文叫heat map，是一种矩阵表示方法，其中矩阵中的元素值用颜色来代表，不同的颜色代表不同大小的值。通过颜色就能直观地知道某个位置上数值的大小。另外你也可以将这个位置上的颜色，与数据集中的其他位置颜色进行比较。 热力图是一种非常直观的多元变量分析方法。 一般使用Seaborn中的sns.heatmap(data)函数，其中data代表需要绘制的热力图数据。 这里使用Seaborn中自带的数据集flights，该数据集记录了1949年到1960年期间，每个月的航班乘客的数量。 1234567# 数据准备flights = sns.load_dataset(\"flights\")data=flights.pivot('year','month','passengers')# 用Seaborn画热力图sns.heatmap(data)plt.show() （此处运行导入fights数据集失败，问题同成对关系） 通过seaborn的heatmap函数，可以观察到不同年份，不同月份的乘客数量变化情况，其中颜色越浅的代表乘客数量越多 蜘蛛图蜘蛛图是一种显示一对多关系的方法。在蜘蛛图中，一个变量相对于另一个变量的显著性是清晰可见的。 假设我们想要给王者荣耀的玩家做一个战力图，指标一共包括推进、KDA、生存、团战、发育和输出。那该如何做呢？ 这里我们需要使用Matplotlib来进行画图：首先设置两个数组：labels和stats。他们分别保存了这些属性的名称和属性值。 因为蜘蛛图是一个圆形，需要计算每个坐标的角度，然后对这些数值进行设置。当画完最后一个点后，需要与第一个点进行连线。 因为需要计算角度，所以我们要准备angles数组；又因为需要设定统计结果的数值，所以我们要设定stats数组。并且需要在原有angles和stats数组上增加一位，也就是添加数组的第一个元素。一些画图函数 1234567891011121314151617# 数据准备labels=np.array([u\"推进\",\"KDA\",u\"生存\",u\"团战\",u\"发育\",u\"输出\"])stats=[83, 61, 95, 67, 76, 88]# 画图数据准备，角度、状态值angles=np.linspace(0, 2*np.pi, len(labels), endpoint=False)stats=np.concatenate((stats,[stats[0]]))angles=np.concatenate((angles,[angles[0]]))# 用Matplotlib画蜘蛛图fig = plt.figure()ax = fig.add_subplot(111, polar=True) ax.plot(angles, stats, 'o-', linewidth=2)ax.fill(angles, stats, alpha=0.25)ax.set_thetagrids(angles * 180/np.pi, labels)plt.show() plt.figure是创建一个空白的figure对象，这样做的目的相当于画画前先准备一个空白的画板。 add_subplot(111)可以把画板划分成1行1列。 ax.plot和ax.fill进行连线以及给图形上色。 最后set_thetagrids在相应的位置上显示出属性名。 这里需要用到中文，Matplotlib对中文的显示不是很友好，需要设置中文字体https://www.zhihu.com/question/25404709，u&quot;中文&quot; 二元变量分布如果我们想要看两个变量之间的关系，就需要用到二元变量分布。当然二元变量分布有多种呈现方式，开头给你介绍的散点图就是一种二元变量分布。 Seaborn sns.jointplot(x, y, data=None, kind) kind表示不同的视图类型：“kind=‘scatter’”代表散点图，“kind=‘kde’”代表核密度图，“kind=‘hex’ ”代表Hexbin图，它代表的是直方图的二维模拟。 这里我们使用Seaborn中自带的数据集tips，这个数据集记录了不同顾客在餐厅的消费账单及小费情况。代码中total_bill保存了客户的账单金额，tip是该客户给出的小费金额。我们可以用Seaborn中的jointplot来探索这两个变量之间的关系。 1234567891011121314# 数据准备# 此处调用Seaborn中自带的数据集tips，需要联网# 会遇到 错误，是验证错误，下面两行解决import sslssl._create_default_https_context = ssl._create_unverified_contexttips = sns.load_dataset(\"tips\")print(tips.head(10))# 用Seaborn画二元变量分布图（散点图，核密度图，Hexbin图）sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='scatter')sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='kde')sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='hex')plt.show() 成对关系如果想要探索数据集中的多个成对双变量的分布，可以直接采用sns.pairplot()函数。 它会同时展示出DataFrame中每对变量的关系，另外在对角线上，你能看到每个变量自身作为单变量的分布情况。它可以说是探索性分析中的常用函数，可以很快帮我们理解变量对之间的关系。 pairplot函数的使用，就像在DataFrame中使用describe()函数一样方便，是数据探索中的常用函数。 这里我们使用Seaborn中自带的iris数据集，这个数据集也叫鸢尾花数据集。鸢尾花可以分成Setosa、Versicolour和Virginica三个品种，在这个数据集中，针对每一个品种，都有50个数据，每个数据中包括了4个属性，分别是花萼长度、花萼宽度、花瓣长度和花瓣宽度。通过这些数据，需要你来预测鸢尾花卉属于三个品种中的哪一种。 12345# 数据准备iris = sns.load_dataset('iris')# 用Seaborn画成对关系sns.pairplot(iris)plt.show() 这里我们用Seaborn中的pairplot函数来对数据集中的多个双变量的关系进行探索，如下图所示。从图上你能看出，一共有sepal_length、sepal_width、petal_length和petal_width4个变量，它们分别是花萼长度、花萼宽度、花瓣长度和花瓣宽度。 （此处导入数据集失败，urllib.error.URLError: &lt;urlopen error [Errno 61] Connection refused&gt;，还没解决。tips数据集导入没有问题，iris有问题） 一些画图函数多画布plt.subplots(nrows, ncols) 以直方图举例 1234fig,axes=plt.subplots(1,3) #创建一个一行三列的画布sns.distplot(x,ax=axes[0]) #左图sns.distplot(x,hist=False,ax=axes[1]) #中图sns.distplot(x,kde=False,ax=axes[2]) #右图 matplotlib中：axes[0].bar()形式 seaborn中：sns.barplot( ,ax=axes[1])形式 title1axes[0].set_title('1')","categories":[{"name":"python","slug":"python","permalink":"http://mangosTeeN96.github.io/categories/python/"}],"tags":[{"name":"数据分析","slug":"数据分析","permalink":"http://mangosTeeN96.github.io/tags/数据分析/"}]},{"title":"Python基础","slug":"Python基础","date":"2019-12-20T05:13:27.000Z","updated":"2020-06-19T08:35:46.441Z","comments":true,"path":"2019/12/20/Python基础/","link":"","permalink":"http://mangosTeeN96.github.io/2019/12/20/Python基础/","excerpt":"","text":"python基础python的介绍 符号 解释 python xxx.py 执行 python 交互模式 &gt;&gt;&gt; exit()退出 ipython 即支持python命令，也支持Linux命令 exit 退出 # 单行注释（一般解释下方or左侧代码） ‘’’换行‘’‘ 多行注释 “”“换行”“” 同上 #coding =utf-8 写在首行可解决python2不能识别中文（我没有python2） #-*- coding:utf-8 -*- 同上 变量以及类型变量是一个容器，可以保存数据 变量值 = 值 如果 变量值=xxxx 是第一次出现的话，那么就表示定义了一个变量； 如果 变量值=xxxx 不是第一次出现。那么就是给这个已知变量赋上一个值。 变量名：必须字母、数字、_构成，且数字不能开头 建议用英文单词，单词之间用_。 如果已经定义，再次使用时，可以Ctrl+a，调用 关键字：Python已经使用，不允许自己再定义 标识符：自己定义的 查看关键字： import keyword keyword.kwlist 运算符 “=”*10 输出的是十个= 符号 解释 type（） 判断类型 int（） 转换类型 float（）浮点数；str（）字符串（更多见下方截图） input 获取用户输入的信息 input(“”)打印“”中内容，等待输入 获取数据默认 字符串类型 print 打印 print(“”)直接打印“”中内容 print(“%d”%变量名）打印变量值；%d 整型（数值）、%s字符（更多见下方截图） 一个print输出多个值：print（“%s%s%d…”%（变量名1，变量名2，变量名3，…）） 若只是打印一个变量值，可以直接print（i） print（“*”，end=“”）后面加的，end=“” ，可以使print打印结果不换行；想换行可以print（“”） if、while、for if if 条件： 条件成立做的事（必须有tab键） else： 条件不成立做的事 elif if 条件1： xxxx1 elif 条件2： xxxx2 …… else：（可以没有else） xxxx if 嵌套 （常见嵌套一个） while 循环 while 条件： 条件满足时执行 while 嵌套 break 立即停止循环 continue continue 后面的不执行，直接进行下一次循环 while True 死循环 for 循环 for in for num in range(10) for else for循环结束之后执行一次else（不常用） else只有for中有break才不支持 while循环是条件循环，在while循环中对于变量的计算更加灵活。因此while循环适合循环次数不确定的循环，而for循环的条件相对确定，适合固定次数的循环。 比较运算符 == 等于（判断） ！= 不等于 &gt;= &lt;= 逻辑运算符 or and not not() 字符串、列表、字典、元组、集合字符串： 名词 解释 数值 一个字节最大值为255（100 占一个字节） 字符串 每个字符占一个字节 字符串可以直接用 + 合并连接 f = “===%s===”%（a+b） 也可以 字符串下标 name = “abcde” name[2] = ‘c’ name[-1] = ‘e’ 切片 name[2:5] 取下标2到4（取不到5） name[2:] 取到最后一个 name[2:-1:2] 2为步长，隔一个取一个 倒序 步长取-1 name[::-1] 字符串常见操作 mystr. (mystr是任意字符串） 可以查看所有字符串操作 mystr.find(“”) 从字符串中查找，返回首字母下标，若没有，返回-1，若有多个，返回的是从左侧数第一个 mystr.rfind(“”) 从右侧开始查找 mystr.index 找到，返回同find，找不到，返回异常 mystr.rindex mystr.count 统计个数 mystr.replace 替换，但是字符串本身不更改，只是得到一个结果 (“”,””,1) 1为多个时的替换个数 mystr.capitalize 把字符串第一个字符大写 .title 每个单词首字母大写 .lower 大写转小写（用户输入可能不是yes小写） .upper 小写转大写 .startswith 是否已xxx开头 .endswith 结尾 （可以判断文件名后缀） .ljust(50) 内容靠左对齐，字符串长度50 .rjust 右 .center 居中 .lstrip() 删除左边空格 .rstrip 右边 .strip 全部 .split 按（“”）内内容切割，（切割后（）内内容没有了） （）啥都不写，默认按空格，\\t等空白字符切割 .partition 切割（）内为一部分，前面为一部分，后面为一部分，（空格不会删除）（从左侧找到第一个切割） .rpartition 从右侧找 .splitlines 按行切割 .isalpha 判断是否字符串中都是字母 .isdigit 都是数字 .isalnum 是字母和数字 b.join(a) 用b连接a a = “abc” b = “123” print(“%s”%b.join(a)) –&gt; a123b123c “ ”.join(a) 用空格连接 “”.join(a) 直接连接 for temp in mystr print(temp) 打印出mystr中的每个元素 列表： 列表 names = [“老王”,”老李”,11] 定义了一个列表 増 names.append(“”) 添加到原有列表最后可append列表，直接将列表作为一个元素放进去 names.insert (位置，要添加的内容） + 可以将两个列表连接 names.extend(names3) 将一个列表添加到names末尾与append不同，是列表内容拆分为单个元素加到names里面 删 names.pop() 删除列表中最后一个，并且返回最后一个的内容 names.remove(“”) 删除，多个删除从左侧第一个 下标，切片 同字符串 del names[0] 按下标删除 改 names[0]=“” 修改 查询 “” in names 返回true或false “” not in names 遍历 while循环，for循环（更简单） 字典 infor =m {键：值，键：值} 构造infor = {“name”:”laoli”}infor = {} key：value infor[“age”]=18 key不存在，添加 key存在，修改 del infor[“age”] 删除 infor[“age”] 查找，没有的话会出错 infor.get(“age”) 获取value，没有的话返回空 len（） 键值对的个数 infor.keys 列表中的key，返回一个对象 values 值 items key和value for key, val in infor.items()遍历字典内key和value infor=defaultdict( factory_function) 当查找infor[“xxx”]，xxx不在字典中时，这样构造 factory_function可以是list、set、str等等，作用是当key不存在时，返回的是工厂函数的默认值，比如list对应[ ]，str对应空字符串，set对应set( )，int对应0 列表里嵌套字典 元组 与列表相似，但元素不能改,只能查 元组内只有一个元素，则必须加，如（30，），才能表示是一个元组 集合 s=set([‘a’,’b’,’c’]) s.add(‘d’) s.remove(‘b’) print ‘c’ in s 查找某个元素是否在集合中，in 集合与字典类似，不过只储存key，不储存value 函数 函数 把具有独立功能的代码块当做整体，这个整体称之为函数 def 函数名（）： 函数名要求同变量名，英文字母、下划线、数字，数字不能开头 定义并不会执行 输入函数名（），调用函数 def 函数名（a，b） 定义了两个变量，函数中就使用a，b这两个变量；调用时函数名（num1，num2）num可以用input输入。 return 变量 返回值 变量（不一定是函数名处定义的变量）只能在定义的函数中使用 此时，result = 函数名（），调用返回值。 return a,b 返回多个值，按元组存储，调用 sh，yu = 函数名（ ，） 局部变量 全局变量 global 全局变量 之后可以在函数中更改全局变量，否则只是定义一个和全局变量名字相同的局部变量，不能更改全局变量的值。 g_a 建议避免全局变量和局部变量重名，可加前缀 列表和字典用作全局变量 不必加global，可以直接添加更改 形参 定义函数时的参数 实参 调用的时候的参数 缺省参数 形参可以给默认赋值，此时若实参没有给这个参数另外赋值，则用默认赋值，若另外给了新的赋值，则不管默认。 命名参数 若多个参数，重新赋值时按原来顺序给值，若想跳过某个有默认赋值，只能对要赋值的参数写清楚是赋给谁的（如：22，c=44）或者想不按顺序赋值也一样。 不定长参数 *args 前面的参数赋值结束后，剩下的都给它，打印出来会是一个元组。（要放在形参的最后位置）（此时调用可以用for循环） **kwargs 若多余参数有key，则按字典存到kwargs 拆包 若想把元组A当做实参赋值给args，则在实参中写为A；同理字典B赋值给kwargs，则在实参中写为B； 引用 id（），变量指向位置 可变类型 列表，字典 不能当key num+=num 会对全局变量里的字典进行更改；num=num+num不会 不可变类型 数字，字符串，元组 可以当key 递归 调用自己（注意不要死循环） 匿名函数 匿名函数 lambda 创建小型匿名函数 只能包含一个语句 sum = lambda a,b : a+b 调用 sum（10，20） 能接收任何数量的参数，只能返回一个表达式的值 匿名函数应用 nums.sort(key=lambda x:x[‘name’]) 列表里嵌套字典，排序，此处按照name排序 匿名函数当做实参 map、reduce、 filter map Map会将一个函数映射到一个输入序列的所有元素上。Map() 会根据提供的函数对指定序列做映射。 map(function_to_apply, list_of_inputs) 参数：function_to_apply：映射函数，也就是处理输入迭代类型的的每一个元素的函数。list_of_inputs：一个或多个序列。输入的序列类型：列表，集合，元组，字典及字符串。返回值： Python2 ：map直接返回列表，不管输入的迭代类型是列表，集合，元组，字典还是字符串类型。Python3：map返回迭代器，可以利用list()转为列表，只能转为列表，set(), tuple()等函数不起作用。 Python 2： 1234567891011121314151617181920a = [1, 2, 3, 4]b = map(lambda x: x*2, a) # 处理列表Out[4]: [2, 4, 6, 8]b = map(lambda x: x*2, (1,2,3)) # 处理元组Out[6]: [2, 4, 6]b = map(lambda x: x*2, &#123;1:2, 3:4, 5:6&#125;) # 处理字典，只处理键Out[8]: [2, 6, 10]b = map(lambda x: x*2, &#123;1:2, 3:4, 5:6&#125;.keys())Out[17]: [2, 6, 10]b = map(lambda x: x*2, &#123;1:2, 3:4, 5:6&#125;.values())Out[15]: [4, 8, 12]b = map(lambda x: x*2, set([1, 2, 3, 4])) # 处理集合Out[11]: [2, 4, 6, 8]b = map(lambda x: x+\"1\", \"12345\") # 处理字符串，字符串也是迭代类型Out[19]: ['11', '21', '31', '41', '51'] Python 3 123456&gt;&gt;&gt; a = [1, 2, 3, 4]&gt;&gt;&gt; b = map(lambda x: x*2, a) # 处理列表&gt;&gt;&gt; b&lt;map object at 0x0000000002B68A20&gt; # map对象&gt;&gt;&gt; list(b)[2, 4, 6, 8] 处理多个序列 想要输入和处理多个序列，需要可以支持多个参数的函数，注意的是各序列的长度必须一样，否则报错。 123# 提供了两个列表，对相同位置的列表数据进行相加&gt;&gt;&gt; map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10])[3, 7, 11, 15, 19] 123456789def multiply(x): return (x*x)def add(x): return (x+x) funcs = [multiply, add]for i in range(5): value = map(lambda x: x(i), funcs) print(list(value)) 12345[0, 0][1, 2][4, 4][9, 6][16, 8] reduce reduce() 函数会对参数序列中元素进行累积。函数将一个数据集合（列表，元组等）中的所有数据进行下列操作：用传给 reduce 中的函数 function（有两个参数）先对集合中的第 1、2 个元素进行操作，得到的结果再与第三个数据用 function 函数运算，最后得到一个结果，逐步迭代。 也就是reduce函数把前两个元素的计算结果继续和序列的下一个元素做累积计算，直到处理完所有元素，返回结果。以下两个函数等价：reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) reduce(function, iterable[, initializer]) function – 函数，有两个参数 iterable – 可迭代对象initializer – 可选，初始参数。第一次时为init的元素，如没有init则为seq的第一个元素。 返回值：返回函数计算结果。 1234567&gt;&gt;&gt;def add(x, y) : # 两数相加... return x + y... &gt;&gt;&gt; reduce(add, [1,2,3,4,5]) # 计算列表和：1+2+3+4+515&gt;&gt;&gt; reduce(lambda x, y: x+y, [1,2,3,4,5]) # 使用 lambda 匿名函数15 filter Python 2： filter() 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。Python 3：filter() 函数用于过滤序列，过滤掉不符合条件的元素，返回一个迭代器对象，如果要转换为列表，可以使用 list() 来转换，利用set转换为集合，tuple转换为元组，str转为字符串。另外注：集合是{}，列表是[]，元组是()，字典是{k1:v1, k2:v2}。注意: Pyhton2.7 返回列表，Python3.x 返回迭代器对象。 filter(function, iterable) 其接收两个参数，第一个为函数，第二个为序列，序列的每个元素作为参数传递给函数进行判断，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。function – 判断函数。过滤序列中每个元素的函数。iterable – 可迭代对象。需要过滤的序列。 12345678def is_odd(n): return n % 2 == 1 tmplist = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])newlist = list(tmplist)print(newlist) [1, 3, 5, 7, 9] （1）map函数和map函数与MapReduce的机制原理相同。map函数对序列的每一个元素进行处理，而resuce函数则两两迭代逐步计算。 （2）reduce函数和filter函数只能处理一个序列。 （3）注意在 python2 和 python3 中，map/reduce/filter 的返回值类型有所不同，python2 返回的是基本数据类型，而 python3 则返回了迭代器。 （4）filter函数很容易被for循环和for in if推导式所替代 （5）使用map、reduce、filter是为了兼顾简洁和效率，它们的循环速度比python内置的for、while循环要快得多。 文件操作 文件夹操作 打开文件 open test.py 打开一个文件(可改，可保存） https://blog.csdn.net/DJH996064549/article/details/79379374 f = open(“test.py”,””) r只读（文件必须存在）w只写（可以创建，存在则覆盖原本的）a追加（不存在创建） （其它见截图） f.close() f.read(1) 读，一个一个读；（）空则全读出来 f.write(“”) 写 f.readline() 读一行 f.readlines 读所有行，每一行当列表的一个元素 复制文件代码 大文件处理 f.seek(offset,from) offset 偏移量 from 方向 0：文件开头 1：当前位置 2：文件末尾 f.seek(0,0) 可以重复读（否则读取只能顺序下去） f.tell（） 获取当前位置 import os 文件 os.rename（“”，“”） 重命名（旧，新） os.remove（“”） 删除 文件夹 os.mkdir（“”） 创建 os.rmdir（“”） 删除 os.getcwd（） 获取当前路径 os.chdir（“../”） 改变默认路径（此处上一层） os.listdir（“./”） 获取路径目录列表（此处当前路径目录） 批量重命名 面向对象创建类就是创建对象的模板 狗 类 大黄狗 类 李四家的那只大黄狗 对象 类由3个部分构成 类的名称：类名 类的属性：一组数据 类的方法：允许对进行操作的方法（行为） 定义类 class 类名： 最初的第一个（父）类还有一种写法 class 类名（object）: 属性 tom.name = 方法 def xxx(self) 创建一个对象 tom = Cat（） 调用 tom.eat（） 魔法方法 __init__方法（初始化对象） def __init__(self): 创建对象后，python会自动调用__init__方法 __new__（创建对象） def __new__(cls): return object.__new__(cls) 默认创建，object中有 __str__方法（获取对象的描述信息） def __str__(self): return __del__方法 删除对象后，Python自动调用 即对象的引用计数为0时 sys.getrefcount（） 测量一个对象的引用计数 初级程序 中级 私有、继承、重写 私有属性（不能随意更改） __属性名 私有方法（外部不能调用） __方法名 定义类的时候，定义另一个公有方法，公有方法有一定条件判断，条件符合调用私有方法，外部再调用公有方法 继承 class 子类（父类）： 子类拥有父类的方法 重写 父类中的方法不适合子类，则在子类中重新定义一个名字一样的方法，调用时调用子类的方法 调用被重写的方法 父类名 . 方法名（self） super（）. 方法名（） 方法2 私有方法，私有属性，并不会被继承，子类中也不能直接调用（可通过父类公有方法调用） __属性名 __方法名 多继承 （）内写多个父类 类名.mro 打印出来的结果决定搜索顺序（继续的类里面有相同的方法） python既支持面对对象又支持面对过程 面向对象的三要素：封装、继承、多态 封装：把函数和全局变量封装为对象；继承：子类继承父类的功能；多态：定义的函数不确定调用哪个功能，真正调用的时候才确定调用子类还是父类的哪个方法。 类对象，类属性 类属性所属于类对象，并且多个实例对象之间共享同一个类属性 实例对象，实例属性 实例属性：和具体的某个实例对象有关系，并且一个实例对象和另一个实例对象是不共享属性的 类名.类属性名 调用类属性 类方法 （更改类属性） @classmethod def 方法名（cls）： cls.类属性名 = 类方法可以通过类名调用，也可以通过这个类创建出来的对象调用 静态方法 可以没有任何参数 一般完成一些最基本的功能，既和类无关，也和实例对象无关 @staticmethod def 静态方法可以通过类名调用，也可以实例对象 12345678910111213141516class Tool(): #类属性 num = 0 #方法 def _init__ (self,new_name) : self.name = new_name #对类属性 +=1 Tool.num +=1tool1 = Tool(\"铁锹\")t0012 = Tool(\"工兵铲\")t0013 = Tool(\"水桶\")print (Tool.num) 模式、异常处理 耦合 类与类之间关系过于紧密 解耦：4s.py 简单工厂模式 定义一个类，把汽车商店和汽车两个类分离。（不再在汽车商店里选择汽车的种类，而是定义的一个类：工厂，进行选择） 工厂方法模式 在基类里面定义方法，但不实现，子类实现具体功能 4s_final.py 单例模式 确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，单例模式是一种对象创建型模式。 创建单例对象 1234567891011121314class Dog(object): __instance = None def __new____(cls): if cls.__instance None: cls.__instance = object.__new__(cls) return cls.__instance else: #return 上一次创建的对象的引用 return cls.__instancea = Dog() print(id(a)) b = Dog() print(id(b)) 只初始化一次对象 思路与创建单例对象相同 03-只初始化一次对象.py 异常处理 try: 可能有异常的代码 except 异常名字： （异常名字1，异常名字2） 异常处理 else: 没有异常的处理 finally： finally 不管有没有异常最后都会执行的语句 最后 except Exception： 若不想先看一下异常名字再写代码，可以再加一个，Exception是所有异常的总称。用了Exception，如果上面的except没有捕获到异常，则这个except一定会捕获到 except 异常名 as ret： 异常处理 print（ret） 打印异常信息 try可以嵌套 一些命令 \\t tab键 一般用于对齐 import random random.randint(0,2) 0到2的随机整数 len（） 求长度 pass 写代码时占坑 nums.sort() 从小到大排序（数字） nums.sort(reverse=True) 从大到小排序 nums.reverse 倒序 eval（） 把字符串的引号去掉，变成语句（用input输入的在Python3中存储为字符串） 交换2个变量 a,b = b,a a=a+b b=a-b a=a-b c=0 c=a a=b b=c import time time.sleep(n) 程序延时n秒 在终端Ctrl+A回到行首，Ctrl+E行末 python 字符串是否包含某个子字符串 if str1 in str2:包含的话，True if str1.find(str2)&gt;=0:包含的话，返回第一次出现的位置，没有的话为负数 zip() zip([iterable, …]) 参数iterable为可迭代的对象，并且可以有多个参数。该函数返回一个以元组为元素的列表，其中第 i 个元组包含每个参数序列的第 i 个元素。返回的列表长度被截断为最短的参数序列的长度。只有一个序列参数时，它返回一个1元组的列表。没有参数时，它返回一个空的列表。 12345678910import numpy as npa=[1,2,3,4,5]b=(1,2,3,4,5)c=np.arange(5)d=\"zhang\"zz=zip(a,b,c,d)print(zz)输出：[(1, 1, 0, 'z'), (2, 2, 1, 'h'), (3, 3, 2, 'a'), (4, 4, 3, 'n'), (5, 5, 4, 'g')] 没有参数时 12345import numpy as npzz=zip()print(zz)输出：[] 只有一个参数 123456import numpy as npa=[1,2,3]zz=zip(a)print(zz)输出：[(1,), (2,), (3,)] 当多个参数长度不同的时候 12345678import numpy as npa=[1,2,3]b=[1,2,3,4]c=[1,2,3,4,5]zz=zip(a,b,c)print(zz)输出：[(1, 1, 1), (2, 2, 2), (3, 3, 3)] zip() 和 * 操作符一起操作可以用来 unzip 一个列表 1234567891011121314151617import numpy as npa=[1,2,3]b=[4,5,6]c=[7,8,9]zz=zip(a,b,c)print(zz)x,y,z=zip(*zz)print(x)print(y)print(z)输出：[(1, 4, 7), (2, 5, 8), (3, 6, 9)](1, 2, 3)(4, 5, 6)(7, 8, 9) 注意这里输出的每个都是元组，而不一定是原来的类型，但是值不会发生变化（除非原来的参数列表长度不一样，看下面的代码） 1234567891011121314151617import numpy as npa=[1,2,3]b=[4,5,6,7]c=[8,9,10,11,12]zz=zip(a,b,c)print(zz)x,y,z=zip(*zz)print(x)print(y)print(z)输出：[(1, 4, 8), (2, 5, 9), (3, 6, 10)](1, 2, 3)(4, 5, 6)(8, 9, 10) unzip后的列表b和c的值都少了","categories":[{"name":"python","slug":"python","permalink":"http://mangosTeeN96.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://mangosTeeN96.github.io/tags/python/"}]},{"title":"leetcode笔记","slug":"leetcode笔记","date":"2019-10-15T07:59:06.000Z","updated":"2020-08-04T07:44:24.028Z","comments":true,"path":"2019/10/15/leetcode笔记/","link":"","permalink":"http://mangosTeeN96.github.io/2019/10/15/leetcode笔记/","excerpt":"","text":"1.两数之和给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 示例: 1234给定 nums = [2, 7, 11, 15], target = 9因为 nums[0] + nums[1] = 2 + 7 = 9所以返回 [0, 1] 方法一 暴力循环时间复杂度：O(n^2) 空间复杂度：O(1) 方法二 两遍哈希表12345678910111213141516171819class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); //数组值为键，索引为值，放入map（map键唯一，过滤掉相同值） for (int i = 0; i &lt; nums.length; i++) &#123; map.put(nums[i], i); &#125; for (int i = 0; i &lt; nums.length; i++) &#123; int complement = target - nums[i]; if (map.containsKey(complement) &amp;&amp; map.get(complement) != i) &#123; return new int[] &#123; i, map.get(complement) &#125;; &#125; &#125; throw new IllegalArgumentException(\"No two sum solution\"); &#125;&#125; 时间复杂度：O(n) 空间复杂度：O(n) 方法三：一遍哈希表 ☆1234567891011121314151617class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; int complement = target - nums[i]; //if语句只会执行一次，就是得到结果的那一次 if (map.containsKey(complement)) &#123; return new int[] &#123; map.get(complement), i &#125;; &#125; //在得到结果之前一直将元素放入哈希表 map.put(nums[i], i); &#125; throw new IllegalArgumentException(\"No two sum solution\"); &#125;&#125; 时间复杂度：O(n) 空间复杂度：O(n) 2.两数相加给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。 如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。 您可以假设除了数字 0 之外，这两个数都不会以 0 开头。 示例： 123输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)输出：7 -&gt; 0 -&gt; 8原因：342 + 465 = 807 ​ 对于链表问题，返回结果为头结点时，通常需要先初始化一个预先指针pre，该指针的下一个节点指向真正的头结点head。 使用预先指针的目的在于链表初始化时无可用节点值，而且链表构造过程需要指针移动，进而会导致头指针丢失，无法返回结果。 cur会移动所以留了个pre，这是个常用的技巧，这样才能找到头的位置，所以pre就没动过，就是为了最后返回结果使用，想想看要是没有pre的话，这个链表就无法使用了，因为头找不到了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Definition for singly-linked list. * public class ListNode &#123; //节点的值 * int val; //下一个节点 * ListNode next; //构造函数的初始化 * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode addTwoNumbers(ListNode l1, ListNode l2) &#123; //pre、cur为指针 //初始化节点值0 ListNode pre = new ListNode(0); ListNode cur = pre; int carry = 0; //循环当l1、l2都不为空时开始 //l1、l2指针移动，当两者指向皆为null时结束 while(l1 != null || l2 != null) &#123; int x = l1 == null ? 0 : l1.val; int y = l2 == null ? 0 : l2.val; int sum = x + y + carry; //carry为进位 carry = sum / 10; //sum为数值 sum = sum % 10; //给结果链表创建新节点，值为sum，cur指向新节点 cur.next = new ListNode(sum); cur = cur.next; //l1、l2指向下一节点 //两者有一个为null，另一个仍会前进，二者皆为null，则循环会结束 if(l1 != null) l1 = l1.next; if(l2 != null) l2 = l2.next; &#125; //判断总体计算是否有进位，有则结果链表创建新节点，值为carry 1 if(carry == 1) &#123; cur.next = new ListNode(carry); &#125; return pre.next; &#125;&#125; 3.无重复的最长子串给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。 示例 1: 123输入: \"abcabcbb\"输出: 3 解释: 因为无重复字符的最长子串是 \"abc\"，所以其长度为 3。 示例 2: 123输入: \"bbbbb\"输出: 1解释: 因为无重复字符的最长子串是 \"b\"，所以其长度为 1。 示例 3: 1234输入: \"pwwkew\"输出: 3解释: 因为无重复字符的最长子串是 \"wke\"，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，\"pwke\" 是一个子序列，不是子串。 方法一：暴力法（时间超出）逐个检查所有的子字符串，看它是否不含有重复的字符 12345678910111213141516171819202122232425public class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int n = s.length(); int ans = 0; //遍历出所有i起始，j结束的字符串 for (int i = 0; i &lt; n; i++) for (int j = i + 1; j &lt;= n; j++) //如果函数返回true，则把j-i与之前得到的j-i相比，取最大值保存为ans if (allUnique(s, i, j)) ans = Math.max(ans, j - i); return ans; &#125; //判断字符串中字符是否唯一的函数 public boolean allUnique(String s, int start, int end) &#123; //HashSet：元素不可重复、无序 //Character：字符类型 Set&lt;Character&gt; set = new HashSet&lt;&gt;(); for (int i = start; i &lt; end; i++) &#123; //strin的charAt方法 Character ch = s.charAt(i); if (set.contains(ch)) return false; set.add(ch); &#125; return true; &#125;&#125; 方法二：滑动窗口 ☆通过使用 HashSet 作为滑动窗口，我们可以用 O(1)的时间来完成对字符是否在当前的子字符串中的检查。 滑动窗口是数组/字符串问题中常用的抽象概念。 窗口通常是在数组/字符串中由开始和结束索引定义的一系列元素的集合，即 [i,j)（左闭，右开）。而滑动窗口是可以将两个边界向某一方向“滑动”的窗口。例如，我们将[i,j) 向右滑动 1 个元素，则它将变为 [i+1,j+1)（左闭，右开）。 回到我们的问题，我们使用 HashSet 将字符存储在当前窗口 [i,j)（最初 j=i）中。 然后我们向右侧滑动索引 j，如果它不在 HashSet 中，我们会继续滑动 j。直到 s[j] 已经存在于 HashSet 中。此时，我们找到的没有重复字符的最长子字符串将会以索引 i 开头。如果我们对所有的 i 这样做，就可以得到答案。 1234567891011121314151617181920public class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int n = s.length(); Set&lt;Character&gt; set = new HashSet&lt;&gt;(); int ans = 0, i = 0, j = 0; while (i &lt; n &amp;&amp; j &lt; n) &#123; //如果set不包含j位的字符，则放入set，j++，j-i与之前比较，取大值 //如果包含，把i位字符移除，i++ if (!set.contains(s.charAt(j)))&#123; set.add(s.charAt(j++)); //此处因为add j后j++了，所以长度是j-i ans = Math.max(ans, j - i); &#125; else &#123; set.remove(s.charAt(i++)); &#125; &#125; return ans; &#125;&#125; 方法三：优化的滑动窗口 ☆如果[i，j)出现重复字符 j ^，则可以抛弃[i，j ^]，将i变为j^ + 1。 123456789101112131415161718public class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int n = s.length(), ans = 0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); for (int j = 0, i = 0; j &lt; n; j++) &#123; //如果map中已经有j字符，则i滑动到前面重复字符中最右的那一个的下一位（map的值是j+1） //max是因为 可能前面出现了重复字符使i已经滑动到了现在出现的重复字符之后。比如：bacabc，当3a出现重复i滑动到2c，当4b出现重复，不max会滑动到1a。 if (map.containsKey(s.charAt(j))) &#123; i = Math.max(map.get(s.charAt(j)), i); &#125; ans = Math.max(ans, j - i + 1); //map的key为字符，值为该字符最近一次出现时的位置j+1，即该字符的下一位，方便i滑动 map.put(s.charAt(j), j + 1); &#125; return ans; &#125;&#125; 4.寻找两个有序数组的中位数给定两个大小为 m 和 n 的有序数组 nums1 和 nums2。 请你找出这两个有序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n))。 你可以假设 nums1 和 nums2 不会同时为空。 示例 1: 1234nums1 = [1, 3]nums2 = [2]则中位数是 2.0 示例 2: 1234nums1 = [1, 2]nums2 = [3, 4]则中位数是 (2 + 3)/2 = 2.5 方法一：合并数组然后根据奇偶，返回中位数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public double findMedianSortedArrays(int[] nums1, int[] nums2) &#123; int[] nums; int m = nums1.length; int n = nums2.length; nums = new int[m + n]; //如果nums1是空数组 //nums2长度为偶，则返回n/2-1与n/2的平均数（注意长度与索引的区别） //nums2长度为奇，则返回n/2 if (m == 0) &#123; if (n % 2 == 0) &#123; return (nums2[n / 2 - 1] + nums2[n / 2]) / 2.0; &#125; else &#123; return nums2[n / 2]; &#125; &#125; //如果nums2为空 if (n == 0) &#123; if (m % 2 == 0) &#123; return (nums1[m / 2 - 1] + nums1[m / 2]) / 2.0; &#125; else &#123; return nums1[m / 2]; &#125; &#125; //如果二者皆不为空 int count = 0; int i = 0, j = 0; while (count != (m + n)) &#123; //注意数组是有序数组，即从小到大排序好的 //把两个数组中小的数放入nums，计数++ //这样合并的数组依然有序 if (nums1[i] &lt; nums2[j]) &#123; nums[count++] = nums1[i++]; &#125; else &#123; nums[count++] = nums2[j++]; &#125; //如果nums1先全部放入nums，则把nums2剩余的数全部放入nums //break，不再判断j==n if (i == m) &#123; while (j != n) &#123; nums[count++] = nums2[j++]; &#125; break; &#125; //nums2 if (j == n) &#123; while (i != m) &#123; nums[count++] = nums1[i++]; &#125; break; &#125; &#125; //按奇偶取中位数 if (count % 2 == 0) &#123; return (nums[count / 2 - 1] + nums[count / 2]) / 2.0; &#125; else &#123; return nums[count / 2]; &#125;&#125; 时间复杂度：遍历全部数组 O（m+n） 方法二：第k小算法题目要求复杂度log（m+n），看到log，想到二分法 由于数列是有序的，其实我们完全可以一半儿一半儿的排除。假设我们要找第 k 小数，我们可以每次循环排除掉 k/2 个数 假设我们要找第 7 小的数字。 我们比较两个数组的第 k/2 个数字，如果 k 是奇数，向下取整。 也就是比较第 3 个数字，如果哪个小，就表明该数组的前 k/2 个数字都不是第 k 小数字，所以可以排除。将 1349 和 45678910 两个数组作为新的数组进行比较。 A 数组中比 A[k/2] 小的数有 k/2-1 个，B 数组中，B[k/2] 比 A[k/2] 大，假设 B[k/2] 前边的数字都比 A[k/2] 小，也只有 k/2-1 个，所以比 A[k/2] 小的数字最多有 k/2-1+k/2-1=k-2个，所以 A[k/2] 最多是第 k-1 小的数。而比 A[k/2] 小的数更不可能是第 k 小的数了，所以可以把它们排除。 即 A[1] ，A[2] ，A[3]，A[k/2] … ，B[1]，B[2]，B[3]，B[k/2] … ，如果 A[k/2]&lt;B[k/2] ，那么A[1]，A[2]，A[3]，A[k/2]都不可能是第 k 小的数字。 此时比较两个数组中的第 k / 2 = 1 个数，4 == 4，怎么办呢？由于两个数相等，所以我们无论去掉哪个数组中的都行，因为去掉 1 个总会保留 1 个的，所以没有影响。为了统一，我们就假设 4 &gt; 4 吧，所以此时将下边的 4 去掉。 此时我们要找第 1 小的数字，所以只需判断两个数组中第一个数字哪个小就可以了，也就是 4。所以第 7 小的数字是 4。 我们每次都是取 k/2 的数进行比较，有时候可能会遇到数组长度小于 k/2的时候。 此时 k / 2 等于 3，而上边的数组长度是 2，我们此时将箭头指向它的末尾就可以了。 这样的话，由于 2 &lt; 3，所以就会导致上边的数组 1，2 都被排除。造成下边的情况。 由于 2 个元素被排除，所以此时 k = 5，又由于上边的数组已经空了，我们只需要返回下边的数组的第 5 个数字就可以了。 从上边可以看到，无论是找第奇数个还是第偶数个数字，对我们的算法并没有影响，而且在算法进行中，k 的值都有可能从奇数变为偶数，最终都会变为 1 或者由于一个数组空了，直接返回结果。 所以我们采用递归的思路，为了防止数组长度小于 k/2，所以每次比较 k/2 和 len(数组) ，取min作为要比较的值的索引。 去除小值及其所在数组前面的值，将两个新数组进入递归，并且 k 要减去排除的数字的个数。 递归出口就是当 k=1 或者其中一个数组长度是 0 了。 123456789101112131415161718192021222324252627282930313233343536public double findMedianSortedArrays(int[] nums1, int[] nums2) &#123; int n = nums1.length; int m = nums2.length; //注意除法int默认忽略余数 //如果是偶数，left和right不同。比如（5+5+1）/2=5，（5+5+2）/2=6 //如果是奇数，left和right相同。比如（5+6+1）/2=6，（5+6+2）/2=6 int left = (n + m + 1) / 2; int right = (n + m + 2) / 2; //将偶数和奇数的情况合并，如果是奇数，会求两次同样的 k 。 return (getKth(nums1, 0, n - 1, nums2, 0, m - 1, left) + getKth(nums1, 0, n - 1, nums2, 0, m - 1, right)) * 0.5; &#125; private int getKth(int[] nums1, int start1, int end1, int[] nums2, int start2, int end2, int k) &#123; int len1 = end1 - start1 + 1; int len2 = end2 - start2 + 1; //让 len1 的长度小于 len2，这样就能保证如果有数组空了，一定是 len1 if (len1 &gt; len2) return getKth(nums2, start2, end2, nums1, start1, end1, k); //递归出口：当 k=1 or 其中一个数组长度是 0 //nums1空，求nums2第k小，索引所以-1 if (len1 == 0) return nums2[start2 + k - 1]; if (k == 1) return Math.min(nums1[start1], nums2[start2]); //k/2化为索引要-1 int i = start1 + Math.min(len1, k / 2) - 1; int j = start2 + Math.min(len2, k / 2) - 1; //去除小值及其所在数组前面的值，将两个新数组进入递归，并且 k 要减去排除的数字的个数。 if (nums1[i] &gt; nums2[j]) &#123; return getKth(nums1, start1, end1, nums2, j + 1, end2, k - (j - start2 + 1)); &#125; else &#123; return getKth(nums1, i + 1, end1, nums2, start2, end2, k - (i - start1 + 1)); &#125; &#125; 时间复杂度：每进行一次循环，我们就减少 k/2 个元素，所以时间复杂度是 O(log(k)），而 k=(m+n)/2，所以最终的复杂也就是 O(log(m+n）。 方法三：中位数定义（二分）☆中位数的定义 中位数:代表一个样本、种群或 概率分布 中的一个数值，其可将数值集合划分为相等的上下两部分。 所以我们只需要将数组进行切。 一个长度为 m 的数组，有 0 到 m 总共 m + 1 个位置可以切。 把数组 A 和数组 B 分别在 i 和 j 进行切割 将 i 的左边和 j 的左边组合成「左半部分」，将 i 的右边和 j 的右边组合成「右半部分」。 当 A 数组和 B 数组的总长度是偶数时，如果能够保证 左半部分的长度=右半部分 i + j = m - i + n - j 即 j = ( m + n ) / 2 - i 左半部分最大的值 &lt;= 右半部分最小的值 max ( A [ i - 1 ] , B [ j - 1 ]） &lt;= min ( A [ i ] , B [ j ]） 那么，中位数就可以表示为（左半部分最大值 + 右半部分最小值 ）/ 2。 （max ( A [ i - 1 ] , B [ j - 1 ]）+ min ( A [ i ] , B [ j ]）） / 2 当 A 数组和 B 数组的总长度是奇数时，如果能够保证 左半部分的长度比右半部分大 1 i + j = m - i + n - j + 1 即 j = ( m + n + 1) / 2 - i 左半部分最大的值小于等于右半部分最小的值 max ( A [ i - 1 ] , B [ j - 1 ]） &lt;= min ( A [ i ] , B [ j ]） 那么，中位数就是：左半部分最大值，也就是左半部比右半部分多出的那一个数。 max ( A [ i - 1 ] , B [ j - 1 ]） 上边的第一个条件我们其实可以合并为 j=(m+n+1)/2−i，因为如果 m+n 是偶数，由于我们取的是 int 值，所以加 1 也不会影响结果。 由于 0&lt;=i&lt;=m ，为了保证 0&lt;=j&lt;=n，我们必须保证 m&lt;=n。原因： m&lt;=n，i&lt;=m，则 j=(m+n+1)/2−i &gt;= (m+m+1)/2−i &gt;= (m+m+1)/2−m = 0 m&lt;=n，i&gt;=0，则 j = (m+n+1)/2−i &lt;= (n+n+1)/2−i &lt;= (n+n+1)/2 = n 最后一步由于是 int 间的运算，所以 1/2=0。 而对于第二个条件，奇数和偶数的情况是一样的，我们进一步分析。为了保证 max ( A [ i - 1 ] , B [ j - 1 ]）） &lt;= min ( A [ i ] , B [ j ]）），因为 A 数组和 B 数组是有序的，所以 A [ i - 1 ] &lt;= A [ i ]，B [ i - 1 ] &lt;= B [ i ] 这是天然的，所以我们只需要保证 B [ j - 1 ] &lt; = A [ i ] 和 A [ i - 1 ] &lt;= B [ j ] 。所以我们分两种情况讨论： 如果B[ j - 1 ] &gt; A[ i ]， （为了不越界，要保证 j != 0，i != m） 此时很明显，我们需要增加 i ，为了数量的平衡还要减少 j ，幸运的是 j = ( m + n + 1) / 2 - i，i 增大，j 自然会减少 如果A [ i - 1 ] &gt; B [ j ] ，（为了不越界，要保证 i != 0，j != n） 此时和上边的情况相反，我们要减少 i ，增大 j 。 上边两种情况，我们把边界都排除了，需要单独讨论 当 i = 0, 或者 j = 0，也就是切在了最前边 此时左半部分当 j = 0 时，最大的值就是 A [ i - 1 ] ；当 i = 0 时 最大的值就是 B [ j - 1] 。右半部分最小值和之前一样。 当 i = m 或者 j = n，也就是切在了最后边。 此时左半部分最大值和之前一样。右半部分当 j = n 时，最小值就是 A [ i ] ；当 i = m 时，最小值就是B [ j ] 。 所有的思路都理清了，最后一个问题，增加 i 的方式。当然用二分了。初始化 i 为中间的值，然后减半找中间的，减半找中间的，减半找中间的直到答案。 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123; public double findMedianSortedArrays(int[] A, int[] B) &#123; int m = A.length; int n = B.length; //这个用法上一个代码也用了( ´▽｀) if (m &gt; n) &#123; return findMedianSortedArrays(B,A); // 保证 m &lt;= n &#125; //i是对长度小的数组的切割 //j用公式算 i int iMin = 0, iMax = m; while (iMin &lt;= iMax) &#123; int i = (iMin + iMax) / 2; int j = (m + n + 1) / 2 - i; //此处是调整iMin、iMax，即直接铲除一半的数 if (j != 0 &amp;&amp; i != m &amp;&amp; B[j-1] &gt; A[i])&#123; // i 需要增大 iMin = i + 1; &#125; else if (i != 0 &amp;&amp; j != n &amp;&amp; A[i-1] &gt; B[j]) &#123; // i 需要减小 iMax = i - 1; &#125; else &#123; // 达到要求，并且将边界条件列出来单独考虑 int maxLeft = 0; if (i == 0) &#123; maxLeft = B[j-1]; &#125; else if (j == 0) &#123; maxLeft = A[i-1]; &#125; else &#123; maxLeft = Math.max(A[i-1], B[j-1]); &#125; if ( (m + n) % 2 == 1 ) &#123; return maxLeft; &#125; // 奇数的话不需要考虑右半部分 int minRight = 0; if (i == m) &#123; minRight = B[j]; &#125; else if (j == n) &#123; minRight = A[i]; &#125; else &#123; minRight = Math.min(B[j], A[i]); &#125; return (maxLeft + minRight) / 2.0; //如果是偶数的话返回结果 &#125; &#125; return 0.0; &#125;&#125; 5.最长回文子串给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。 示例 1： 123输入: \"babad\"输出: \"bab\"注意: \"aba\" 也是一个有效答案。 示例 2： 12输入: \"cbbd\"输出: \"bb\" 方法一：扩展中心我们知道回文串一定是对称的，所以我们可以每次循环选择一个中心，进行左右扩展，判断左右字符是否相等即可。 由于存在奇数的字符串和偶数的字符串，所以我们需要从一个字符开始扩展，或者从两个字符之间开始扩展，所以总共有 n+n-1 个中心。 12345678910111213141516171819202122232425262728293031public String longestPalindrome(String s) &#123; if (s == null || s.length() &lt; 1) return \"\"; int start = 0, end = 0; for (int i = 0; i &lt; s.length(); i++) &#123; //奇数字符串 int len1 = expandAroundCenter(s, i, i); //偶数字符串 int len2 = expandAroundCenter(s, i, i + 1); int len = Math.max(len1, len2); //更新end、start，以便输出子串 //如果新的len比旧的end-start长，则更新 if (len &gt; end - start) &#123; start = i - (len - 1) / 2; end = i + len / 2; &#125; &#125; return s.substring(start, end + 1);&#125;//左右扩展，判断是否对称，返回子串长度private int expandAroundCenter(String s, int left, int right) &#123; int L = left, R = right; while (L &gt;= 0 &amp;&amp; R &lt; s.length() &amp;&amp; s.charAt(L) == s.charAt(R)) &#123; L--; R++; &#125; //注意这里是-1，因为在判断相同之后，L--，R++，所以得到的LR是结果子串的左右两位，+1-2=-1 return R - L - 1;&#125; 617 合并二叉树给定两个二叉树，想象当你将它们中的一个覆盖到另一个上时，两个二叉树的一些节点便会重叠。 你需要将他们合并为一个新的二叉树。合并的规则是如果两个节点重叠，那么将他们的值相加作为节点合并后的新值，否则不为 NULL 的节点将直接作为新二叉树的节点。 示例 1: 1234567891011121314输入: Tree 1 Tree 2 1 2 / \\ / \\ 3 2 1 3 / \\ \\ 5 4 7 输出: 合并后的树: 3 / \\ 4 5 / \\ \\ 5 4 7 递归12345678910111213class Solution &#123; public TreeNode mergeTrees(TreeNode t1, TreeNode t2) &#123; if(t1 == null)&#123;return t2;&#125; if(t2 == null)&#123;return t1;&#125; TreeNode t3 = new TreeNode(t1.val + t2.val); t3.left = mergeTrees(t1.left, t2.left); t3.right = mergeTrees(t1.right, t2.right); return t3; &#125;&#125; 递归方法：每一次调用都是有return返回值，返回到上一级调用的。 461 汉明距离两个整数之间的汉明距离指的是这两个数字对应二进制位不同的位置的数目。 给出两个整数 x 和 y，计算它们之间的汉明距离。 注意：0 ≤ x, y &lt; 231. 示例: 12345678910输入: x = 1, y = 4输出: 2解释:1 (0 0 0 1)4 (0 1 0 0) ↑ ↑上面的箭头指出了对应二进制位不同的位置。 与 &amp;、或 |、非 ～、异或 ^ 异或：相同0，不同1 123456class Solution &#123; public int hammingDistance(int x, int y) &#123; //bitCount 数出整数二进制下 1 的个数 return Integer.bitCount(x ^ y); &#125;&#125; 移位： 左移 &lt;&lt;、右移 &gt;&gt; 123456789101112class Solution&#123; public int hammingDistance(int x,int y)&#123; int z = x ^ y, i = 0; //判断最后一位是否是1，是1，i++ //z右移一位，直到z为0 while(z != 0)&#123; i += z &amp; 1; z &gt;&gt;= 1; &#125; return i; &#125;&#125; 226 翻转二叉树翻转一棵二叉树。 示例： 1234567891011121314输入： 4 / \\ 2 7 / \\ / \\1 3 6 9输出： 4 / \\ 7 2 / \\ / \\9 6 3 1 方法一 广度优先 BFS12345678910111213141516class Solution&#123; public TreeNode invertTree(TreeNode root) &#123; //递归出口 //只判断左右节点为空是不行的，因为如果左为空，右不为空，向下运行，会给root赋值null，null没有left、right，会报错：NullPoint。 //但是如果只判断root == null，会对叶节点的左右两个null进行交换，效率低。 if (root == null || (root.left == null &amp;&amp; root.right == null)) &#123;return root;&#125; TreeNode temp = root.left; root.left = root.right; root.right = temp; //二叉树递归要递归左右两边 invertTree(root.left); invertTree(root.right); return root; &#125;&#125; 广度优先：一层一层往下交换 方法二 深度优先123456789101112131415class Solution &#123; public TreeNode invertTree(TreeNode root) &#123; //递归结束条件 if(root == null || (root.right == null &amp;&amp; root.left == null) ) return root; //临时变量记录左右节点地址 TreeNode left = root.left; TreeNode right = root.right; //交换左右节点 root.right = invertTree(left); root.left = invertTree(right); return root; &#125;&#125; 此代码同上 12345678910public TreeNode invertTree(TreeNode root) &#123; if(root == null || (root.right == null &amp;&amp; root.left == null) ) return root; //先找到最底层，一层一层向上交换 TreeNode right = invertTree(root.right); TreeNode left = invertTree(root.left); root.left = right; root.right = left; return root;&#125; 104 二叉树的最大深度给定一个二叉树，找出其最大深度。 二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。 说明: 叶子节点是指没有子节点的节点。 示例： 1234567给定二叉树 [3,9,20,null,null,15,7]， 3 / \\ 9 20 / \\ 15 7 返回它的最大深度 3 。 1234567891011121314class Solution &#123; public int maxDepth(TreeNode root) &#123; int len1 = 0, len2 = 0; if(root == null)&#123;return 0;&#125; if(root.left == null &amp;&amp; root.right == null)&#123;return 1;&#125; len1 = maxDepth(root.left) + 1; len2 = maxDepth(root.right) + 1; return Math.max(len1, len2); &#125;&#125; 206 反转链表反转一个单链表。 示例: 12输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL 进阶:你可以迭代或递归地反转链表。你能否用两种方法解决这道题 方法一 递归递归关键在于反向工作。假设列表的其余部分已经被反转，现在我该如何反转它前面的部分？ 我们希望nk+1 的下一个节点指向 nk所以，nk.next.next = nk 要小心的是 n1的下一个必须指向 null 。如果忽略了这一点，链表中可能会产生循环。如果使用大小为 2 的链表测试代码，则可能会捕获此错误。 123456789101112public ListNode reverseList(ListNode head) &#123; if (head == null || head.next == null) return head; //p指针直接找到了链表最后一个不为null的节点，之后的操作中都没有移动。 ListNode p = reverseList(head.next); //此处的反转操作，val数据本身是不变的，变的只是指针或者链表节点的指向 //详细见图片 head.next.next = head; head.next = null; return p;&#125; 方法二 迭代在遍历列表时，将当前节点的 next 指针改为指向前一个元素。从头至尾遍历，每遍历一个节点把该节点指向改为前一个元素，第一个节点的前一个元素为null。 由于链表不能引用节点的上一个节点，因此必须事先存储其前一个元素，初始化一个为null的节点即可。 当前节点指向原本的前一个节点之后，要使当前指针指向原本的下一个节点已经不可行，所以在更改指向之前就要一个指针来存储下一个节点。 12345678910111213141516171819202122232425class Solution&#123; public ListNode reverseList(ListNode head)&#123; //存储前一个节点的指针 ListNode pre = null; //存储当前节点的指针 ListNode cur = head; while(cur!=null)&#123; //存储下一个节点的指针 //滑动 ListNode nex = cur.next; //改变指向 cur.next = pre; //存储前一个节点的指针滑动 pre = cur; //存储当前节点的指针滑动 cur = nex; &#125; //存储当前节点的指针指向在最后一次循环中，指向了null //此时它的前一个节点pre为新的头节点 return pre; &#125;&#125; 136.只出现一次的数字给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。 说明： 你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？ 示例 1: 12输入: [2,2,1]输出: 1 示例 2: 12输入: [4,1,2,1,2]输出: 4 方法一 哈希表123456789101112131415161718192021222324252627class Solution &#123; public int singleNumber(int[] nums) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; if(map.containsKey(nums[i]))&#123; map.put(nums[i], 2); &#125; else&#123; map.put(nums[i], 1); &#125; &#125; //获得值为1的nums值 for (Integer i : map.keySet())&#123; Integer count = map.get(i); if (count == 1)&#123;return i;&#125; &#125; //与前面的for循环功能一样 // Set&lt;Entry&lt;Integer,Integer&gt;&gt; entrySet = map.entrySet(); // for (Entry&lt;Integer,Integer&gt; entry : entrySet)&#123; // if(entry.getValue() == 1)&#123;return entry.getKey();&#125; // &#125; return -1; &#125;&#125; 时间复杂度：O（n） 空间复杂度：O（n） 方法二 异或异或概念 如果我们对 0 和二进制位做 XOR 运算，得到的仍然是这个二进制位a⊕0=a 如果我们对相同的二进制位做 XOR 运算，返回的结果是 0a⊕a=0 XOR 满足交换律和结合律a⊕b⊕a=(a⊕a)⊕b=0⊕b=b 所以我们只需要将所有的数进行 XOR 操作，得到那个唯一的数字 123456789class Solution &#123; public int singleNumber(int[] nums) &#123; int ans = nums[0]; for (int i = 1; i &lt; nums.length; i++) &#123; ans = ans ^ nums[i]; &#125; return ans; &#125;&#125; 时间复杂度：O（n） 空间复杂度：O（1） 169.求众数给定一个大小为 n 的数组，找到其中的众数。众数是指在数组中出现次数大于 ⌊ n/2 ⌋ 的元素。 你可以假设数组是非空的，并且给定的数组总是存在众数。 示例 1: 12输入: [3,2,3]输出: 3 示例 2: 12输入: [2,2,1,1,1,2,2]输出: 2 方法一 哈希表代码（我的） 1234567891011121314151617class Solution &#123; public int majorityElement(int[] nums) &#123; HashMap&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int i : nums)&#123; if(map.containsKey(i))&#123; map.put(i, map.get(i)+1); &#125;else&#123;map.put(i, 1);&#125; if(map.get(i) &gt; nums.length/2)&#123;return i;&#125; &#125; return -1; &#125;&#125; 方法二 排序如果所有数字被单调递增或者单调递减的顺序排了序，那么众数的下标为 ⌊n/2⌋（n为数组包含数字个数，即数组长度） 123456class Solution &#123; public int majorityElement(int[] nums) &#123; Arrays.sort(nums); return nums[nums.length/2]; &#125;&#125; 时间复杂度：O(nlgn) 数组排序开销为O(nlgn) ，它占据了运行的主要时间。 方法三 投票法想法 如果我们把众数记为 +1 ，把其他数记为 −1 ，将它们全部加起来，显然和大于 0 ，从结果本身我们可以看出众数比其他数多。 算法 本质上， Boyer-Moore 算法就是找 nums 的一个后缀 suf ，其中 suf[0] 就是后缀中的众数。我们维护一个计数器，如果遇到一个我们目前的候选众数，就将计数器加一，否则减一。只要计数器等于 0 ，我们就将 nums 中之前访问的数字全部 忘记 ，并把下一个数字当做候选的众数。直观上这个算法不是特别明显为何是对的，我们先看下面这个例子（竖线用来划分每次计数器归零的情况） [7, 7, 5, 7, 5, 1 | 5, 7 | 5, 5, 7, 7 | 7, 7, 7, 7] 首先，下标为 0 的 7 被当做众数的第一个候选。在下标为 5 处，计数器会变回0 。所以下标为 6 的 5 是下一个众数的候选者。由于这个例子中 7 是真正的众数，所以通过忽略掉前面的数字，我们忽略掉了同样多数目的众数和非众数。因此， 7 仍然是剩下数字中的众数。 1234567891011121314class Solution&#123; public int majorityElement(int[] nums)&#123; int count = 0; Integer candidate = null; for(int num : nums)&#123; if(count == 0)&#123; candidate = num; &#125; count += candidate == num ? 1 : -1; &#125; return candidate; &#125;&#125; 时间复杂度：O(n) 空间复杂度：O(1) 21. 合并两个有序链表将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例： 12输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 方法一 迭代代码（我的） 12345678910111213141516171819202122232425class Solution &#123; public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; if(l1 == null)&#123;return l2;&#125; if(l2 == null)&#123;return l1;&#125; ListNode pre = new ListNode(0); ListNode cur = pre; while(l1 != null &amp;&amp; l2 != null)&#123; if(l1.val &lt;= l2.val)&#123; cur.next = l1; cur = cur.next; l1 = l1.next; &#125;else&#123; cur.next = l2; cur = cur.next; l2 = l2.next; &#125; &#125; if(l1 == null)&#123;cur.next = l2;&#125;else&#123;cur.next = l1;&#125; return pre.next; &#125;&#125; 方法二 递归12345678910111213141516171819class Solution &#123; public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; if (l1 == null) &#123; return l2; &#125; else if (l2 == null) &#123; return l1; &#125; else if (l1.val &lt; l2.val) &#123; l1.next = mergeTwoLists(l1.next, l2); return l1; &#125; else &#123; l2.next = mergeTwoLists(l1, l2.next); return l2; &#125; &#125;&#125; 283.移动零给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。 示例: 12输入: [0,1,0,3,12]输出: [1,3,12,0,0] 说明: 必须在原数组上操作，不能拷贝额外的数组。尽量减少操作次数。 方法一 暴力法代码（mine） 12345678910111213141516class Solution &#123; public void moveZeroes(int[] nums) &#123; int n = nums.length; for (int i = 0; i &lt; n; i++) &#123; if(nums[i] == 0)&#123; for (int j = i; j &lt; n-1; j++)&#123; nums[j] = nums[j+1]; &#125; nums[n-1] = 0; i--; n = n - 1; &#125; &#125; &#125;&#125; 方法二 双指针定义两个指针i,j，然后遍历数组，i跟j同时往前走，当遇到0时j停下，i继续往前走。当nums[i]不为0时则将num[i]的元素赋给j的位置，j++,nums[i]被赋值为0 123456789101112public void moveZeroes(int[] nums) &#123; int j = 0; for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] != 0) &#123; if(i!=j) &#123; nums[j] = nums[i]; nums[i] = 0; &#125; j++; &#125; &#125; &#125; 在i等于j的情况下，如果num[i]不为0，将num[i]的元素赋给j的位置其实就是自己赋值给自己，所以可以加一个判断条件，i不等j的时候才替换0 538. 把二叉搜索树转换为累加树给定一个二叉搜索树（Binary Search Tree），把它转换成为累加树（Greater Tree)，使得每个节点的值是原来的节点值加上所有大于它的节点值之和。 例如： 123456789输入: 二叉搜索树: 5 / \\ 2 13输出: 转换为累加树: 18 / \\ 20 13 二叉搜索树（又二叉查找树、二叉排序树）定义： 它或者是一棵空树，或者是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉搜索树。 方法 递归深度优先，right-root-left顺序遍历 1234567891011121314int add = 0; public TreeNode convertBST(TreeNode root) &#123; //递归终止条件 if (root == null) return root; //找到最右 convertBST(root.right); root.val += add; add = root.val; convertBST(root.left); return root; &#125; 在过程中的return，并没有作为输入给上一层。因为这里用add存储信息。 树在root.val+=add处已经更新了 另一种代码写法 1234567891011121314151617181920212223242526class Solution &#123; public TreeNode convertBST(TreeNode root) &#123; //判断所给树是否为空 if (root != null) &#123; dfs(root, 0); &#125; return root; &#125; private int dfs(TreeNode node, int sum) &#123; //递归终止条件 if (node == null) &#123; return sum; &#125; sum = dfs(node.right, sum); node.val += sum; //此处会更新sum sum = dfs(node.left, node.val); return sum; &#125;&#125; 448. 找到所有数组中消失的数字给定一个范围在 1 ≤ a[i] ≤ n ( n = 数组大小 ) 的 整型数组，数组中的元素一些出现了两次，另一些只出现一次。 找到所有在 [1, n] 范围之间没有出现在数组中的数字。 您能在不使用额外空间且时间复杂度为O(n)的情况下完成这个任务吗? 你可以假定返回的数组不算在额外空间内。 示例: 12345输入:[4,3,2,7,8,2,3,1]输出:[5,6] 方法一代码（mine） 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123; public List&lt;Integer&gt; findDisappearedNumbers(int[] nums) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); //数组排序 Arrays.sort(nums); int n = nums.length; //假如数组最大值小于n if(n &gt; 0 &amp;&amp; nums[n - 1] &lt; n)&#123; int m = n - nums[n - 1]; for(int q = 1; q &lt;= m; q++)&#123; list.add(nums[n - 1] + q); &#125; &#125; //假如数组最小值大于1 if(n &gt; 0 &amp;&amp; nums[0] &gt; 1)&#123; int m = nums[0] - 1; for(int q = 1; q &lt;= m; q++)&#123; list.add(nums[0] - q); &#125; &#125; //如果相邻数相差大于1，则两者之间的数是消失的 int i = 0, j = 0; while(i &lt; n - 1)&#123; if(nums[i+1] - nums[i] &lt;= 1)&#123; i++; &#125;else&#123; nums[i] += 1; list.add(nums[i]); j++; &#125; &#125; return list; &#125;&#125; 方法二 抽屉原理 + 基于“异或运算”交换两个变量的值「力扣」第 41 题：“缺失的第 1 个正数”也可以用这个方法解 抽屉原理：即“一个萝卜一个坑” 以下介绍来自“百度百科”之“抽屉原理”词条： 抽屉原理的一般含义为：“如果每个抽屉代表一个集合，每一个苹果就可以代表一个元素，假如有 n + 1 个元素放到 n 个集合中去，其中必定有一个集合里至少有两个元素。” 抽屉原理有时也被称为鸽巢原理。它是组合数学中一个重要的原理。 本题中，我们可以把数组进行一次“排序”，“排序”的规则是：i 就应该放在索引为 i - 1 的位置上。 这句话也可以这么说 “索引为 i 的位置上应该存放的数字是 i + 1”。 基于“异或运算”交换两个变量的值： 这道题的一个子过程是“交换数组中两个位置的元素”，如果不使用额外的空间，可以使用“异或运算”代替。 “基于异或运算”利用了“异或运算”是不进位的二进制加法。它有如下性质： 如果 a ^ b = c ，那么 a ^ c = b 与 b ^ c = a 同时成立，利用这一条，可以用于交换两个变量的值。于是，交换两个变量的值，例如 a 和 b，不使用第三个变量，可以这样做： a = a ^ bb = a ^ ba = a ^ b （自己想一下就明白了） 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; public List&lt;Integer&gt; findDisappearedNumbers(int[] nums) &#123; //遍历数组，对数组进行排序，排序规则：索引i上就应该放i+1，放了之后，位置锁定。 //数组[4,3,2,7,8,2,3,1] 排序后 [1,2,3,4,3,2,7,8] //比如：i=0，nums[0]=4，4应该放在索引nums[0]-1处，即判断与nums[nums[0]-1]是否相等，不等，则交换（图见代码后） for (int i = 0; i &lt; nums.length; i++) &#123; while (nums[nums[i] - 1] != nums[i]) &#123; swap(nums, i, nums[i] - 1); &#125; &#125; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); //只要索引i处不是i+1，就把i+1存入list for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] != i + 1) &#123; res.add(i + 1); &#125; &#125; return res; &#125; //将数组nums中，索引1、2的数调换 //由于不能使用额外空间，使用基于异或交换 private void swap(int[] nums, int index1, int index2) &#123; if (index1 == index2) &#123; return; &#125; nums[index1] = nums[index1] ^ nums[index2]; nums[index2] = nums[index1] ^ nums[index2]; nums[index1] = nums[index1] ^ nums[index2]; &#125;&#125; 437.路径总和③给定一个二叉树，它的每个结点都存放着一个整数值。 找出路径和等于给定数值的路径总数。 路径不需要从根节点开始，也不需要在叶子节点结束，但是路径方向必须是向下的（只能从父节点到子节点）。 二叉树不超过1000个节点，且节点数值范围是 [-1000000,1000000] 的整数。 示例： 12345678910111213141516root = [10,5,-3,3,2,null,11,3,-2,null,1], sum = 8 10 / \\ 5 -3 / \\ \\ 3 2 11 / \\ \\3 -2 1返回 3。和等于 8 的路径有:1. 5 -&gt; 32. 5 -&gt; 2 -&gt; 13. -3 -&gt; 11 方法一以每个节点为根节点，都算一遍路径和为sum的有几条，然后加起来 12345678910111213141516171819202122class Solution &#123; public int pathSum(TreeNode root, int sum) &#123; if(root == null)return 0; return eve(root, sum)+ pathSum(root.left, sum) + pathSum(root.right, sum); &#125; //每棵树有几条 public int eve(TreeNode root, int sum) &#123; if(root == null)return 0; sum -= root.val; int a; if(sum == 0)&#123;a = 1;&#125;else&#123;a = 0;&#125; return a + eve(root.left, sum) + eve(root.right, sum); &#125;&#125; 此处测试时出现一个问题，如果eve函数不用ifelse判断，而是直接return (sum == 0 ? 1 : 0) + helper(root.left, sum) + helper(root.right, sum);测试例子会有不通过： 此处原因还未理解 121.买卖股票的最佳时机给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。 如果你最多只允许完成一笔交易（即买入和卖出一支股票），设计一个算法来计算你所能获取的最大利润。 注意你不能在买入股票前卖出股票。 示例 1: 1234输入: [7,1,5,3,6,4]输出: 5解释: 在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。 注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格。 示例 2: 123输入: [7,6,4,3,1]输出: 0解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。 方法一 暴力法代码（mine） 1234567891011121314class Solution &#123; public int maxProfit(int[] prices) &#123; int profit = 0; for (int i = 0; i &lt; prices.length; i++) &#123; for (int j = i+1; j &lt; prices.length; j++) &#123; int a = prices[j] - prices[i]; if(a &gt; profit)&#123;profit = a;&#125; &#125; &#125; return profit; &#125;&#125; 时间复杂度：O(n^2)循环运行 n(n-1)/2次。空间复杂度：O(1)。只使用了两个变量 —— a 和 profit 方法二：一次遍历假设给定的数组为： [7, 1, 5, 3, 6, 4] 如果我们在图表上绘制给定数组中的数字，我们将会得到： 使我们感兴趣的点是上图中的峰和谷。我们需要找到最小的谷之后的最大的峰。我们可以维持两个变量——minprice 和 maxprofit，它们分别对应迄今为止所得到的最小的谷值和最大的利润（卖出价格与最低价格之间的最大差值）。 123456789101112131415161718public class Solution &#123; public int maxProfit(int prices[]) &#123; //java int类整数的最大值是2的31次方-1 = 2147483648-1 = 2147483647可以用 Integer.MAX_VALUE表示它 int minprice = Integer.MAX_VALUE; int maxprofit = 0; for (int i = 0; i &lt; prices.length; i++) &#123; //如果 prices[i] &lt; minprice，更新最小谷值 //如果 prices[i] &gt;= minprice,并且利润大于之前的最大利润，则更新最大利润 if (prices[i] &lt; minprice) minprice = prices[i]; else if (prices[i] - minprice &gt; maxprofit) maxprofit = prices[i] - minprice; &#125; return maxprofit; &#125;&#125; 155.最小栈设计一个支持 push，pop，top 操作，并能在常数时间内检索到最小元素的栈。 push(x) – 将元素 x 推入栈中。pop() – 删除栈顶的元素。top() – 获取栈顶元素。getMin() – 检索栈中的最小元素。 示例: 12345678MinStack minStack = new MinStack();minStack.push(-2);minStack.push(0);minStack.push(-3);minStack.getMin(); --&gt; 返回 -3.minStack.pop();minStack.top(); --&gt; 返回 0.minStack.getMin(); --&gt; 返回 -2. 这道题的思想：“以空间换时间”，使用辅助栈是常见的做法。 两种方式： 1、辅助栈和数据栈同步 优点：编码简单，不用考虑一些边界情况；缺点：辅助栈可能会存一些“不必要”的元素。 数据栈增加元素x。如果辅助栈为空，或者x小于辅助栈的栈顶元素，辅助栈增加元素x；否则辅助栈重复增加原本的栈顶元素 2、辅助栈和数据栈不同步 由“辅助栈和数据栈同步”的思想，当数据栈进来的数越来越大的时候，我们要在辅助栈顶放置和当前辅助栈顶一样的元素，这样做有点“浪费”。基于这一点做一些“优化”，但是在编码上就要注意一些边界条件。 （1）辅助栈为空的时候，必须放入新进来的数； （2）新来的数小于或者等于辅助栈栈顶元素的时候，才放入，特别注意这里“等于”要考虑进去，因为出栈的时候，连续的、相等的并且是最小值的元素要同步出栈； （3）出栈的时候，辅助栈的栈顶元素等于数据栈的栈顶元素，才出栈。 总结一下：出栈时，最小值出栈才同步；入栈时，最小值入栈才同步。 辅助栈只存储了&lt;=第一个入栈元素的元素，事实上那些 大于第一个入栈元素的元素 在 检索栈中的最小元素时是没有用的。 对比：“同步栈”思路清楚，所有操作都同步进行，所以调试代码、定位问题也简单。“不同步栈”，减少了一些空间，但是在“出栈”、“入栈”的时候还要做判断，也有性能上的消耗。 方法一 辅助栈和数据栈同步12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class MinStack &#123; // 数据栈 private Stack&lt;Integer&gt; data; // 辅助栈 private Stack&lt;Integer&gt; helper; /** * initialize your data structure here. */ public MinStack() &#123; data = new Stack&lt;&gt;(); helper = new Stack&lt;&gt;(); &#125; // 思路 1：数据栈和辅助栈在任何时候都同步 public void push(int x) &#123; // 数据栈和辅助栈一定会增加元素 // 数据栈增加元素x data.add(x); // 如果辅助栈为空，或者x小于辅助栈的栈顶元素，辅助栈增加元素x // 否则辅助栈重复增加原本的栈顶元素 if (helper.isEmpty() || helper.peek() &gt;= x) &#123; helper.add(x); &#125; else &#123; helper.add(helper.peek()); &#125; &#125; public void pop() &#123; // 两个栈都得 pop if (!data.isEmpty()) &#123; helper.pop(); data.pop(); &#125; &#125; public int top() &#123; if(!data.isEmpty())&#123; return data.peek(); &#125; // 如果data为空，还要求top获取栈顶元素，则抛出异常 throw new RuntimeException(\"栈中元素为空，此操作非法\"); &#125; public int getMin() &#123; if(!helper.isEmpty())&#123; return helper.peek(); &#125; throw new RuntimeException(\"栈中元素为空，此操作非法\"); &#125;&#125; 时间复杂度：O(1)，“出栈”、“入栈”、“查看栈顶元素”的操作不论数据规模多大，都只是有限个步骤，因此时间复杂度是O(1)。空间复杂度：O(N)，这里 N 是读出的数据的个数。 方法二 辅助栈和数据栈不同步123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class MinStack &#123; // 数据栈 private Stack&lt;Integer&gt; data; // 辅助栈 private Stack&lt;Integer&gt; helper; /** * initialize your data structure here. */ public MinStack() &#123; data = new Stack&lt;&gt;(); helper = new Stack&lt;&gt;(); &#125; // 思路 2：辅助栈和数据栈不同步 // 关键 1：辅助栈的元素空的时候，必须放入新进来的数 // 关键 2：新来的数小于或者等于辅助栈栈顶元素的时候，才放入（特别注意这里等于要考虑进去） // 关键 3：出栈的时候，辅助栈的栈顶元素等于数据栈的栈顶元素，才出栈，即\"出栈保持同步\"就可以了 public void push(int x) &#123; // 辅助栈在必要的时候才增加 data.add(x); // 关键 1 和 关键 2 if (helper.isEmpty() || helper.peek() &gt;= x) &#123; helper.add(x); &#125; &#125; public void pop() &#123; // 关键 3：data 一定得 pop() if (!data.isEmpty()) &#123; // 注意：声明成 int 类型，这里完成了自动拆箱，从 Integer 转成了 int，因此下面的比较可以使用 \"==\" 运算符 // 参考资料：https://www.cnblogs.com/GuoYaxiang/p/6931264.html // 如果把 top 变量声明成 Integer 类型，下面的比较就得使用 equals 方法 int top = data.pop(); if(top == helper.peek())&#123; helper.pop(); &#125; &#125; &#125; public int top() &#123; if(!data.isEmpty())&#123; return data.peek(); &#125; throw new RuntimeException(\"栈中元素为空，此操作非法\"); &#125; public int getMin() &#123; if(!helper.isEmpty())&#123; return helper.peek(); &#125; throw new RuntimeException(\"栈中元素为空，此操作非法\"); &#125;&#125; 时间复杂度：O(1)，“出栈”、“入栈”、“查看栈顶元素”的操作不论数据规模多大，都只是有限个步骤，因此时间复杂度是O(1)。空间复杂度：O(N)，这里 N 是读出的数据的个数。 160.相交链表编写一个程序，找到两个单链表相交的起始节点。 如下面的两个链表： 在节点 c1 开始相交。 示例 1： 123输入：intersectVal = 8, listA = [4,1,8,4,5], listB = [5,0,1,8,4,5], skipA = 2, skipB = 3输出：Reference of the node with value = 8输入解释：相交节点的值为 8 （注意，如果两个列表相交则不能为 0）。从各自的表头开始算起，链表 A 为 [4,1,8,4,5]，链表 B 为 [5,0,1,8,4,5]。在 A 中，相交节点前有 2 个节点；在 B 中，相交节点前有 3 个节点。 示例 2： 123输入：intersectVal = 2, listA = [0,9,1,2,4], listB = [3,2,4], skipA = 3, skipB = 1输出：Reference of the node with value = 2输入解释：相交节点的值为 2 （注意，如果两个列表相交则不能为 0）。从各自的表头开始算起，链表 A 为 [0,9,1,2,4]，链表 B 为 [3,2,4]。在 A 中，相交节点前有 3 个节点；在 B 中，相交节点前有 1 个节点。 示例 3： 1234输入：intersectVal = 0, listA = [2,6,4], listB = [1,5], skipA = 3, skipB = 2输出：null输入解释：从各自的表头开始算起，链表 A 为 [2,6,4]，链表 B 为 [1,5]。由于这两个链表不相交，所以 intersectVal 必须为 0，而 skipA 和 skipB 可以是任意值。解释：这两个链表不相交，因此返回 null。 注意： 如果两个链表没有交点，返回 null.在返回结果后，两个链表仍须保持原有的结构。可假定整个链表结构中没有循环。程序尽量满足 O(n) 时间复杂度，且仅用 O(1) 内存。 方法一 暴力法双层循环 时间复杂度：O（mn） 空间复杂度：O（1） 方法二 双指针根据题目意思如果两个链表相交，那么相交点之后的长度是相同的 我们需要做的事情是，让两个链表从同距离末尾同等距离的位置开始遍历。这个位置只能是较短链表的头结点位置。为此，我们必须消除两个链表的长度差 指针 pA 指向 A 链表，指针 pB 指向 B 链表，依次往后遍历 如果 pA 到了末尾，则 pA = headB 继续遍历 如果 pB 到了末尾，则 pB = headA 继续遍历 若在某一时刻 pA 和 pB 相遇，则 pA/pB 为相交结点。 想弄清楚为什么这样可行, 可以考虑以下两个链表: A={1,3,5,7,9,11} 和 B={2,4,9,11}，相交于结点 9。 由于 B.length (=4) &lt; A.length (=6)，pB 比 pA 少经过 2 个结点，会先到达尾部。将 pB 重定向到 A 的头结点，pA 重定向到 B 的头结点后，pB 要比 pA 多走 2 个结点。因此，它们会同时到达交点。 关于死循环问题，如果pA和pB同时为null循环也是会结束的 如果两个链表不相交且长度不等，那么pA和pB在把两个链表都走一遍之后会同时为null 如果两个链表不相交且长度相等，那么pA走完headA、pB走完headB时就会同时为null 123456789101112131415161718class Solution &#123; public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; if(headA == null || headB == null)return null; ListNode pA = headA; ListNode pB = headB; while(pA != pB)&#123; pA = pA == null ? headB : pA.next; pB = pB == null ? headA : pB.next; &#125; return pA; &#125;&#125; 关于while循环内的代码，最初写为 1234pA = pA.next;pB = pB.next；if(pA == null)pA = headB;if(pB == null)pB = headA; 发现这样就不会出现pA = null = pB的情况了，pA、pB为null时不到判断！=时就被赋值了 后来调换为 1234if(pA == null)pA = headB;if(pB == null)pB = headA;pA = pA.next;pB = pB.next； 发现依然不行，示例： 123453[3][2,3]01 返回null，此时发现应采用if else 101. 对称二叉树给定一个二叉树，检查它是否是镜像对称的。 例如，二叉树 [1,2,2,3,4,4,3] 是对称的。 12345 1 / \\ 2 2 / \\ / \\3 4 4 3 但是下面这个 [1,2,2,null,3,null,3] 则不是镜像对称的: 12345 1 / \\2 2 \\ \\ 3 3 说明: 如果你可以运用递归和迭代两种方法解决这个问题，会很加分。 方法一 递归如果一个树的左子树与右子树镜像对称，那么这个树是对称的。 因此，该问题可以转化为：两个树在什么情况下互为镜像？ 如果同时满足下面的条件，两个树互为镜像： 它们的两个根结点具有相同的值。 每个树的右子树都与另一个树的左子树镜像对称。 123456789101112131415161718192021class Solution &#123; public boolean isSymmetric(TreeNode root) &#123; //[]返回true if(root == null)return true; return isMirror(root.left, root.right); &#125; public boolean isMirror(TreeNode l1, TreeNode l2)&#123; if(l1 == null &amp;&amp; l2 == null)return true; if(l1 == null || l2 == null)return false; // if(l1.val == l2.val &amp;&amp; l1.left.val == l2.right.val &amp;&amp; l1.right.val == l2.left.val)是没有必要的 //因为 在判断isMirror(l1.left, l2.right) &amp;&amp; isMirror(l1.right, l2.left) 时会判断这一层的根结点也就是上一级的那些左右节点值 if(l1.val == l2.val)&#123; return isMirror(l1.left, l2.right) &amp;&amp; isMirror(l1.right, l2.left); &#125;else return false; &#125;&#125; 方法二 迭代(未解决)除了递归的方法外，我们也可以利用队列进行迭代。队列中每两个连续的结点应该是相等的，而且它们的子树互为镜像。最初，队列中包含的是 root 以及 root。该算法的工作原理类似于 BFS，但存在一些关键差异。每次提取两个结点并比较它们的值。然后，将两个结点的左右子结点按相反的顺序插入队列中。当队列为空时，或者我们检测到树不对称（即从队列中取出两个不相等的连续结点）时，该算法结束。 LinkedList集合数据存储的结构是链表结构。在开发时，LinkedList集合也可以作为堆栈，队列的结构使用。LinkedList在当队列使用的时候，弹出元素应该用poll()而不是pop() 1234567891011121314151617public boolean isSymmetric(TreeNode root) &#123; Queue&lt;TreeNode&gt; q = new LinkedList&lt;&gt;(); q.add(root); q.add(root); while (!q.isEmpty()) &#123; TreeNode t1 = q.poll(); TreeNode t2 = q.poll(); if (t1 == null &amp;&amp; t2 == null) continue; if (t1 == null || t2 == null) return false; if (t1.val != t2.val) return false; q.add(t1.left); q.add(t2.right); q.add(t1.right); q.add(t2.left); &#125; return true;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://mangosTeeN96.github.io/categories/java/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://mangosTeeN96.github.io/tags/数据结构/"}]},{"title":"Vim基本命令","slug":"Vim基本命令","date":"2019-08-25T12:18:17.000Z","updated":"2020-08-10T08:48:19.216Z","comments":true,"path":"2019/08/25/Vim基本命令/","link":"","permalink":"http://mangosTeeN96.github.io/2019/08/25/Vim基本命令/","excerpt":"","text":"Vim命令 代码操作 命令 作用 yy 复制 光标所在的这一行 4yy 复制 光标所在的行开始向下的4行 p 粘贴 dd 剪切 光标所在行 4dd 向下4行 D 从光标开始剪切，一直到行末 d0 从光标开始剪切，一直到行首 dw 删除这个单词 x 删除当前光标，每次只删除一个 X 删除当前光标前面的那个，每次只删除一个 u 撤销刚刚操作(可多次） ctrl+r 反撤销 . 重复执行上一次命令 定位操作 命令 作用 h，j，k，l 命令下的光标 左，下，上，右 H，M，L 当前屏幕的 上方，中间，下方 ctrl+f 向下翻一页代码 ctrl+b 向上翻一页代码 20G 快速定位到第20行代码 G 快速回到整个代码的最后一行 gg 快速回到整个代码的第一行 w 向后跳一个单词的长度，即下一个单词的开始 b 向前 移动替换 命令 作用 { 按段移动，上移 } 按段移动，下移 v 选中（配合上下左右可以选中一片）光标在哪选到哪 V 选中，光标所在行都选中 &gt; 整体向右移动代码 &lt; 向左 r 替换当前字符(输入r后输入替换后的字符） R 替换当前行光标后的字符 查找替换、保存退出 命令 作用 / 查找（搜不存在的可去掉颜色） n下一个搜索到的 N上一个 %s///g(：末行模式下） /被替换/替换/ 11,16s///g 替换11到16行 vim 4.py vim下 创建or进入4.py vi (似乎更方便，再次进入的时候） ：w （末行模式） 保存 ：q 直接退出（没保存的话会提示） ：q！ 不保存退出 ：wq或者x 保存并退出 shift+zz 相当于末行模式的wq ctrl+N查看已经定义的变量","categories":[{"name":"Vim","slug":"Vim","permalink":"http://mangosTeeN96.github.io/categories/Vim/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"http://mangosTeeN96.github.io/tags/Vim/"}]},{"title":"Linux以及命令.md","slug":"Linux以及命令","date":"2019-08-25T11:24:06.000Z","updated":"2019-08-25T12:15:14.767Z","comments":true,"path":"2019/08/25/Linux以及命令/","link":"","permalink":"http://mangosTeeN96.github.io/2019/08/25/Linux以及命令/","excerpt":"","text":"Linux操作系统命令： 命令 作用 command + 调大字体 - 调小 ls 当前路径下所有文件夹和名字 pwd 目前处在的路径，第一个/为根目录 cd 切换路径 clear 清屏 命令基本格式:命令 选项 参数选项的格式为:-选项 命令 作用 ls -a 创建的文件的名字以.开头，则为隐藏文件，ls命令看不见。此时运行ls -a，则能看见 ls -l 以列表方式显示 ls -l -h 显示列表的时候会给数字显示一个合适的单位 可以ls -a -l -h一起使用，顺序无所谓，ls -alh 查看帮助文档 命令 作用 命令 –help man 命令 （进入后不能输入命令，按q退出，f向下翻一屏，b向上） man 2 命令 查看c语言下的帮助文档 history 查看历史命令 对文件（夹）的操作 命令 作用 tab键 文件名补全 touch 新建文件 mkdir 创建文件夹 rmdir 删除文件夹（非空删除不了） open 打开并编辑文件 cat 查看文件 cat 123.txt 234.txt 会同时显示两个文件的内容 cat 123.txt 234.txt &gt; xxx.txt 合并两个文件的内容到一个文件xxx.txt more 查看文件（适合大文件，不会全显示出来，显示一页，按f键翻页，q退出) 可以结合ls命令：ls -ahl /bin ` rm 删除命令 可以删除非空文件夹：rm -r 文件夹名。不想一直询问，直接删除-rf mv 123.txt 789.txt 重命名，原文件名 新文件名 mv 789.txt A 剪切文件到A文件夹 cp 复制粘贴 不让copy文件夹，加-r，遇到文件夹不让动的，多数可以加-r解决（-r：递归） 文件中查找操作 命令 作用 grep “s” xxx.txt 在xxx.txt中查找s grep -n “s” xxx.txt 搜索显示前面会带有在哪一行 grep -n “s” xxx.txt 查找不包含s的 grep “^s” xxx.txt 查找以s开头的 grep “s$” xxx.txt 查找以s结尾的 通配符 命令 作用 ls 2* 只查看以2开头的文件 ls *.txt 只查看.txt文件 *代表的位数可以为0到n位（不只可以与ls合用，与rm等也可以一起） ls 2？ 查看以2开头且只有两位 几个？则几位 ls 2？3 .txt ls 2[12345]3.txt 查看213到253之间到文件（可以写成1-5） 重定向 命令 作用 ls -ahl &gt; xxx.txt 创建了xxx.txt文件，并且把命令ls -ahl应该显示的内容存放进去 &gt;&gt; 追加，会在原来的末尾把当前内容追加进去 如果只&gt;，会把原来的删除。如果原来没有这个文件，&gt;&gt;也会创建文件。 路径 相对路径 从当前路径算起 绝对路径 从根目录算起 cd时不知道下一层文件夹名字，可以按两次tab键，会把能补全的文件夹名字全显示出来 cd A 跳转到（当前路径的）A文件夹 cd ./A 跳转到当前路径的A文件夹 cd .. 跳转到上一层文件夹 cd ../.. 上上层 跳转文件距离根目录近，用绝对路径，距离当前文件近，用相对路径。 cd - 跳转到上一次操作所在路径（最多只能记忆一次，再次使用就跳回来了） cd ~ 回到家目录 链接 命令 作用 ln -s 789.txt 789-softlink.txt 创建软链接文件（快捷方式） 原文件删除，软链接文件没有用了 ln 789.txt 789-hardlink.txt 创建硬链接文件（快捷方式） 硬链接文件相当于给原文件重新起名，原文件删除，硬链接文件数据仍然在。 如果写完一行命令不想执行，按control+C，则直接换行。 文件查找操作 命令 作用 find 在一个路径里找东西 find / -name “” 在根目录里按名字找，名字里带双引号里的 如果有没有权限的，在find前加sudo find ./ 在当前目录查找 按照文件名查找 find / -name httpd.conf 在根目录下查找文件httpd.conf，表示在整个硬盘查找 find /etc -name httpd.conf 在/etc目录下文件httpd.conf find /etc -name ‘srm‘ 使用通配符*(0或者任意多个)。表示在/etc目录下查找文件名中含有字符串‘srm’的文件 find . -name ‘srm*’ 表示当前目录下查找文件名开头是字符串‘srm’的文件 -size 按大小找 2M 大小等于 +2M 大小大于2M的文件 归档管理 tar tar -cvf test.tar *.py 将*.py的文件打包为test.tar tar -xvf test.tar 将test.tar解压到当前文件夹，压缩包不删 打包不压缩 tar -zcvf test.tar.gz *.py 压缩 tar -zxvf 解压缩 tar -jcvf test.tar.bz2 *.py 另一种压缩方式 tar -jxvf 解 tar 在命令后面加-C，加指定路径 解压到指定路径 一般用上面这两种压缩 zip test.zip *.py 压缩为zip文件（压缩效果不好） unzip test.zip 解 一些其它命令 命令 作用 links … 打开网页 which 查看用的命令在哪个路径下的文件 cal 日历 cal -y 2008 date 日期时间 ps aux ; top 查看当前运行情况（任务管理器） kill PID码 结束那个进程 kill后加-9 强制结束 reboot 重启 shutdown -h now 立刻关机 +10 10分钟后关机 20:20 df df -h 查看硬盘使用情况 du -h 当前路径使用情况 ifconfig 查看当前电脑上的网卡信息 ping +IP地址 测试远程电脑联通情况，能否通信 useradd shuaige -m 添加用户 sudo（没有权限） passwd shuaige 更改密码 su shuaige 切换账户 exit 退出 whoami 当前用户是谁 userdel shuaige 删除账户 userdel -r shuaige 同时删除家目录 sudo 拥有超级管理员的权限 sudo -s 变成超级管理员(root) groupadd shuaige 创建组 groupdel 删除 cat /etc/group 查看所有组 ls -alf","categories":[{"name":"Linux","slug":"Linux","permalink":"http://mangosTeeN96.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://mangosTeeN96.github.io/tags/Linux/"}]},{"title":"大数据环境搭建","slug":"大数据环境搭建","date":"2019-06-29T09:30:52.000Z","updated":"2020-08-10T08:44:51.292Z","comments":true,"path":"2019/06/29/大数据环境搭建/","link":"","permalink":"http://mangosTeeN96.github.io/2019/06/29/大数据环境搭建/","excerpt":"","text":"一、hadoop安装与伪分布式搭建创建Hadoop用户 创建新用户用户名为hadoop，使用/bin/bash作为shellsudo useradd -m hadoop -s /bin/bash 修改密码 1234$ sudo passwd hadoopEnter new UNIX password: Retype new UNIX password: passwd: password updated successfully 为hadoop用户添加管理员权限sudo adduser hadoop sudo 安装jdk1.7首先在oracle官网下载,接下来进行安装与环境变量配置，根据个人电脑系统选择对应版本，我选的是jdk-8u211-linux-x64.tar.gz 12345$ mkdir /usr/lib/jvm #创建jvm文件夹$ sudo tar -zxvf jdk-8u211-linux-x64.tar.gz -C /usr/lib/jvm #/ 解压到/usr/lib/jvm目录下$ cd /usr/lib/jvm #进入该目录$ mv jdk1.8.0_211 java #重命名为java$ vim ~/.bashrc #给JDK配置环境变量 在.bashrc文件添加如下指令： 1234export JAVA_HOME=/usr/lib/jvm/javaexport JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 在文件修改完毕以后，输入代码：$ source ~/.bashrc #使新配置的环境变量生效$ java -version #检测是否安装成功，查看java版本 安装SSH服务端 安装$ sudo apt-get install openssh-server 登录localhost$ ssh localhost 之后会在~/文件夹下发现一个.ssh文件 设置为无密码登录 123$ cd ~/.ssh/$ ssh-keygen -t rsa #出现提示直接按enter$ cat ./id_rsa.pub &gt;&gt; ./authorized_keys #加入授权 此时就直接使用$ ssh localhost，无密码登录了。 安装Hadoop本文采用伪分布式模式：存储采用分布式文件系统HDFS，但是HDFS的节点和数据节点都在同一节点。 下载安装下载安装包后解压即可使用： 1234$ sudo tar -zxvf hadoop-2.7.1.tar.gz -C /usr/local$ cd /usr/local/$ sudo mv ./hadoop-2.7.1/ ./hadoop # 将文件夹名改为hadoop$ sudo chown -R hadoop ./hadoop # 修改文件权限 查看Hadoop版本信息： 12$ cd /usr/local/hadoop/bin$ ./hadoop version &lt;img src=”大数据环境搭建/2.png&gt; 伪分布式模式配置修改配置文件:需要修改/usr/local/hadoop/etc/hadoop/文件夹下的core-site.xml和hdfs-site.xml文件。core-site.xml文件:将 12&lt;configuration&gt;&lt;/configuration&gt; 修改为： 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml文件修改如下： 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 将/hadoop/etc/hadoop/hadoop-env.sh文件的JAVA_HOME改为绝对路径。将export JAVA_HOME=$JAVA_HOME改为export JAVA_HOME=/usr/lib/jvm/default-java 注意：Hadoop的运行方式是由配置文件决定的，如果想从伪分布式模式切换回单机模式，只需删除core-site.xml文件中的配置项即可 执行名称节点格式化执行如下命令： 12$ cd /usr/local/hadoop$ ./bin/hdfs namenode -format 出现如下错误 原因应该是权限不够无法再目录内新建文件。解决方案是：先输入命令：sudo su转为root身份输入命令：sudo chmod -R a+w /opt/hadoop-1.2.1/注意修改自己的安装路径。输入命令exit回到用户身份 再执行格式化成功。如果出现/usr/local/hadoop/tmp/dfs/name has been successfully formatted.和 Exiting with status 0，表示格式化成功。 启动Hadoop12$ cd /usr/local/hadoop$ ./sbin/start-dfs.sh 用jps命令查看Hadoop是否启动成功，如果出现DataNode、NameNode、SecondaryNameNode的进程说明启动成功。 使用浏览器查看HDFS信息在浏览器中打开链接：http://localhost:50070/dfshealth.html#tab-overview即可查看 关闭Hadoop使用命令：./sbin/stop-dfs.sh下次启动时不需要再执行节点格式化命令（否则会报错），只需要直接运行start-dfs.sh命令即可。 二、hive安装2.1 hive的安装下载hive2.3.5，使用以下命令安装到/usr/local 1234$ sudo tar -xzf apache-hive-2.3.5-bin.tar.gz -C /usr/local/bigdata/$ cd /usr/local/bigdata/$ sudo mv apache-hive-2.3.5-bin/ hive$ sudo chown -R hadoop hive 2.2 配置环境变量1vim ~/.bashrc 添加以下代码： 1234export HIVE_HOME=/usr/local/hiveexport HCAT_HOME=$HIVE_HOME/hcatalogexport HIVE_CONF=$HIVE_HOME/confexport PATH=$PATH:$HIVE_HOME/bin 保存source ~/.bashrc 2.3 配置hive-site.xml以下操作默认是再hive安装目录/usr/local/hive下进行 1cp conf/hive-default.xml.template conf/hive-site.xml 然后修改hive-site.xml中的部分内容将对应的name修改成下面的value: 12345678910111213141516&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://localhost:3306/hive?characterEncoding=UTF-8&amp;amp;createDatabaseIfNotExist=true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt;&lt;/property&gt; 注意：此处name和password是后面mysql里面创建的hive用户和by hive密码，不要写错，否则后面初始化会报权限错误 在/usr/local/bigdata/hive/bin/修改hive-config.sh添加下面的3个export语句 123export JAVA_HOME=/usr/local/bigdata/java/javaexport HADOOP_HOME=/usr/local/bigdata/hadoopexport HIVE_HOME=/usr/local/bigdata/hive 1.4 安装MySQL (之前就安装了)运行 sudo apt-get install mysql-server mysql-client ,安装mysql 启动mysql服务 service mysql start 下载mysql-jdbc包，我下载的是mysql-connector-java-5.1.40.tar.gz，然后tar -xzf mysql-connector-java-5.1.40.tar.gzcp mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar /usr/local/bigdata/hive/lib/ 2.4 创建hive用户没安装MySQL的安装MySQL 运行 sudo apt-get install mysql-server mysql-client ,安装mysql 启动mysql服务 service mysql start 下载mysql-jdbc包，我下载的是mysql-connector-java-5.1.40.tar.gz，然后 12tar -xzf mysql-connector-java-5.1.40.tar.gzcp mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar /usr/local/bigdata/hive/lib/ 创建hive用户： 123mysql -uroot -prootcreate user ‘hive‘ identified by ‘hive‘;grant all privileges on *.* to ‘hive‘@‘localhost‘ identified by ‘hive‘; 2.5 使用hive用户再在mysql中创建名为hive的数据库12mysql -uhive -phivemysql&gt; create database hive; 元数据库初始化，使用命令 1schematool -dbType mysql -initSchema 使用hive即可进入 用root身份进入MySqlmysql -u root -p 出现错误 步骤一：登录mysqlsudo mysql -u root -p步骤四：修改root密码update mysql.user set authentication_string=PASSWORD(‘111111’), plugin=’mysql_native_password’ where user=’root’; 111111为设置的密码步骤五：刷新flush privileges; exit退出重启service mysql restart可以 mysql -u root -p 进入了 三、scala安装1234sudo tar -xzvf scala-2.12.5.tgz -C /usr/local/bigdata/cd /usr/local/bigdata/sudo mv scala-2.12.5/ scalasudo vim /etc/profile 添加 12export SCALA_HOME=/usr/local/bigdata/scalaexport PATH=$PATH:$SCALA_HOME/bin source /etc/profile 查看版本 scala -version 四、spark安装（伪分布式）1234sudo tar -xzvf spark-2.4.3-bin-hadoop2.7.tgz -C /usr/local/bigdata/cd /usr/local/bigdata/sudo mv spark-2.4.3-bin-hadoop2.7/ sparksudo vim /etc/profile 添加 12export SPARK_HOME=/usr/local/bigdata/sparkexport PATH=$PATH:$SPARK_HOME/bin source /etc/profile 配置配置spark-env.sh 进入到spark/conf/ 12cp spark-env.sh.template spark-env.shvim spark-env.sh 添加： 1234567export SCALA_HOME=/usr/local/bigdata/scalaexport JAVA_HOME=/usr/local/bigdata/java/javaexport HADOOP_HOME=/usr/local/bigdata/hadoopexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopSPARK_MASTER_IP=192.168.81.136SPARK_LOCAL_DIRS=/usr/local/bigdata/sparkSPARK_DRIVER_MEMORY=512M 注意：其中MASTER_IP为服务器IP java，hadoop等具体路径根据自己实际环境设置 配置Slave 12cp slaves.template slavesvim slaves 默认就是localhost（就无须更改了） 启动（前提是hadoop伪分布已经启动，就是上面的jps后出现那几个）： 启动sbin目录下的start-master.sh以及start-slaves.sh 启动bin目录下的spark-shell 五、hbase安装123sudo tar -xzvf hbase-2.0.5-bin.tar.gz -C /usr/local/bigdata/cd /usr/local/bigdata/sudo mv hbase-2.0.5/ hbase 修改系统环境变量sudo vim /etc/profile 添加： 12export HBASE_HOME=/usr/local/bigdata/hbaseexport PATH=$PATH:$HBASE_HOME/bin 使环境变量生效并验证环境变量生效 source /etc/profile 修改文件夹的权限123cd /usr/local/bigdatasudo chown -R hadoop:hadoop hbase 注意：hadoop为用户名（电脑） 不改权限后面启动会报权限错误 测试一下是否安装成功 hbase version 编辑hbase-env.sh 打开hbase-env.sh文件 12cd /usr/local/bigdata/hbase/confsudo vim hbase-env.sh 修改该文件配置 123456# Java环境export JAVA_HOME=/usr/local/bigdata/java/java#通过hadoop的配置文件找到hadoop集群（这行没写）export HBASE_CLASSPATH=/app/hadoop-1.1.2/conf#使用HBASE自带的zookeeper管理集群export HBASE_MANAGES_ZK=true 编辑hbase-site.xmlsudo vim hbase-site.xml 123456789101112131415&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;# ******默认localhost，分布式时是master，slave1，slave2(此处没写)&lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;******&lt;/value&gt;&lt;/property&gt; 启动并验证启动HBase 通过如下命令启动Hbase 12cd /usr/local/bigdata/hbase/bin./start-hbase.sh 验证启动 在hadoop节点使用jps查看节点状态 进入hbase的shell命令行，创建表member并进行查看 hbase shell 六、sqoop安装12345cd downloadsudo tar -xvzf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz -C /usr/local/bigdata/cd /usr/local/bigdatasudo mv sqoop-1.4.7.bin__hadoop-2.6.0/ sqoopsudo chown -R mangosteen:mangosteen sqoop 修改配置文件sqoop-env.sh123 cd sqoop/conf/cat sqoop-env-template.sh &gt;&gt; sqoop-env.sh #将sqoop-env-template.sh复制一份并命名为sqoop-env.shvim sqoop-env.sh #编辑sqoop-env.sh 修改sqoop-env.sh的如下信息 12345export HADOOP_COMMON_HOME=/usr/local/bigdata/hadoopexport HADOOP_MAPRED_HOME=/usr/local/bigdata/hadoopexport HBASE_HOME=/usr/local/bigdata/hbaseexport HIVE_HOME=/usr/local/bigdata/hive#export ZOOCFGDIR= #如果配置了ZooKeeper,也需要在此配置ZooKeeper的路径 配置环境变量打开当前用户的环境变量配置文件： vim ~/.bashrc 在配置文件第一行键入如下信息： 123export SQOOP_HOME=/usr/local/bigdata/sqoopexport PATH=$PATH:$SBT_HOME/bin:$SQOOP_HOME/binexport CLASSPATH=$CLASSPATH:$SQOOP_HOME/lib source ~/.bashrc 将mysql驱动包拷贝到$SQOOP_HOME/lib 1234sudo tar -zxvf mysql-connector-java-5.1.40.tar.gz #解压mysql驱动包ls #这时就可以看到解压缩后得到的目录mysql-connector-java-5.1.40cp ./mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar /usr/local/sqoop/lib 测试与MySQL的连接首先请确保mysql服务已经启动了，如果没有启动，请执行下面命令启动： service mysql start 然后就可以测试sqoop与MySQL之间的连接是否成功： 12sqoop list-databases --connect jdbc:mysql://192.168.81.136:3306/ --username hive -P 注意：192….是服务器ip；hive是mysql创建的用户名 注意：会让输入密码，输入的是创建hive时的密码hive mysql的数据库列表显示在屏幕上表示连接成功，如下图：","categories":[{"name":"大数据","slug":"大数据","permalink":"http://mangosTeeN96.github.io/categories/大数据/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://mangosTeeN96.github.io/tags/hadoop/"}]},{"title":"Java_多线程","slug":"Java_多线程","date":"2019-06-04T07:14:28.000Z","updated":"2020-08-04T07:48:11.791Z","comments":true,"path":"2019/06/04/Java_多线程/","link":"","permalink":"http://mangosTeeN96.github.io/2019/06/04/Java_多线程/","excerpt":"","text":"第一章 多线程我们在之前，学习的程序在没有跳转语句的前提下，都是由上至下依次执行，那现在想要设计一个程序，边打游戏边听歌，怎么设计？ 要解决上述问题,咱们得使用多进程或者多线程来解决. 1.1 并发与并行 并发：指两个或多个事件在同一个时间段内发生。 并行：指两个或多个事件在同一时刻发生（同时发生）。 在操作系统中，安装了多个程序，并发指的是在一段时间内宏观上有多个程序同时运行，这在单 CPU 系统中，每一时刻只能有一道程序执行，即微观上这些程序是分时的交替运行，只不过是给人的感觉是同时运行，那是因为分时交替运行的时间是非常短的。 而在多个 CPU 系统中，则这些可以并发执行的程序便可以分配到多个处理器上（CPU），实现多任务并行执行，即利用每个处理器来处理一个可以并发执行的程序，这样多个程序便可以同时执行。目前电脑市场上说的多核 CPU，便是多核处理器，核 越多，并行处理的程序越多，能大大的提高电脑运行的效率。 注意：单核处理器的计算机肯定是不能并行的处理多个任务的，只能是多个任务在单个CPU上并发运行。同理,线程也是一样的，从宏观角度上理解线程是并行运行的，但是从微观角度上分析却是串行运行的，即一个线程一个线程的去运行，当系统只有一个CPU时，线程会以某种顺序执行多个线程，我们把这种情况称之为线程调度。 1.2 线程与进程 进程：是指一个内存中运行的应用程序。每个进程都有一个独立的内存空间，一个应用程序可以同时运行多个进程；进程也是程序的一次执行过程，是系统运行程序的基本单位；系统运行一个程序即是一个进程从创建、运行到消亡的过程。 线程：线程是进程中的一个执行单元，负责当前进程中程序的执行，一个进程中至少有一个线程。一个进程中是可以有多个线程的，这个应用程序也可以称之为多线程程序。 简而言之：一个程序运行后至少有一个进程，一个进程中可以包含多个线程 我们可以再电脑底部任务栏，右键—–&gt;打开任务管理器,可以查看当前任务的进程： 进程 线程 线程调度: 分时调度 所有线程轮流使用 CPU 的使用权，平均分配每个线程占用 CPU 的时间。 抢占式调度 优先让优先级高的线程使用 CPU，如果线程的优先级相同，那么会随机选择一个(线程随机性)，Java使用的为抢占式调度。 设置线程的优先级 抢占式调度详解 大部分操作系统都支持多进程并发运行，现在的操作系统几乎都支持同时运行多个程序。比如：现在我们上课一边使用编辑器，一边使用录屏软件，同时还开着画图板，dos窗口等软件。此时，这些程序是在同时运行，”感觉这些软件好像在同一时刻运行着“。 实际上，CPU(中央处理器)使用抢占式调度模式在多个线程间进行着高速的切换。对于CPU的一个核而言，某个时刻，只能执行一个线程，而 CPU的在多个线程间切换速度相对我们的感觉要快，看上去就是在同一时刻运行。其实，多线程程序并不能提高程序的运行速度，但能够提高程序运行效率，让CPU的使用率更高。 1.3 主线程主线程:执行主(main)方法的线程 单线程程序:java程序中只有一个线程，执行从main方法开始,从上到下依次执行。 JVM执行main方法，main方法会进入到栈内存，JVM会找操作系统开辟一条main方法通向cpu的执行路径，cpu就可以通过这个路径来执行main方法，而这个路径有一个名字,叫main(主)线程。 1234567891011public class Demo01MainThread &#123; public static void main(String[] args) &#123; Person p1 = new Person(\"小强\"); p1.run(); System.out.println(0/0); //ArithmeticException: / by zero //当出现异常时，下面的代码将不再执行 Person p2 = new Person(\"旺财\"); p2.run(); &#125;&#125; 1.4 Thread类Java使用java.lang.Thread类代表线程，所有的线程对象都必须是Thread类或其子类的实例。 java.lang.Thread类:是描述线程的类,我们想要实现多线程程序,就必须继承Thread类 构造方法: public Thread() :分配一个新的线程对象。 public Thread(String name):分配一个指定名字的新的线程对象。 public Thread(Runnable target):分配一个带有指定目标新的线程对象。 public Thread(Runnable target,String name) :分配一个带有指定目标新的线程对象并指定名字。 常用方法: public String getName() :获取当前线程名称。 public void start() :导致此线程开始执行; Java虚拟机调用此线程的run方法。 public void run():此线程要执行的任务在此处定义代码。 public static void sleep(long millis) :使当前正在执行的线程以指定的毫秒数暂停(暂时停止执行)。 public static Thread currentThread():返回对当前正在执行的线程对象的引用。 获取线程的名称:两种方法： 使用Thread类中的方法getName()String getName() 返回该线程的名称。 可以先获取到当前正在执行的线程,使用线程中的方法getName()获取线程的名称static Thread currentThread() 返回对当前正在执行的线程对象的引用。 定义一个Thread类的子类 123456789101112131415161718public class MyThread extends Thread&#123; //重写Thread类中的run方法,设置线程任务 @Override public void run() &#123; //方法一获取线程名称 //String name = getName(); //System.out.println(name); //方法二 //Thread t = Thread.currentThread(); //System.out.println(t);//Thread[Thread-0,5,main] //String name = t.getName(); //System.out.println(name); //链式编程 System.out.println(Thread.currentThread().getName()); &#125;&#125; 测试类 12345678910111213141516171819/* 线程的名称: 主线程: main 新线程: Thread-0,Thread-1,Thread-2 */public class Demo01GetThreadName &#123; public static void main(String[] args) &#123; //创建Thread类的子类对象 MyThread mt = new MyThread(); //调用start方法,开启新线程,执行run方法 mt.start(); new MyThread().start(); new MyThread().start(); //链式编程（注意主方法只能用方法二，它没有继承thread类） System.out.println(Thread.currentThread().getName()); &#125;&#125; 设置线程的名称:(了解)两种方法： 使用Thread类中的方法setName(名字)void setName(String name)改变线程名称，使之与参数 name 相同。 创建一个带参数的构造方法,参数传递线程的名称;调用父类的带参构造方法,把线程名称传递给父类,让父类(Thread)给子线程起一个名字Thread(String name)分配新的 Thread 对象。 1234567891011121314public class MyThread extends Thread&#123; public MyThread()&#123;&#125; public MyThread(String name)&#123; super(name);//把线程名称传递给父类,让父类(Thread)给子线程起一个名字 &#125; @Override public void run() &#123; //获取线程的名称 System.out.println(Thread.currentThread().getName()); &#125;&#125; 1234567891011public class Demo01SetThreadName &#123; public static void main(String[] args) &#123; //开启多线程 MyThread mt = new MyThread(); mt.setName(\"小强\"); mt.start(); //开启多线程 new MyThread(\"旺财\").start(); &#125;&#125; sleep方法12345678910111213141516public class Demo01Sleep &#123; public static void main(String[] args) &#123; //模拟秒表 for (int i = 1; i &lt;=60 ; i++) &#123; System.out.println(i); //使用Thread类的sleep方法让程序睡眠1秒钟 //sleep方法本身有报错，处理一下 try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 1.5 创建线程类翻阅API后得知创建线程的方式总共有两种，一种是继承Thread类方式，一种是实现Runnable接口方式 创建Thread类的子类创建多线程程序的第一种方式:创建Thread类的子类 实现步骤: 创建一个Thread类的子类 在Thread类的子类中重写Thread类中的run方法,设置线程任务(开启线程要做什么?) 创建Thread类的子类对象 调用Thread类中的方法start方法,开启新的线程,执行run方法void start() 使该线程开始执行；Java 虚拟机调用该线程的 run 方法。结果是两个线程并发地运行；当前线程（main线程）和另一个线程（创建的新线程,执行其 run 方法）。多次启动一个线程是非法的。特别是当线程已经结束执行后，不能再重新启动。 java程序属于抢占式调度,那个线程的优先级高,那个线程优先执行;同一个优先级,随机选择一个执行 代码如下： 测试类： 123456789101112public class Demo01Thread &#123; public static void main(String[] args) &#123; //3.创建Thread类的子类对象 MyThread mt = new MyThread(); //4.调用Thread类中的方法start方法,开启新的线程,执行run方法 mt.start(); for (int i = 0; i &lt;20 ; i++) &#123; System.out.println(\"main:\"+i); &#125; &#125;&#125; 自定义线程类： 12345678910//1.创建一个Thread类的子类public class MyThread extends Thread&#123; //2.在Thread类的子类中重写Thread类中的run方法,设置线程任务(开启线程要做什么?) @Override public void run() &#123; for (int i = 0; i &lt;20 ; i++) &#123; System.out.println(\"run:\"+i); &#125; &#125;&#125; 执行结果是main、run交替输出。 实现Runnable接口方式创建多线程程序的第二种方式:实现Runnable接口 java.lang.RunnableRunnable 接口应该由那些打算通过某一线程执行其实例的类来实现。类必须定义一个称为 run 的无参数方法。 java.lang.Thread类的构造方法Thread(Runnable target)分配新的 Thread 对象。Thread(Runnable target, String name)分配新的 Thread 对象。 实现步骤: 创建一个Runnable接口的实现类 在实现类中重写Runnable接口的run方法,设置线程任务 创建一个Runnable接口的实现类对象 创建Thread类对象,构造方法中传递Runnable接口的实现类对象 调用Thread类中的start方法,开启新的线程执行run方法 测试类 123456789101112131415public class Demo01Runnable &#123; public static void main(String[] args) &#123; //3.创建一个Runnable接口的实现类对象 RunnableImpl run = new RunnableImpl(); //4.创建Thread类对象,构造方法中传递Runnable接口的实现类对象 Thread t = new Thread(run);//打印线程名称 //5.调用Thread类中的start方法,开启新的线程执行run方法 t.start(); for (int i = 0; i &lt;20 ; i++) &#123; System.out.println(Thread.currentThread().getName()+\"--&gt;\"+i); &#125; &#125;&#125; Runnable接口 12345678910//1.创建一个Runnable接口的实现类public class RunnableImpl implements Runnable&#123; //2.在实现类中重写Runnable接口的run方法,设置线程任务 @Override public void run() &#123; for (int i = 0; i &lt;20 ; i++) &#123; System.out.println(Thread.currentThread().getName()+\"--&gt;\"+i); &#125; &#125;&#125; Thread和Runnable的区别实现Runnable接口创建多线程程序的好处: 避免了单继承的局限性 一个类只能继承一个类，类继承了Thread类就不能继承其他的类 实现了Runnable接口,还可以继承其他的类,实现其他的接口 增强了程序的扩展性,降低了程序的耦合性(解耦) 实现Runnable接口的方式,把设置线程任务和开启新线程进行了分离(解耦) 实现类中,重写了run方法:用来设置线程任务 创建Thread类对象,调用start方法:用来开启新线程 匿名内部类方式匿名内部类方式实现线程的创建 匿名:没有名字内部类:写在其他类内部的类 匿名内部类作用:简化代码 把子类继承父类,重写父类的方法,创建子类对象合一步完成 把实现类实现类接口,重写接口中的方法,创建实现类对象合成一步完成 匿名内部类的最终产物:子类/实现类对象,而这个类没有名字 格式: 123new 父类/接口()&#123; 重复父类/接口中的方法&#125;; 123456789101112131415161718192021222324252627282930313233343536373839public class Demo01InnerClassThread &#123; public static void main(String[] args) &#123; //线程的父类是Thread // new MyThread().start(); new Thread()&#123; //重写run方法,设置线程任务 @Override public void run() &#123; for (int i = 0; i &lt;20 ; i++) &#123; System.out.println(Thread.currentThread().getName()+\"--&gt;\"+\"黑马\"); &#125; &#125; &#125;.start(); //线程的接口Runnable //Runnable r = new RunnableImpl();//多态 Runnable r = new Runnable()&#123; //重写run方法,设置线程任务 @Override public void run() &#123; for (int i = 0; i &lt;20 ; i++) &#123; System.out.println(Thread.currentThread().getName()+\"--&gt;\"+\"程序员\"); &#125; &#125; &#125;; new Thread(r).start(); //简化接口的方式 new Thread(new Runnable()&#123; //重写run方法,设置线程任务 @Override public void run() &#123; for (int i = 0; i &lt;20 ; i++) &#123; System.out.println(Thread.currentThread().getName()+\"--&gt;\"+\"传智播客\"); &#125; &#125; &#125;).start(); &#125;&#125; 第二章 线程安全2.1 线程安全如果有多个线程在同时运行，而这些线程可能会同时运行这段代码。程序每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。 案例： 模拟电影院的卖票过程，共有电影票100张，三个窗口同时卖这100张票 需要窗口，采用线程对象来模拟;需要票，Runnable接口子类来模拟 模拟票 1234567891011121314151617181920212223242526272829/* 实现卖票案例 */public class RunnableImpl implements Runnable&#123; //定义一个多个线程共享的票源 private int ticket = 100; //设置线程任务:卖票 @Override public void run() &#123; //使用死循环,让卖票操作重复执行 while(true)&#123; //先判断票是否存在 if(ticket&gt;0)&#123; //提高安全问题出现的概率,让程序睡眠,可以没有，多执行几次就会出现 try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //票存在,卖票 ticket-- System.out.println(Thread.currentThread().getName()+\"--&gt;正在卖第\"+ticket+\"张票\"); ticket--; &#125; &#125; &#125;&#125; 测试类 123456789101112131415161718/* 模拟卖票案例 创建3个线程,同时开启,对共享的票进行出售 */public class Demo01Ticket &#123; public static void main(String[] args) &#123; //创建Runnable接口的实现类对象 RunnableImpl run = new RunnableImpl(); //创建Thread类对象,构造方法中传递Runnable接口的实现类对象 Thread t0 = new Thread(run); Thread t1 = new Thread(run); Thread t2 = new Thread(run); //调用start方法开启多线程 t0.start(); t1.start(); t2.start(); &#125;&#125; 出现如下问题，不存在的票和重复的票： 这种问题，几个窗口(线程)票数不同步了，这种问题称为线程不安全。 线程安全问题产生的原理： 2.2 线程同步当我们使用多个线程访问同一资源的时候，且多个线程中对资源有写的操作，就容易出现线程安全问题。 要解决上述多线程并发访问一个资源的安全性问题:也就是解决重复票与不存在票问题，Java中提供了同步机制 (synchronized)来解决。 有三种方式完成同步操作: 同步代码块 同步方法 锁机制 同步代码块同步代码块: synchronized 关键字可以用于方法中的某个区块中，表示只对这个区块的资源实行互斥访问。 格式: 123synchronized(锁对象)&#123; 可能会出现线程安全问题的代码(访问了共享数据的代码)&#125; 注意: 通过代码块中的锁对象,可以使用任意的对象 但是必须保证多个线程使用的锁对象是同一个 锁对象作用:把同步代码块锁住,只让一个线程在同步代码块中执行 12345678910111213141516171819202122232425262728293031public class RunnableImpl implements Runnable&#123; //定义一个多个线程共享的票源 private int ticket = 100; //创建一个锁对象 Object obj = new Object(); //设置线程任务:卖票 @Override public void run() &#123; //使用死循环,让卖票操作重复执行 while(true)&#123; //同步代码块 synchronized (obj)&#123; //先判断票是否存在 if(ticket&gt;0)&#123; //提高安全问题出现的概率,让程序睡眠 try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //票存在,卖票 ticket-- System.out.println(Thread.currentThread().getName()+\"--&gt;正在卖第\"+ticket+\"张票\"); ticket--; &#125; &#125; &#125; &#125;&#125; 原理： 同步方法同步方法:使用synchronized修饰的方法,就叫做同步方法,保证A线程执行该方法的时候,其他线程只能在方法外等着。 使用步骤: 把访问了共享数据的代码抽取出来,放到一个方法中 在方法上添加synchronized修饰符 格式:定义方法的格式 123修饰符 synchronized 返回值类型 方法名(参数列表)&#123; 可能会出现线程安全问题的代码(访问了共享数据的代码)&#125; 1234567891011121314151617181920212223242526272829303132public class RunnableImpl implements Runnable&#123; //定义一个多个线程共享的票源 private int ticket = 100; //设置线程任务:卖票 @Override public void run() &#123; System.out.println(\"this:\"+this);//this:com.itheima.demo08.Synchronized.RunnableImpl@58ceff1 //使用死循环,让卖票操作重复执行 while(true)&#123; payTicket(); &#125; &#125; public synchronized void payTicket()&#123; //先判断票是否存在 if(ticket&gt;0)&#123; //提高安全问题出现的概率,让程序睡眠 try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //票存在,卖票 ticket-- System.out.println(Thread.currentThread().getName()+\"--&gt;正在卖第\"+ticket+\"张票\"); ticket--; &#125; &#125;&#125; 原理： 定义一个同步方法，同步方法也会把方法内部的代码锁住，只让一个线程执行 同步方法的锁对象是谁?就是实现类对象 new RunnableImpl()，也是就是this Lock锁java.util.concurrent.locks.Lock 机制提供了比synchronized代码块和synchronized方法更广泛的锁定操作，同步代码块/同步方法具有的功能Lock都有,除此之外更强大,更体现面向对象。 Lock锁也称同步锁，加锁与释放锁方法化了，如下: public void lock() :加同步锁 public void unlock() :释放同步锁 使用步骤: 在成员位置创建一个ReentrantLock对象 在可能会出现安全问题的代码前调用Lock接口中的方法lock获取锁 在可能会出现安全问题的代码后调用Lock接口中的方法unlock释放锁 12345678910111213141516171819202122232425262728293031323334public class RunnableImpl implements Runnable&#123; //定义一个多个线程共享的票源 private int ticket = 100; //1.在成员位置创建一个ReentrantLock对象 Lock l = new ReentrantLock(); //设置线程任务:卖票 @Override public void run() &#123; //使用死循环,让卖票操作重复执行 while(true)&#123; //2.在可能会出现安全问题的代码前调用Lock接口中的方法lock获取锁 l.lock(); //先判断票是否存在 if(ticket&gt;0)&#123; //提高安全问题出现的概率,让程序睡眠 try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //票存在,卖票 ticket-- System.out.println(Thread.currentThread().getName()+\"--&gt;正在卖第\"+ticket+\"张票\"); ticket--; &#125; //3.在可能会出现安全问题的代码后调用Lock接口中的方法unlock释放锁 l.unlock(); &#125; &#125;&#125; 部分代码简化： 123456789101112131415161718@Overridepublic void run() &#123; while(true)&#123; l.lock(); if(ticket&gt;0)&#123; try &#123; Thread.sleep(10); System.out.println(Thread.currentThread().getName()+\"--&gt;正在卖第\"+ticket+\"张票\"); ticket--; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; l.unlock();//无论程序是否异常,都会把锁释放 &#125; &#125; &#125;&#125; 第三章 等待唤醒机制3.1 线程状态概述当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。java.lang.Thread.State 枚举中给出了六种线程状态 线程状态 导致状态发生条件 NEW(新建) 线程刚被创建，但是并未启动。还没调用start方法。 Runnable(可 运行) 线程可以在java虚拟机中运行的状态，可能正在运行自己代码，也可能没有，这取决于操 作系统处理器。 Blocked(锁阻 塞) 当一个线程试图获取一个对象锁，而该对象锁被其他的线程持有，则该线程进入Blocked状 态;当该线程持有锁时，该线程将变成Runnable状态。 Waiting(无限 等待) 一个线程在等待另一个线程执行一个(唤醒)动作时，该线程进入Waiting状态。进入这个 状态后是不能自动唤醒的，必须等待另一个线程调用notify或者notifyAll方法才能够唤醒。 Timed Waiting(计时 等待) 同waiting状态，有几个方法有超时参数，调用他们将进入Timed Waiting状态。这一状态 将一直保持到超时期满或者接收到唤醒通知。带有超时参数的常用方法有Thread.sleep 、 Object.wait。 Teminated(被 终止) 因为run方法正常退出而死亡，或者因为没有捕获的异常终止了run方法而死亡。 Timed Waiting(计时等待)进入到TimeWaiting(计时等待)有两种方 使用sleep(long m)方法,在毫秒值结束之后,线程睡醒进入到Runnable/Blocked状态 使用wait(long m)方法,wait方法如果在毫秒值结束之后,还没有被notify唤醒,就会自动醒来,线程睡醒进入到Runnable/Blocked状态 唤醒的方法:void notify() 唤醒在此对象监视器上等待的单个线程。void notifyAll() 唤醒在此对象监视器上等待的所有线程。 BLOCKED(锁阻塞) Waiting(无限等待) 等待唤醒案例:线程之间的通信 创建一个顾客线程(消费者):告知老板要的包子的种类和数量,调用wait方法,放弃cpu的执行,进入到WAITING状态(无限等待) 创建一个老板线程(生产者):花了5秒做包子,做好包子之后,调用notify方法,唤醒顾客吃包子 注意: 顾客和老板线程必须使用同步代码块包裹起来,保证等待和唤醒只能有一个在执行 同步使用的锁对象必须保证唯一 只有锁对象才能调用wait和notify方法 Obejct类中的方法void wait():在其他线程调用此对象的 notify() 方法或 notifyAll() 方法前，导致当前线程等待。void notify():唤醒在此对象监视器上等待的单个线程。会继续执行wait方法之后的代码void notifyAll() 唤醒在此对象监视器上等待的所有线程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Demo01WaitAndNotify &#123; public static void main(String[] args) &#123; //创建锁对象,保证唯一 Object obj = new Object(); // 创建一个顾客线程(消费者) new Thread()&#123; @Override public void run() &#123; //一直等着买包子 while(true)&#123; //保证等待和唤醒的线程只能有一个执行,需要使用同步技术 synchronized (obj)&#123; System.out.println(\"告知老板要的包子的种类和数量\"); //调用wait方法,放弃cpu的执行,进入到WAITING状态(无限等待) try &#123; obj.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //唤醒之后执行的代码 System.out.println(\"包子已经做好了,开吃!\"); System.out.println(\"---------------------------------------\"); &#125; &#125; &#125; &#125;.start(); //创建一个老板线程(生产者) new Thread()&#123; @Override public void run() &#123; //一直做包子 while (true)&#123; //花了5秒做包子 try &#123; Thread.sleep(5000);//花5秒钟做包子 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //保证等待和唤醒的线程只能有一个执行,需要使用同步技术 synchronized (obj)&#123; System.out.println(\"老板5秒钟之后做好包子,告知顾客,可以吃包子了\"); //做好包子之后,调用notify方法,唤醒顾客吃包子 obj.notify(); &#125; &#125; &#125; &#125;.start(); &#125;&#125; 3.2 线程间通信概念：多个线程在处理同一个资源，但是处理的动作（线程的任务）却不相同。 比如：线程A用来生成包子的，线程B用来吃包子的，包子可以理解为同一资源，线程A与线程B处理的动作，一个是生产，一个是消费，那么线程A与线程B之间就存在线程通信问题。 为什么要处理线程间通信： 多个线程并发执行时, 在默认情况下CPU是随机切换线程的，当我们需要多个线程来共同完成一件任务，并且我们希望他们有规律的执行, 那么多线程之间需要一些协调通信，以此来帮我们达到多线程共同操作一份数据。 如何保证线程间通信有效利用资源： 多个线程在处理同一个资源，并且任务不同时，需要线程通信来帮助解决线程之间对同一个变量的使用或操作。 就是多个线程在操作同一份数据时， 避免对同一共享变量的争夺。也就是我们需要通过一定的手段使各个线程能有效的利用资源。而这种手段即—— 等待唤醒机制。 3.3 等待唤醒机制等待唤醒机制: 这是多个线程间的一种协作机制。就是在一个线程进行了规定操作后，就进入等待状态（wait()）， 等待其他线程执行完他们的指定代码过后 再将其唤醒（notify()）;在有多个线程进行等待时， 如果需要，可以使用 notifyAll()来唤醒所有的等待线程。 wait/notify 就是线程间的一种协作机制。 等待唤醒中的方法 等待唤醒机制就是用于解决线程间通信的问题的，使用到的3个方法的含义如下： wait：线程不再活动，不再参与调度，进入 wait set 中，因此不会浪费 CPU 资源，也不会去竞争锁了，这时的线程状态即是 WAITING。它还要等着别的线程执行一个特别的动作，也即是“通知（notify）”在这个对象上等待的线程从wait set 中释放出来，重新进入到调度队列（ready queue）中 notify：则选取所通知对象的 wait set 中的一个线程释放；例如，餐馆有空位置后，等候就餐最久的顾客最先入座。 notifyAll：则释放所通知对象的 wait set 上的全部线程。 注意： 哪怕只通知了一个等待的线程，被通知线程也不能立即恢复执行，因为它当初中断的地方是在同步块内，而此刻它已经不持有锁，所以她需要再次尝试去获取锁（很可能面临其它线程的竞争），成功后才能在当初调用 wait 方法之后的地方恢复执行。 总结如下： 如果能获取锁，线程就从 WAITING 状态变成 RUNNABLE 状态； 否则，从 wait set 出来，又进入 entry set，线程就从 WAITING 状态又变成 BLOCKED 状态 调用wait和notify方法需要注意的细节 wait方法与notify方法必须要由同一个锁对象调用。因为：对应的锁对象可以通过notify唤醒使用同一个锁对象调用的wait方法后的线程。 wait方法与notify方法是属于Object类的方法的。因为：锁对象可以是任意对象，而任意对象的所属类都是继承了Object类的。 wait方法与notify方法必须要在同步代码块或者是同步函数中使用。因为：必须要通过锁对象调用这2个方法。 3.4 生产者与消费者问题等待唤醒机制其实就是经典的“生产者与消费者”的问题。 就拿生产包子消费包子来说等待唤醒机制如何有效利用资源： 代码演示： 包子资源类： 12345678910111213141516/* 资源类:包子类 设置包子的属性 皮 陷 包子的状态: 有 true,没有 false */public class BaoZi &#123; //皮 String pi; //陷 String xian; //包子的状态: 有 true,没有 false,设置初始值为false没有包子 boolean flag = false;&#125; 吃货线程类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* 消费者(吃货)类:是一个线程类,可以继承Thread 设置线程任务(run):吃包子 对包子的状态进行判断 false:没有包子 吃货调用wait方法进入等待状态 true:有包子 吃货吃包子 吃货吃完包子 修改包子的状态为false没有 吃货唤醒包子铺线程,生产包子 */public class ChiHuo extends Thread&#123; //1.需要在成员位置创建一个包子变量 private BaoZi bz; //2.使用带参数构造方法,为这个包子变量赋值 public ChiHuo(BaoZi bz) &#123; this.bz = bz; &#125; //设置线程任务(run):吃包子 @Override public void run() &#123; //使用死循环,让吃货一直吃包子 while (true)&#123; //必须同时同步技术保证两个线程只能有一个在执行 synchronized (bz)&#123; //对包子的状态进行判断 if(bz.flag==false)&#123; //吃货调用wait方法进入等待状态 try &#123; bz.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //被唤醒之后执行的代码,吃包子 System.out.println(\"吃货正在吃:\"+bz.pi+bz.xian+\"的包子\"); //吃货吃完包子 //修改包子的状态为false没有 bz.flag = false; //吃货唤醒包子铺线程,生产包子 bz.notify(); System.out.println(\"吃货已经把:\"+bz.pi+bz.xian+\"的包子吃完了,包子铺开始生产包子\"); System.out.println(\"----------------------------------------------------\"); &#125; &#125; &#125;&#125; 包子铺线程类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/* 生产者(包子铺)类:是一个线程类,可以继承Thread 设置线程任务(run):生产包子 对包子的状态进行判断 true:有包子 包子铺调用wait方法进入等待状态 false:没有包子 包子铺生产包子 增加一些趣味性:交替生产两种包子 有两种状态(i%2==0) 包子铺生产好了包子 修改包子的状态为true有 唤醒吃货线程,让吃货线程吃包子 注意: 包子铺线程和包子线程关系--&gt;通信(互斥) 必须同时同步技术保证两个线程只能有一个在执行 锁对象必须保证唯一,可以使用包子对象作为锁对象 包子铺类和吃货的类就需要把包子对象作为参数传递进来 1.需要在成员位置创建一个包子变量 2.使用带参数构造方法,为这个包子变量赋值 */public class BaoZiPu extends Thread&#123; //1.需要在成员位置创建一个包子变量 private BaoZi bz; //2.使用带参数构造方法,为这个包子变量赋值 public BaoZiPu(BaoZi bz) &#123; this.bz = bz; &#125; //设置线程任务(run):生产包子 @Override public void run() &#123; //定义一个变量 int count = 0; //让包子铺一直生产包子 while(true)&#123; //必须同时同步技术保证两个线程只能有一个在执行 synchronized (bz)&#123; //对包子的状态进行判断 if(bz.flag==true)&#123; //包子铺调用wait方法进入等待状态 try &#123; bz.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //被唤醒之后执行,包子铺生产包子 //增加一些趣味性:交替生产两种包子 if(count%2==0)&#123; //生产 薄皮三鲜馅包子 bz.pi = \"薄皮\"; bz.xian = \"三鲜馅\"; &#125;else&#123; //生产 冰皮 牛肉大葱陷 bz.pi = \"冰皮\"; bz.xian = \"牛肉大葱陷\"; &#125; count++; System.out.println(\"包子铺正在生产:\"+bz.pi+bz.xian+\"包子\"); //生产包子需要3秒钟 try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //包子铺生产好了包子 //修改包子的状态为true有 bz.flag = true; //唤醒吃货线程,让吃货线程吃包子 bz.notify(); System.out.println(\"包子铺已经生产好了:\"+bz.pi+bz.xian+\"包子,吃货可以开始吃了\"); &#125; &#125; &#125;&#125; 测试类： 1234567891011121314151617/* 测试类: 包含main方法,程序执行的入口,启动程序 创建包子对象; 创建包子铺线程,开启,生产包子; 创建吃货线程,开启,吃包子; */public class Demo &#123; public static void main(String[] args) &#123; //创建包子对象; BaoZi bz =new BaoZi(); //创建包子铺线程,开启,生产包子; new BaoZiPu(bz).start(); //创建吃货线程,开启,吃包子; new ChiHuo(bz).start(); &#125;&#125; 执行效果： 第四章 线程池如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？ 4.1 线程池概念 线程池：其实就是一个容纳多个线程的容器，其中的线程可以反复使用，省去了频繁创建线程对象的操作，无需反复创建线程而消耗过多资源。 合理利用线程池能够带来三个好处： 降低资源消耗。减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。 2.3 线程池的使用Java里面线程池的顶级接口是java.util.concurrent.Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是java.util.concurrent.ExecutorService。 要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在java.util.concurrent.Executors线程工厂类里面提供了一些静态工厂，生成一些常用的线程池。官方建议使用Executors工程类来创建线程池对象。 Executors类中创建线程池的方法： public static ExecutorService newFixedThreadPool(int nThreads)：返回线程池对象。(创建的是有界线程池,也就是池中的线程个数可以指定最大数量) 参数:int nThreads创建线程池中包含的线程数量 返回值:ExecutorService接口,返回的是ExecutorService接口的实现类对象,我们可以使用ExecutorService接口接收(面向接口编程 获取到了一个线程池ExecutorService对象，使用线程池对象的方法： public Future&lt;?&gt; submit(Runnable task):获取线程池中的某一个线程对象，并执行 Future接口：用来记录线程任务执行完毕后产生的结果。线程池创建与使用。 关闭/销毁线程池的方法 void shutdown() 线程池的使用步骤: 使用线程池的工厂类Executors里边提供的静态方法newFixedThreadPool生产一个指定线程数量的线程池 创建一个类,实现Runnable接口,重写run方法,设置线程任务 调用ExecutorService中的方法submit,传递线程任务(实现类),开启线程,执行run方法 调用ExecutorService中的方法shutdown销毁线程池(不建议执行) Runnable实现类代码： 12345678910111213public class MyRunnable implements Runnable &#123; @Override public void run() &#123; System.out.println(\"我要一个教练\"); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"教练来了： \" + Thread.currentThread().getName()); System.out.println(\"教我游泳,交完后，教练回到了游泳池\"); &#125;&#125; 线程池测试类： 12345678910111213141516171819202122public class ThreadPoolDemo &#123; public static void main(String[] args) &#123; // 创建线程池对象 ExecutorService service = Executors.newFixedThreadPool(2);//包含2个线程对象 // 创建Runnable实例对象 MyRunnable r = new MyRunnable(); //自己创建线程对象的方式 // Thread t = new Thread(r); // t.start(); ---&gt; 调用MyRunnable中的run() // 从线程池中获取线程对象,然后调用MyRunnable中的run() service.submit(r); // 再获取个线程对象，调用MyRunnable中的run() service.submit(r); service.submit(r); // 注意：submit方法调用结束后，程序并不终止，是因为线程池控制了线程的关闭。 // 将使用完的线程又归还到了线程池中 // 关闭线程池 //service.shutdown(); &#125;&#125; 第五章 Lambda表达式5.1 背景函数式编程思想概述在数学中，函数就是有输入量、输出量的一套计算方案，也就是“拿什么东西做什么事情”。相对而言，面向对象过分强调“必须通过对象的形式来做事情”，而函数式思想则尽量忽略面向对象的复杂语法——强调做什么，而不是以什么形式做。 面向对象的思想:做一件事情,找一个能解决这个事情的对象,调用对象的方法,完成事情. 函数式编程思想:只要能获取到结果,谁去做的,怎么做的都不重要,重视的是结果,不重视过程 冗余的Runnable代码传统写法 当需要启动一个线程去完成任务时，通常会通过java.lang.Runnable接口来定义任务内容，并使用java.lang.Thread类来启动该线程。代码如下： 123456789101112public class Demo01Runnable &#123; public static void main(String[] args) &#123; // 匿名内部类 Runnable task = new Runnable() &#123; @Override public void run() &#123; // 覆盖重写抽象方法 System.out.println(\"多线程任务执行！\"); &#125; &#125;; new Thread(task).start(); // 启动线程 &#125;&#125; 本着“一切皆对象”的思想，这种做法是无可厚非的：首先创建一个Runnable接口的匿名内部类对象来指定任务内容，再将其交给一个线程来启动。 代码分析 对于Runnable的匿名内部类用法，可以分析出几点内容： Thread类需要Runnable接口作为参数，其中的抽象run方法是用来指定线程任务内容的核心； 为了指定run的方法体，不得不需要Runnable接口的实现类； 为了省去定义一个RunnableImpl实现类的麻烦，不得不使用匿名内部类； 必须覆盖重写抽象run方法，所以方法名称、方法参数、方法返回值不得不再写一遍，且不能写错； 而实际上，似乎只有方法体才是关键所在。 编程思想转换做什么，而不是怎么做 我们并不希望创建一个匿名内部类对象吗，只是为了做这件事情而不得不创建一个对象。真正希望做的事情是：将run方法体内的代码传递给Thread类知晓。 传递一段代码——这才是我们真正的目的。而创建对象只是受限于面向对象语法而不得不采取的一种手段方式。 体验Lambda的更优写法2014年3月Oracle所发布的Java 8（JDK 1.8）中，加入了Lambda表达式的重量级新特性。 借助Java 8的全新语法，上述Runnable接口的匿名内部类写法可以通过更简单的Lambda表达式达到等效： 12345public class Demo02LambdaRunnable &#123; public static void main(String[] args) &#123; new Thread(() -&gt; System.out.println(\"多线程任务执行！\")).start(); // 启动线程 &#125;&#125; 这段代码和刚才的执行效果是完全一样的，可以在1.8或更高的编译级别下通过。从代码的语义中可以看出：我们启动了一个线程，而线程任务的内容以一种更加简洁的形式被指定。 回顾匿名内部类Lambda是怎样击败面向对象的？在上例中，核心代码其实只是如下所示的内容： 1() -&gt; System.out.println(\"多线程任务执行！\") 为了理解Lambda的语义，我们需要从传统的代码起步。 使用实现类: 要启动一个线程，需要创建一个Thread类的对象并调用start方法。而为了指定线程执行的内容，需要调用Thread类的构造方法： public Thread(Runnable target) 为了获取Runnable接口的实现对象，可以为该接口定义一个实现类RunnableImpl： 123456public class RunnableImpl implements Runnable &#123; @Override public void run() &#123; System.out.println(\"多线程任务执行！\"); &#125;&#125; 然后创建该实现类的对象作为Thread类的构造参数： 123456public class Demo03ThreadInitParam &#123; public static void main(String[] args) &#123; Runnable task = new RunnableImpl(); new Thread(task).start(); &#125;&#125; 使用匿名内部类: 这个RunnableImpl类只是为了实现Runnable接口而存在的，而且仅被使用了唯一一次，所以使用匿名内部类的语法即可省去该类的单独定义，即匿名内部类： 12345678910public class Demo04ThreadNameless &#123; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"多线程任务执行！\"); &#125; &#125;).start(); &#125;&#125; 匿名内部类的好处与弊端: 一方面，匿名内部类可以帮我们省去实现类的定义；另一方面，匿名内部类的语法——确实太复杂了！ 语义分析: 仔细分析该代码中的语义，Runnable接口只有一个run方法的定义： public abstract void run(); 即制定了一种做事情的方案（其实就是一个函数）： 无参数：不需要任何条件即可执行该方案。 无返回值：该方案不产生任何结果。 代码块（方法体）：该方案的具体执行步骤。 同样的语义体现在Lambda语法中，要更加简单： 1() -&gt; System.out.println(\"多线程任务执行！\") 前面的一对小括号即run方法的参数（无），代表不需要任何条件； 中间的一个箭头代表将前面的参数传递给后面的代码； 后面的输出语句即业务逻辑代码。 5.2 Lambda标准格式Lambda省去面向对象的条条框框，格式由3个部分组成： 一些参数 一个箭头 一段代码 Lambda表达式的标准格式为： 1(参数类型 参数名称) -&gt; &#123; 一些重写方法的代码 &#125; 格式说明： ():接口中抽象方法的参数列表,没有参数,就空着;有参数就写出参数,多个参数使用逗号分隔 -&gt;是新引入的语法格式，代表指向动作。 {}:重写接口的抽象方法的方法体 使用Lambda标准格式（无参无返回）题目 给定一个厨子Cook接口，内含唯一的抽象方法makeFood，且无参数、无返回值。如下： 123public interface Cook &#123; void makeFood();&#125; 在下面的代码中，请使用Lambda的标准格式调用invokeCook方法，打印输出“吃饭啦！”字样： 123456789public class Demo05InvokeCook &#123; public static void main(String[] args) &#123; // TODO 请在此使用Lambda【标准格式】调用invokeCook方法 &#125; private static void invokeCook(Cook cook) &#123; cook.makeFood(); &#125;&#125; 解答 123456789101112131415161718192021222324public class Demo01Cook &#123; public static void main(String[] args) &#123; //调用invokeCook方法,参数是Cook接口,传递Cook接口的匿名内部类对象 invokeCook(new Cook() &#123; @Override public void makeFood() &#123; System.out.println(\"吃饭了\"); &#125; &#125;); //使用Lambda表达式,简化匿名内部类的书写 invokeCook(()-&gt;&#123; System.out.println(\"吃饭了\"); &#125;); //优化省略Lambda invokeCook(()-&gt; System.out.println(\"吃饭了\")); &#125; //定义一个方法,参数传递Cook接口,方法内部调用Cook接口中的方法makeFood public static void invokeCook(Cook cook)&#123; cook.makeFood(); &#125;&#125; 备注：小括号代表Cook接口makeFood抽象方法的参数为空，大括号代表makeFood的方法体。 5.3 Lambda的参数和返回值 需求: 使用数组存储多个Person对象 对数组中的Person对象使用Arrays的sort方法通过年龄进行升序排序 下面举例演示java.util.Comparator&lt;T&gt;接口的使用场景代码，其中的抽象方法定义为： public abstract int compare(T o1, T o2); 当需要对一个对象数组进行排序时，Arrays.sort方法需要一个Comparator接口实例来指定排序的规则。假设有一个Person类，含有String name和int age两个成员变量： 123456public class Person &#123; private String name; private int age; // 省略构造器、toString方法与Getter Setter &#125; 传统写法如果使用传统的代码对Person[]数组进行排序，写法如下： 12345678910111213141516171819202122232425import java.util.Arrays;import java.util.Comparator;public class Demo06Comparator &#123; public static void main(String[] args) &#123; // 本来年龄乱序的对象数组 Person[] array = &#123; new Person(\"古力娜扎\", 19), new Person(\"迪丽热巴\", 18), new Person(\"马尔扎哈\", 20) &#125;; // 匿名内部类 Comparator&lt;Person&gt; comp = new Comparator&lt;Person&gt;() &#123; @Override public int compare(Person o1, Person o2) &#123; return o1.getAge() - o2.getAge(); &#125; &#125;; Arrays.sort(array, comp); // 第二个参数为排序规则，即Comparator接口实例 for (Person person : array) &#123; System.out.println(person); &#125; &#125;&#125; 代码分析: 下面我们来搞清楚上述代码真正要做什么事情。 为了排序，Arrays.sort方法需要排序规则，即Comparator接口的实例，抽象方法compare是关键； 为了指定compare的方法体，不得不需要Comparator接口的实现类； 为了省去定义一个ComparatorImpl实现类的麻烦，不得不使用匿名内部类； 必须覆盖重写抽象compare方法，所以方法名称、方法参数、方法返回值不得不再写一遍，且不能写错； 实际上，只有参数和方法体才是关键。 Lambda写法123456789101112131415161718192021import java.util.Arrays;public class Demo07ComparatorLambda &#123; public static void main(String[] args) &#123; Person[] array = &#123; new Person(\"古力娜扎\", 19), new Person(\"迪丽热巴\", 18), new Person(\"马尔扎哈\", 20) &#125;; Arrays.sort(array, (Person a, Person b) -&gt; &#123; return a.getAge() - b.getAge(); &#125;); //优化省略Lambda //Arrays.sort(arr,(o1, o2)-&gt;o1.getAge()-o2.getAge()); for (Person person : array) &#123; System.out.println(person); &#125; &#125;&#125; 练习：使用Lambda标准格式（有参有返回）题目 给定一个计算器Calculator接口，内含抽象方法calc可以将两个int数字相加得到和值： 123public interface Calculator &#123; int calc(int a, int b);&#125; 在下面的代码中，请使用Lambda的标准格式调用invokeCalc方法，完成120和130的相加计算： 12345678910public class Demo08InvokeCalc &#123; public static void main(String[] args) &#123; // TODO 请在此使用Lambda【标准格式】调用invokeCalc方法来计算120+130的结果ß &#125; private static void invokeCalc(int a, int b, Calculator calculator) &#123; int result = calculator.calc(a, b); System.out.println(\"结果是：\" + result); &#125;&#125; 解答 12345678public static void main(String[] args) &#123; invokeCalc(120, 130, (int a, int b) -&gt; &#123; return a + b; &#125;); //优化省略Lambda //invokeCalc(120,130,(a,b)-&gt; a + b);&#125; 备注：小括号代表Calculator接口calc抽象方法的参数，大括号代表calc的方法体。 5.4 Lambda省略格式可推导即可省略: 凡是可以根据上下文推导得知的信息，都可以省略。例如上例还可以使用Lambda的省略写法： 123public static void main(String[] args) &#123; invokeCalc(120, 130, (a, b) -&gt; a + b);&#125; 省略规则: 在Lambda标准格式的基础上，使用省略写法的规则为： 小括号内参数类型可以省略； 如果小括号内有且仅有一个参，则小括号可以省略； 如果大括号内有且仅有一个语句，则无论是否有返回值，都可以省略大括号、return关键字及语句分号（要省略三个必须一起省略） 具体例子可以看前面的代码。 5.5 Lambda的使用前提Lambda的语法非常简洁，完全没有面向对象复杂的束缚。但是使用时有几个问题需要特别注意： 使用Lambda必须具有接口，且要求接口中有且仅有一个抽象方法。 无论是JDK内置的Runnable、Comparator接口还是自定义的接口，只有当接口中的抽象方法存在且唯一时，才可以使用Lambda。 使用Lambda必须具有上下文推断。 也就是方法的参数或局部变量类型必须为Lambda对应的接口类型，才能使用Lambda作为该接口的实例。 备注：有且仅有一个抽象方法的接口，称为“函数式接口”。","categories":[{"name":"java","slug":"java","permalink":"http://mangosTeeN96.github.io/categories/java/"}],"tags":[]},{"title":"Java_List、Set、Map集合","slug":"Java_List、Set、Map集合","date":"2019-05-30T02:42:27.000Z","updated":"2020-08-04T07:48:36.032Z","comments":true,"path":"2019/05/30/Java_List、Set、Map集合/","link":"","permalink":"http://mangosTeeN96.github.io/2019/05/30/Java_List、Set、Map集合/","excerpt":"","text":"第一章 数据结构1.1 常见的数据结构数据存储的常用结构有：栈、队列、数组、链表和红黑树 栈栈：stack,又称堆栈，它是运算受限的线性表，其限制是仅允许在标的一端进行插入和删除操作，不允许在其他任何位置进行添加、查找、删除等操作。 采用该结构的集合，对元素的存取有如下的特点 先进后出（即，存进去的元素，要在后它后面的元素依次取出后，才能取出该元素） 栈的入口、出口的都是栈的顶端位置。 注意： 压栈：就是存元素。即，把元素存储到栈的顶端位置，栈中已有元素依次向栈底方向移动一个位置。 弹栈：就是取元素。即，把栈的顶端位置元素取出，栈中已有元素依次向栈顶方向移动一个位置。 补充： Stack的方法java中Stack只有一个无参构造函数。属于stack自己的方法包括： push( num) //入栈 pop() //栈顶元素出栈 empty() //判定栈是否为空 peek() //获取栈顶元素 search(num) //判端元素num是否在栈中，如果在返回1，不在返回-1。 队列队列：queue,简称队，它同堆栈一样，也是一种运算受限的线性表，其限制是仅允许在表的一端进行插入，而在表的另一端进行删除。 采用该结构的集合，对元素的存取有如下的特点： 先进先出（即，存进去的元素，要在后它前面的元素依次取出后，才能取出该元素） 队列的入口、出口各占一侧 数组数组:Array,是有序的元素序列，数组是在内存中开辟一段连续的空间，并在此空间存放元素。就像是一排出租屋，有100个房间，从001到100每个房间都有固定编号，通过编号就可以快速找到租房子的人。 采用该结构的集合，对元素的存取有如下的特点： 查找元素快：通过索引，可以快速访问指定位置的元素 增删元素慢 指定索引位置增加元素：需要创建一个新数组，将指定新元素存储在指定索引位置，再把原数组元素根据索引，复制到新数组对应索引的位置。 指定索引位置删除元素：需要创建一个新数组，把原数组元素根据索引，复制到新数组对应索引的位置，原数组中指定索引位置元素不复制到新数组中。 链表链表:linked list,由一系列结点node（链表中每一个元素称为结点）组成，结点可以在运行时i动态生成。每个结点包括两个部分：一个是存储数据元素的数据域，另一个是存储下一个结点地址的指针域。 我们常说的链表结构有单向链表与双向链表 单向链表: 采用该结构的集合，对元素的存取有如下的特点： 多个结点之间，通过地址进行连接 查找元素慢：想查找某个元素，需要通过连接的节点，依次向后查找指定元素 增删元素快： 增加元素：只需要修改连接下个元素的地址即可。 删除元素：只需要修改连接下个元素的地址即可。 红黑树二叉树：binary tree ,是每个结点不超过2的有序树（tree）。 二叉树是每个节点最多有两个子树的树结构。顶上的叫根结点，两边被称作“左子树”和“右子树”。 红黑树，红黑树本身就是一颗二叉查找树，将节点插入后，该树仍然是一颗二叉查找树。也就意味着，树的键值仍然是有序的。 红黑树的约束: 节点可以是红色的或者黑色的 根节点是黑色的 叶子节点(特指空节点)是黑色的 每个红色节点的子节点都是黑色的 任何一个节点到其每一个叶子节点的所有路径上黑色节点数相同 红黑树的特点: ​ 速度特别快,趋近平衡树,查找叶子元素最少和最多次数不多于二倍 第二章 List集合Collection中的常用子类（java.util.List集合、java.util.Set集合）。 2.1 List接口介绍java.util.List接口继承自Collection接口，是单列集合的一个重要分支，习惯性地会将实现了List接口的对象称为List集合。 List接口特点： 它是一个元素存取有序的集合。例如，存元素的顺序是11、22、33。那么集合中，元素的存储就是按照11、22、33的顺序完成的）。 它是一个带有索引的集合，通过索引就可以精确的操作集合中的元素（与数组的索引是一个道理）。 集合中可以有重复的元素，通过元素的equals方法，来比较是否为重复的元素。 tips:java.util.ArrayList类是List接口的子类，该类中的方法都是来自List中定义。 2.2 List接口中常用方法List作为Collection集合的子接口，不但继承了Collection接口中的全部方法，而且还增加了一些根据元素索引来操作集合的特有方法，如下： public void add(int index, E element): 将指定的元素，添加到该集合中的指定位置上。 public E get(int index):返回集合中指定位置的元素。 public E remove(int index): 移除列表中指定位置的元素, 返回的是被移除的元素。 public E set(int index, E element):用指定元素替换集合中指定位置的元素,返回值的更新前的元素。 注意：操作索引时注意不要越界异常 List集合特有的方法都是跟索引相关，前面学过，此处复习 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class ListDemo &#123; public static void main(String[] args) &#123; // 创建List集合对象，多态 List&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 往 尾部添加 指定元素 list.add(\"图图\"); list.add(\"小美\"); list.add(\"不高兴\"); System.out.println(list); // add(int index,String s) 往指定位置添加 list.add(1,\"没头脑\"); System.out.println(list); // String remove(int index) 删除指定位置元素 返回被删除元素 // 删除索引位置为2的元素 System.out.println(\"删除索引位置为2的元素\"); System.out.println(list.remove(2)); System.out.println(list); // String set(int index,String s) // 在指定位置 进行 元素替代（改） // 修改指定位置元素 list.set(0, \"三毛\"); System.out.println(list); // String get(int index) 获取指定位置元素 // 跟size() 方法一起用 来 遍历的 for(int i = 0;i&lt;list.size();i++)&#123; System.out.println(list.get(i)); &#125; //使用迭代器 Iterator&lt;String&gt; it = list.iterator(); while(it.hasNext())&#123; String s = it.next(); System.out.println(s); &#125; //还可以使用增强for for (String string : list) &#123; System.out.println(string); &#125; &#125;&#125; 第三章 List的子类（实现类）3.1 ArrayList集合java.util.ArrayList集合数据存储的结构是数组结构。元素增删慢，查找快，由于日常开发中使用最多的功能为查询数据、遍历数据，所以ArrayList是最常用的集合。 许多程序员开发时非常随意地使用ArrayList完成任何需求，并不严谨，这种用法是不提倡的。 3.2 LinkedList集合java.util.LinkedList集合数据存储的结构是链表结构。查询慢，增删快，方便元素添加、删除的集合。 LinkedList是一个双向链表 实际开发中对一个集合元素的添加与删除经常涉及到首尾操作，而LinkedList提供了大量首尾操作的方法。这些方法作为了解即可： public void addFirst(E e):将指定元素插入此列表的开头。 public void addLast(E e):将指定元素添加到此列表的结尾。 public E getFirst():返回此列表的第一个元素。 public E getLast():返回此列表的最后一个元素。 public E removeFirst():移除并返回此列表的第一个元素。 public E removeLast():移除并返回此列表的最后一个元素。 public E pop():从此列表所表示的堆栈处弹出一个元素（等效于removeFirst） public void push(E e):将元素推入此列表所表示的堆栈。（等效于addFirst） public boolean isEmpty()：如果列表不包含元素，则返回true。 LinkedList是List的子类，List中的方法LinkedList都是可以使用，这里不做详细介绍，了解LinkedList的特有方法即可。在开发时，LinkedList集合也可以作为堆栈，队列的结构使用。（了解即可） 方法演示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class Demo02LinkedList &#123; public static void main(String[] args) &#123; show03(); &#125; private static void show03() &#123; //创建LinkedList集合对象 LinkedList&lt;String&gt; linked = new LinkedList&lt;&gt;(); //使用add方法往集合中添加元素 linked.add(\"a\"); linked.add(\"b\"); linked.add(\"c\"); System.out.println(linked);//[a, b, c] //String first = linked.removeFirst(); String first = linked.pop(); System.out.println(\"被移除的第一个元素:\"+first); String last = linked.removeLast(); System.out.println(\"被移除的最后一个元素:\"+last); System.out.println(linked);//[b] &#125; private static void show02() &#123; //创建LinkedList集合对象 LinkedList&lt;String&gt; linked = new LinkedList&lt;&gt;(); //使用add方法往集合中添加元素 linked.add(\"a\"); linked.add(\"b\"); linked.add(\"c\"); //linked.clear();//清空集合中的元素 在获取集合中的元素会抛出NoSuchElementException //public boolean isEmpty()：如果列表不包含元素，则返回true。 if(!linked.isEmpty())&#123; String first = linked.getFirst(); System.out.println(first);//a String last = linked.getLast(); System.out.println(last);//c &#125; &#125; private static void show01() &#123; //创建LinkedList集合对象 LinkedList&lt;String&gt; linked = new LinkedList&lt;&gt;(); //使用add方法往集合中添加元素 linked.add(\"a\"); linked.add(\"b\"); linked.add(\"c\"); System.out.println(linked);//[a, b, c] //public void addFirst(E e):将指定元素插入此列表的开头。 //linked.addFirst(\"www\"); linked.push(\"www\"); System.out.println(linked);//[www, a, b, c] //public void addLast(E e):将指定元素添加到此列表的结尾。此方法等效于 add() linked.addLast(\"com\"); System.out.println(linked);//[www, a, b, c, com] &#125;&#125; 第四章 Set接口java.util.Set接口和java.util.List接口一样，同样继承自Collection接口，它与Collection接口中的方法基本一致，和Collection一样没有索引，并没有对Collection接口进行功能上的扩充，只是比Collection接口更加严格了。 与List接口不同的是，Set接口中元素无序，并且都会以某种规则保证存入的元素不出现重复。 Set集合有多个子类，这里介绍其中的java.util.HashSet、java.util.LinkedHashSet这两个集合。 tips:Set集合取出元素的方式可以采用：迭代器、增强for。 4.1 HashSet集合介绍java.util.HashSet是Set接口的一个实现类 存储的元素是不可重复的 元素都是无序的(即存取顺序不一致)。 java.util.HashSet底层的实现其实是一个java.util.HashMap支持 HashSet是根据对象的哈希值来确定元素在集合中的存储位置，因此具有良好的存取和查找性能。保证元素唯一性的方式依赖于：hashCode与equals方法。 我们先来使用一下Set集合存储，看下现象，再进行原理的讲解: 1234567891011121314151617181920212223public class HashSetDemo &#123; public static void main(String[] args) &#123; //创建 Set集合 HashSet&lt;String&gt; set = new HashSet&lt;String&gt;(); //添加元素 set.add(new String(\"cba\")); set.add(\"abc\"); set.add(\"bac\"); set.add(\"cba\"); //使用迭代器遍历set集合 Iterator&lt;Integer&gt; it = set.iterator(); while (it.hasNext())&#123; Integer n = it.next(); System.out.println(n); &#125; //使用增强for遍历set集 for (String name : set) &#123; System.out.println(name); &#125; &#125;&#125; 输出结果如下，说明集合中不能存储重复元素，且无序： 123cbaabcbac 4.2 HashSet集合存储数据的结构（哈希表）哈希值哈希值是一个十进制的整数,由系统随机给出(就是对象的地址值,是一个逻辑地址,是模拟出来得到地址,不是数据实际存储的物理地址) 在Object类有一个方法,可以获取对象的哈希值： int hashCode() 返回该对象的哈希码值。 hashCode方法的源码:public native int hashCode();native:代表该方法调用的是本地操作系统的方法 1234567891011121314151617181920212223242526272829303132public class Demo01HashCode &#123; public static void main(String[] args) &#123; //Person类继承了Object类,所以可以使用Object类的hashCode方法 Person p1 = new Person(); int h1 = p1.hashCode(); System.out.println(h1);//1967205423 （十进制） Person p2 = new Person(); int h2 = p2.hashCode(); System.out.println(h2);//42121758 /* toString方法的源码: return getClass().getName() + \"@\" + Integer.toHexString(hashCode()); */ System.out.println(p1);//com.itheima.demo03.hashCode.Person@75412c2f（十六进制） System.out.println(p2);//com.itheima.demo03.hashCode.Person@282ba1e System.out.println(p1==p2);//false /* String类的哈希值 String类重写Obejct类的hashCode方法 */ String s1 = new String(\"abc\"); String s2 = new String(\"abc\"); System.out.println(s1.hashCode());//96354 System.out.println(s2.hashCode());//96354（字符串相同，纸相同） System.out.println(\"重地\".hashCode());//1179395 System.out.println(\"通话\".hashCode());//1179395（这两个是巧合） &#125;&#125; 哈希表在JDK1.8之前，哈希表底层采用数组+链表实现，即使用链表处理冲突，同一hash值的链表都存储在一个链表里。但是当位于一个桶中的元素较多，即hash值相等的元素较多时，通过key值依次查找的效率较低。 而JDK1.8中，哈希表存储采用数组+链表+红黑树实现，当链表长度超过阈值（8）时，将链表转换为红黑树，这样大大减少了查找时间。 哈希表是由数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的，如图所示 结合一个存储流程图理解： Set集合存储元素不重复的原理: JDK1.8引入红黑树大程度优化了HashMap的性能 保证HashSet集合元素的唯一，其实就是根据对象的hashCode和equals方法决定。如果我们往集合中存放自定义的对象，那么为保证其唯一，就必须复写hashCode和equals方法建立属于当前对象的比较方式。 4.3 HashSet存储自定义类型元素给HashSet中存放String、Integer等Java定义好的类时，这些类的特点是它们都重写了hashCode和equals方法，以保证元素不重复。 给HashSet中存放自定义类型元素时，需要重写自定义类中的hashCode和equals方法，建立自己的比较方式，才能保证HashSet集合中的对象唯一。否则创建的自定义类型元素，即使元素内容是一样的，它们的hashcode和地址值其实也是不一样的。 创建自定义Student类要求:同名同年龄的人,视为同一个人,只能存储一次 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Student &#123; private String name; private int age; public Student() &#123; &#125; public Student(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Student student = (Student) o; return age == student.age &amp;&amp; Objects.equals(name, student.name); &#125; @Override public int hashCode() &#123; return Objects.hash(name, age); &#125;&#125; tips:重写IDEA快捷键可以自动生成 123456789101112131415161718192021public class HashSetDemo2 &#123; public static void main(String[] args) &#123; //创建集合对象 该集合中存储 Student类型对象 HashSet&lt;Student&gt; stuSet = new HashSet&lt;Student&gt;(); //存储 Student stu = new Student(\"于谦\", 43); stuSet.add(stu); stuSet.add(new Student(\"郭德纲\", 44)); stuSet.add(new Student(\"于谦\", 43)); stuSet.add(new Student(\"郭麒麟\", 23)); stuSet.add(stu); for (Student stu2 : stuSet) &#123; System.out.println(stu2); &#125; &#125;&#125;执行结果：Student [name=郭德纲, age=44]Student [name=于谦, age=43]Student [name=郭麒麟, age=23] 4.4 LinkedHashSetHashSet保证元素唯一，但元素存放进去是没有顺序 在HashSet下面有一个子类java.util.LinkedHashSet，底层是一个哈希表(数组+链表/红黑树)+链表:多了一条链表(记录元素的存储顺序),保证元素有序。 演示代码如下: 123456789101112131415161718public class LinkedHashSetDemo &#123; public static void main(String[] args) &#123; Set&lt;String&gt; set = new LinkedHashSet&lt;String&gt;(); set.add(\"bbb\"); set.add(\"aaa\"); set.add(\"abc\"); set.add(\"bbc\"); Iterator&lt;String&gt; it = set.iterator(); while (it.hasNext()) &#123; System.out.println(it.next()); &#125; &#125;&#125;结果： bbb aaa abc bbc 结果有序 4.5 可变参数使用前提:当方法的参数列表数据类型已经确定,但是参数的个数不确定,就可以使用可变参数。 使用格式: 1修饰符 返回值类型 方法名(参数类型... 形参名)&#123; &#125; 其实这个书写完全等价与 1修饰符 返回值类型 方法名(参数类型[] 形参名)&#123; &#125; 只是后面这种定义，在调用时必须传递数组，而前者可以直接传递数据即可。 可变参数的原理:可变参数底层就是一个数组,根据传递参数个数不同,会创建不同长度的数组,来存储这些参数传递的参数个数,可以是0个(不传递),1,2…多个 代码演示： 1234567891011121314151617181920212223242526272829303132public class ChangeArgs &#123; public static void main(String[] args) &#123; // int[] arr = &#123; 1, 4, 62, 431, 2 &#125;; // int sum = getSum(arr); // System.out.println(sum); // 6 7 2 12 2121 // 求 这几个元素和 6 7 2 12 2121 int sum2 = getSum(6, 7, 2, 12, 2121); System.out.println(sum2); &#125; /* * 完成数组 所有元素的求和 原始写法 public static int getSum(int[] arr)&#123; int sum = 0; for(int a : arr)&#123; sum += a; &#125; return sum; &#125; */ //可变参数写法 public static int getSum(int... arr) &#123; int sum = 0; for (int a : arr) &#123; sum += a; &#125; return sum; &#125;&#125; 注意事项： 一个方法的参数列表,只能有一个可变参数 如果方法的参数有多个,那么可变参数必须写在参数列表的末尾 可变参数的特殊(终极)写法 1public static void method(Object...obj)&#123;&#125; 第五章 Collections5.1 常用功能 java.utils.Collections是集合工具类，用来对集合进行操作。部分方法如下： public static &lt;T&gt; boolean addAll(Collection&lt;T&gt; c, T... elements):往集合中添加多个元素。 public static void shuffle(List&lt;?&gt; list) 打乱顺序:打乱集合顺序。 public static &lt;T&gt; void sort(List&lt;T&gt; list):将集合中元素按照默认规则排序。 public static &lt;T&gt; void sort(List&lt;T&gt; list，Comparator&lt;? super T&gt; ):将集合中元素按照指定规则排序。 addall、sort（默认）代码演示： 12345678910111213141516171819public class CollectionsDemo &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); //原来写法 //list.add(12); //list.add(14); //list.add(15); //list.add(1000); //采用工具类 完成 往集合中添加元素 Collections.addAll(list, 5, 222, 1，2); System.out.println(list); //排序方法 Collections.sort(list); System.out.println(list); &#125;&#125;结果：[5, 222, 1, 2][1, 2, 5, 222] 5.2 Comparable接口public static &lt;T&gt; void sort(List&lt;T&gt; list):将集合中元素按照默认规则排序 当list中只是数字或者简单的字母字符串时，直接sort即可，就像上面的代码，但当list存储当不是integer、string等类型，比如存储的是自己定义的Person类时，默认排序规则将不管用，会编译报错。 此时仍使用sort(List&lt;T&gt; list)则需要：被排序的集合里边存储的元素,必须实现Comparable,重写接口中的方法compareTo定义排序的规则 Comparable接口的排序规则: 自己(this) - 参数 —&gt; 升序 参数 - 自己(this) —&gt; 降序 main代码： 1234567891011121314151617181920212223242526272829303132public class Demo02Sort &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; list01 = new ArrayList&lt;&gt;(); list01.add(1); list01.add(3); list01.add(2); System.out.println(list01);//[1, 3, 2] //public static &lt;T&gt; void sort(List&lt;T&gt; list):将集合中元素按照默认规则排序。 Collections.sort(list01);//默认是升序 System.out.println(list01);//[1, 2, 3] ArrayList&lt;String&gt; list02 = new ArrayList&lt;&gt;(); list02.add(\"a\"); list02.add(\"c\"); list02.add(\"b\"); System.out.println(list02);//[a, c, b] Collections.sort(list02); System.out.println(list02);//[a, b, c] ArrayList&lt;Person&gt; list03 = new ArrayList&lt;&gt;(); list03.add(new Person(\"张三\",18)); list03.add(new Person(\"李四\",20)); list03.add(new Person(\"王五\",15)); System.out.println(list03);//[Person&#123;name='张三', age=18&#125;, Person&#123;name='李四', age=20&#125;, Person&#123;name='王五', age=15&#125;] Collections.sort(list03); System.out.println(list03);//[Person&#123;name='李四', age=20&#125;, Person&#123;name='张三', age=18&#125;, Person&#123;name='王五', age=15&#125;] &#125;&#125; Person类 1234567891011121314151617181920212223public class Person implements Comparable&lt;Person&gt;&#123; private String name; private int age; //getter、setter、构造方法省略 @Override public String toString() &#123; return \"Person&#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + '&#125;'; &#125; //重写排序的规则 @Override public int compareTo(Person o) &#123; //return 0;//认为元素都是相同的 //自定义比较的规则,比较两个人的年龄(this,参数Person) //return this.getAge() - o.getAge();//年龄升序排序 return o.getAge() - this.getAge();//年龄降序排序 &#125;&#125; 5.3 Comparator比较器public static &lt;T&gt; void sort(List&lt;T&gt; list，Comparator&lt;? super T&gt; ):将集合中元素按照指定规则排序 public int compare(String o1, String o2)：比较其两个参数的顺序。 两个对象比较的结果有三种：大于，等于，小于。 如果要按照升序排序：o1-o2则o1 小于o2，返回（负数），相等返回0，01大于02返回（正数）如果要按照降序排序：o2-o1则o1 小于o2，返回（正数），相等返回0，01大于02返回（负数） Comparator和Comparable的区别: Comparable:自己(this)和别人(参数)比较,自己需要实现Comparable接口,重写比较的规则compareTo方法 Comparator:相当于找一个第三方的裁判,比较两个 Comparator的排序规则:&emsp;&emsp;&emsp;&emsp;o1-o2:升序 main代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Demo03Sort &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; list01 = new ArrayList&lt;&gt;(); list01.add(1); list01.add(3); list01.add(2); System.out.println(list01);//[1, 3, 2] Collections.sort(list01, new Comparator&lt;Integer&gt;() &#123; //重写比较的规则 @Override public int compare(Integer o1, Integer o2) &#123; //return o1-o2;//升序 return o2-o1;//降序 &#125; &#125;); System.out.println(list01);//[3, 2, 1] ArrayList&lt;Student&gt; list02 = new ArrayList&lt;&gt;(); list02.add(new Student(\"迪丽热巴\",18)); list02.add(new Student(\"古力娜扎\",20)); list02.add(new Student(\"杨幂\",17)); System.out.println(list02);//[Student&#123;name='迪丽热巴', age=18&#125;, Student&#123;name='古力娜扎', age=20&#125;, Student&#123;name='杨幂', age=17&#125;] Collections.sort(list02, new Comparator&lt;Student&gt;() &#123; @Override public int compare(Student o1, Student o2) &#123; //按照年龄升序排序 return o1.getAge()-o2.getAge(); &#125; &#125;); System.out.println(list02);//[Student&#123;name='杨幂', age=17&#125;, Student&#123;name='迪丽热巴', age=18&#125;, Student&#123;name='古力娜扎', age=20&#125;] //扩展:了解 //复合判断排序 ArrayList&lt;Student&gt; list03 = new ArrayList&lt;&gt;(); list02.add(new Student(\"a迪丽热巴\",18)); list02.add(new Student(\"古力娜扎\",20)); list02.add(new Student(\"杨幂\",17)); list02.add(new Student(\"b杨幂\",18)); System.out.println(list03);//[Student&#123;name='a迪丽热巴', age=18&#125;, Student&#123;name='古力娜扎', age=20&#125;, Student&#123;name='杨幂', age=17&#125;, Student&#123;name='b杨幂', age=18&#125;] Collections.sort(list03, new Comparator&lt;Student&gt;() &#123; @Override public int compare(Student o1, Student o2) &#123; //按照年龄升序排序 int result = o1.getAge()-o2.getAge(); //如果两个人年龄相同,再使用姓名的第一个字比较 if(result==0)&#123; result = o1.getName().charAt(0)-o2.getName().charAt(0); &#125; return result; &#125; &#125;); System.out.println(list03);//[Student&#123;name='杨幂', age=17&#125;, Student&#123;name='a迪丽热巴', age=18&#125;, Student&#123;name='b杨幂', age=18&#125;, Student&#123;name='古力娜扎', age=20&#125;] &#125;&#125; Student类： 12345678910111213public class Student &#123; private String name; private int age; //getter、setter、构造方法省略 @Override public String toString() &#123; return \"Student&#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + '&#125;'; &#125; 5.4 简述Comparable和Comparator两个接口的区别。Comparable：强行对实现它的每个类的对象进行整体排序。这种排序被称为类的自然排序，类的compareTo方法被称为它的自然比较方法。只能在类中实现compareTo()一次，不能经常修改类的代码实现自己想要的排序。实现此接口的对象列表（和数组）可以通过Collections.sort（和Arrays.sort）进行自动排序，对象可以用作有序映射中的键或有序集合中的元素，无需指定比较器。 Comparator强行对某个对象进行整体排序。可以将Comparator 传递给sort方法（如Collections.sort或 Arrays.sort），从而允许在排序顺序上实现精确控制。还可以使用Comparator来控制某些数据结构（如有序set或有序映射）的顺序，或者为那些没有自然顺序的对象collection提供排序。 第六章 Map集合现实生活中，我们常会看到这样的一种集合：IP地址与主机名，身份证号与个人，系统用户名与系统用户对象等，这种一一对应的关系，就叫做映射。Java提供了专门的集合类用来存放这种对象关系的对象，即java.util.Map接口。 Map接口下的集合与Collection接口下的集合，存储数据的形式不同，如图。 Collection中的集合，元素是孤立存在的（理解为单身），向集合中存储元素采用一个个元素的方式存储。 Map中的集合，元素是成对存在的(理解为夫妻)。每个元素由键与值两部分组成，通过键可以找对所对应的值。 Collection中的集合称为单列集合，Map中的集合称为双列集合。 需要注意的是，Map中的集合不能包含重复的键，值可以重复；每个键只能对应一个值。 6.1 Map常用子类Map有多个子类，常用的有HashMap集合、LinkedHashMap集合。 HashMap&lt;K,V&gt;：存储数据采用的哈希表结构，元素的存取顺序不能保证一致。由于要保证键的唯一、不重复，需要重写键的hashCode()方法、equals()方法。 LinkedHashMap&lt;K,V&gt;：HashMap下有个子类LinkedHashMap，存储数据采用的哈希表结构+链表结构。通过链表结构可以保证元素的存取顺序一致；通过哈希表结构可以保证的键的唯一、不重复，需要重写键的hashCode()方法、equals()方法。 tips：Map接口中的集合都有两个泛型变量&lt;K,V&gt;,在使用时，要为两个泛型变量赋予数据类型。两个泛型变量&lt;K,V&gt;的数据类型可以相同，也可以不同。 6.2 Map常用方法Map接口中定义了很多方法，常用的如下： public V put(K key, V value): 把指定的键与指定的值添加到Map集合中。 public V remove(Object key): 把指定的键 所对应的键值对元素 在Map集合中删除，返回被删除元素的值。 public V get(Object key) 根据指定的键，在Map集合中获取对应的值。 boolean containsKey(Object key) 判断集合中是否包含指定的键。 public Set&lt;K&gt; keySet(): 获取Map集合中所有的键，存储到Set集合中。 public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet(): 获取到Map集合中所有的键值对对象的集合(Set集合)。 Map接口的方法演示 1234567891011121314151617181920public class MapDemo &#123; public static void main(String[] args) &#123; //创建 map对象 HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); //添加元素到集合 map.put(\"黄晓明\", \"杨颖\"); map.put(\"文章\", \"马伊琍\"); map.put(\"邓超\", \"孙俪\"); System.out.println(map);//&#123;邓超=孙俪, 文章=马伊琍, 黄晓明=杨颖&#125; //String remove(String key) System.out.println(map.remove(\"邓超\"));//孙俪 System.out.println(map);//&#123;文章=马伊琍, 黄晓明=杨颖&#125; // 想要查看 黄晓明的媳妇 是谁 System.out.println(map.get(\"黄晓明\"));//杨颖 System.out.println(map.get(\"邓超\")); //null &#125;&#125; tips: 使用put方法时，若指定的键(key)在集合中没有，则没有这个键对应的值，返回null，并把指定的键值添加到集合中； 若指定的键(key)在集合中存在，则返回值为集合中键对应的值（该值为替换前的值），并把指定键所对应的值，替换成指定的新值。 6.3 遍历键找值键找值方式：即通过元素中的键，获取键所对应的值 分析步骤： 获取Map中所有的键，由于键是唯一的，所以返回一个Set集合存储所有的键。方法提示:keyset() 遍历键的Set集合，得到每一个键。 根据键，获取键所对应的值。方法提示:get(K key) 代码演示： 1234567891011121314151617181920public class MapDemo01 &#123; public static void main(String[] args) &#123; //创建Map集合对象 HashMap&lt;String, String&gt; map = new HashMap&lt;String,String&gt;(); //添加元素到集合 map.put(\"胡歌\", \"霍建华\"); map.put(\"郭德纲\", \"于谦\"); map.put(\"薛之谦\", \"大张伟\"); //获取所有的键 获取键集 Set&lt;String&gt; keys = map.keySet(); // 遍历键集 得到 每一个键 for (String key : keys) &#123; //key 就是键 //获取对应值 String value = map.get(key); System.out.println(key+\"的CP是：\"+value); &#125; &#125;&#125; 遍历图解： 6.4 Entry键值对对象我们已经知道，Map中存放的是两种对象，一种称为key(键)，一种称为value(值)，它们在Map中是一一对应关系，这一对对象又称做Map中的一个Entry(项)。 Entry将键值对的对应关系封装成了对象。即键值对对象，这样我们在遍历Map集合时，就可以从每一个键值对（Entry）对象中获取对应的键与对应的值。 既然Entry表示了一对键和值，那么也同样提供了获取对应键和对应值得方法： public K getKey()：获取Entry对象中的键。 public V getValue()：获取Entry对象中的值。 在Map集合中也提供了获取所有Entry对象的方法： public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet(): 获取到Map集合中所有的键值对对象的集合(Set集合)。 6.5 遍历键值对键值对方式：即通过集合中每个键值对(Entry)对象，获取键值对(Entry)对象中的键与值。 操作步骤与图解： 获取Map集合中，所有的键值对(Entry)对象，以Set集合形式返回。方法提示:entrySet()。 遍历包含键值对(Entry)对象的Set集合，得到每一个键值对(Entry)对象。 通过键值对(Entry)对象，获取Entry对象中的键与值。 方法提示:getkey() getValue() 123456789101112131415161718192021public class MapDemo02 &#123; public static void main(String[] args) &#123; // 创建Map集合对象 HashMap&lt;String, String&gt; map = new HashMap&lt;String,String&gt;(); // 添加元素到集合 map.put(\"胡歌\", \"霍建华\"); map.put(\"郭德纲\", \"于谦\"); map.put(\"薛之谦\", \"大张伟\"); // 获取 所有的 entry对象 entrySet Set&lt;Entry&lt;String,String&gt;&gt; entrySet = map.entrySet(); // 遍历得到每一个entry对象 for (Entry&lt;String, String&gt; entry : entrySet) &#123; // 解析 String key = entry.getKey(); String value = entry.getValue(); System.out.println(key+\"的CP是:\"+value); &#125; &#125;&#125; 遍历图解： tips：Map集合不能直接使用迭代器或者foreach进行遍历。但是转成Set之后就可以使用了。 6.6 HashMap存储自定义类型键值练习：每位学生（姓名，年龄）都有自己的家庭住址。将学生对象和家庭住址存储到map集合中。学生作为键, 家庭住址作为值。(学生姓名相同并且年龄相同视为同一名学生) 编写学生类： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Student &#123; private String name; private int age; public Student() &#123; &#125; public Student(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Student student = (Student) o; return age == student.age &amp;&amp; Objects.equals(name, student.name); &#125; @Override public int hashCode() &#123; return Objects.hash(name, age); &#125;&#125; 编写测试类： 12345678910111213141516171819public class HashMapTest &#123; public static void main(String[] args) &#123; //1,创建Hashmap集合对象。 Map&lt;Student,String&gt;map = new HashMap&lt;Student,String&gt;(); //2,添加元素。 map.put(newStudent(\"lisi\",28), \"上海\"); map.put(newStudent(\"wangwu\",22), \"北京\"); map.put(newStudent(\"zhaoliu\",24), \"成都\"); map.put(newStudent(\"zhouqi\",25), \"广州\"); map.put(newStudent(\"wangwu\",22), \"南京\"); //3,取出元素。键找值方式 Set&lt;Student&gt; keySet = map.keySet(); for(Student key: keySet)&#123; Stringvalue = map.get(key); System.out.println(key.toString()+\".....\"+value); &#125; &#125;&#125; 当给HashMap中存放自定义对象时，如果自定义对象作为key存在，这时要保证对象唯一，必须重写对象的hashCode和equals方法(如果忘记，请回顾HashSet存放自定义对象)。 如果要保证map中存放的key和取出的顺序一致，可以使用java.util.LinkedHashMap集合来存放。 6.7 LinkedHashMap我们知道HashMap保证成对元素唯一，并且查询速度很快，可是成对元素存放进去是没有顺序的，那么我们要保证有序，还要速度快怎么办呢？ 在HashMap下面有一个子类LinkedHashMap，它是链表和哈希表组合的一个数据存储结构。 123456789101112public class LinkedHashMapDemo &#123; public static void main(String[] args) &#123; LinkedHashMap&lt;String, String&gt; map = new LinkedHashMap&lt;String, String&gt;(); map.put(\"邓超\", \"孙俪\"); map.put(\"李晨\", \"范冰冰\"); map.put(\"刘德华\", \"朱丽倩\"); Set&lt;Entry&lt;String, String&gt;&gt; entrySet = map.entrySet(); for (Entry&lt;String, String&gt; entry : entrySet) &#123; System.out.println(entry.getKey() + \" \" + entry.getValue()); &#125; &#125;&#125; 结果: 123邓超 孙俪李晨 范冰冰刘德华 朱丽倩 6.8 Map集合练习需求： 计算一个字符串中每个字符出现次数。 分析： 使用Scanner获取用户输入的字符串 创建Map集合,key是字符串中的字符,value是字符的个数 遍历字符串,获取每一个字符 使用获取到的字符,去Map集合判断key是否存在&emsp;&emsp;key存在:&emsp;&emsp;&emsp;&emsp;通过字符(key),获取value(字符个数)&emsp;&emsp;&emsp;&emsp;value++&emsp;&emsp;&emsp;&emsp;put(key,value)把新的value存储到Map集合中&emsp;&emsp;key不存在:&emsp;&emsp;&emsp;&emsp;put(key,1) 遍历Map集合,输出结果 代码： 123456789101112131415161718192021222324252627282930313233public class Demo03MapTest &#123; public static void main(String[] args) &#123; //1.使用Scanner获取用户输入的字符串 Scanner sc = new Scanner(System.in); System.out.println(\"请输入一个字符串:\"); String str = sc.next(); //2.创建Map集合,key是字符串中的字符,value是字符的个数 HashMap&lt;Character,Integer&gt; map = new HashMap&lt;&gt;(); //3.遍历字符串,获取每一个字符 for(char c :str.toCharArray())&#123; //4.使用获取到的字符,去Map集合判断key是否存在 if(map.containsKey(c))&#123; //key存在 Integer value = map.get(c); value++; map.put(c,value); &#125;else&#123; //key不存在 map.put(c,1); &#125; &#125; //5.遍历Map集合,输出结果 for(Character key :map.keySet())&#123; Integer value = map.get(key); System.out.println(key+\"=\"+value); &#125; &#125;&#125; 第七章 List、Set、Map综合7.1 JDK9对集合添加的优化通常，我们在代码中创建一个集合（例如，List 或 Set ），并直接用一些元素填充它。 实例化集合，几个 add方法 调用，使得代码重复。 123456789public class Demo01 &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"abc\"); list.add(\"def\"); list.add(\"ghi\"); System.out.println(list); &#125;&#125; Java 9，添加了几种集合工厂方法,更方便创建少量元素的集合、map实例。新的List、Set、Map的静态工厂方法可以更方便地创建集合的不可变实例。 例子： 1234567891011public class HelloJDK9 &#123; public static void main(String[] args) &#123; Set&lt;String&gt; str1=Set.of(\"a\",\"b\",\"c\"); //str1.add(\"c\");这里编译的时候不会错，但是执行的时候会报错，因为是不可变的集合 System.out.println(str1); Map&lt;String,Integer&gt; str2=Map.of(\"a\",1,\"b\",2); System.out.println(str2); List&lt;String&gt; str3=List.of(\"a\",\"b\"); System.out.println(str3); &#125; &#125; 需要注意以下两点： 1:of()方法只是Map，List，Set这三个接口的静态方法，其父类接口和子类实现并没有这类方法，比如HashSet，ArrayList等； 2:返回的集合是不可变的； 7.2 模拟斗地主洗牌发牌案例介绍按照斗地主的规则，完成洗牌发牌的动作。 具体规则： 组装54张扑克牌将 54张牌顺序打乱 三个玩家参与游戏，三人交替摸牌，每人17张牌，最后三张留作底牌。 查看三人各自手中的牌（按照牌的大小排序）、底牌 规则：手中扑克牌从大到小的摆放顺序：大王,小王,2,A,K,Q,J,10,9,8,7,6,5,4,3 案例需求分析 准备牌： 完成数字与纸牌的映射关系： 使用双列Map(HashMap)集合，完成一个数字与字符串纸牌的对应关系(相当于一个字典)。 洗牌： 通过数字完成洗牌发牌 发牌： 将每个人以及底牌设计为ArrayList,将最后3张牌直接存放于底牌，剩余牌通过对3取模依次发牌。 存放的过程中要求数字大小与斗地主规则的大小对应。 将代表不同纸牌的数字分配给不同的玩家与底牌。 看牌： 通过Map集合找到对应字符展示。 通过查询纸牌与数字的对应关系，由数字转成纸牌字符串再进行展示。 实现代码步骤123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class Poker &#123; public static void main(String[] args) &#123; /* * 1组装54张扑克牌 */ // 1.1 创建Map集合存储 HashMap&lt;Integer, String&gt; pokerMap = new HashMap&lt;Integer, String&gt;(); // 1.2 创建 花色集合 与 数字集合 ArrayList&lt;String&gt; colors = new ArrayList&lt;String&gt;(); ArrayList&lt;String&gt; numbers = new ArrayList&lt;String&gt;(); // 1.3 存储 花色 与数字 Collections.addAll(colors, \"♦\", \"♣\", \"♥\", \"♠\"); Collections.addAll(numbers, \"2\", \"A\", \"K\", \"Q\", \"J\", \"10\", \"9\", \"8\", \"7\", \"6\", \"5\", \"4\", \"3\"); // 设置 存储编号变量 int count = 1; pokerMap.put(count++, \"大王\"); pokerMap.put(count++, \"小王\"); // 1.4 创建牌 存储到map集合中 for (String number : numbers) &#123; for (String color : colors) &#123; String card = color + number; pokerMap.put(count++, card); &#125; &#125; /* * 2 将54张牌顺序打乱 */ // 取出编号 到Set集合 Set&lt;Integer&gt; numberSet = pokerMap.keySet(); // set无序、list有序 // 因为要将编号打乱顺序 所以 应该先进行转换到 list集合中 ArrayList&lt;Integer&gt; numberList = new ArrayList&lt;Integer&gt;(); numberList.addAll(numberSet); // 打乱顺序 Collections.shuffle(numberList); // 3 完成三个玩家交替摸牌，每人17张牌，最后三张留作底牌 // 3.1 发牌的编号 // 创建三个玩家编号集合 和一个 底牌编号集合 ArrayList&lt;Integer&gt; noP1 = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Integer&gt; noP2 = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Integer&gt; noP3 = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Integer&gt; dipaiNo = new ArrayList&lt;Integer&gt;(); // 3.2发牌的编号 for (int i = 0; i &lt; numberList.size(); i++) &#123; // 获取该编号 Integer no = numberList.get(i); // 发牌 // 留出底牌 if (i &gt;= 51) &#123; dipaiNo.add(no); &#125; else &#123; if (i % 3 == 0) &#123; noP1.add(no); &#125; else if (i % 3 == 1) &#123; noP2.add(no); &#125; else &#123; noP3.add(no); &#125; &#125; &#125; // 4 查看三人各自手中的牌（按照牌的大小排序）、底牌 // 4.1 对手中编号进行排序 Collections.sort(noP1); Collections.sort(noP2); Collections.sort(noP3); Collections.sort(dipaiNo); // 4.2 进行牌面的转换 // 创建三个玩家牌面集合 以及底牌牌面集合 ArrayList&lt;String&gt; player1 = new ArrayList&lt;String&gt;(); ArrayList&lt;String&gt; player2 = new ArrayList&lt;String&gt;(); ArrayList&lt;String&gt; player3 = new ArrayList&lt;String&gt;(); ArrayList&lt;String&gt; dipai = new ArrayList&lt;String&gt;(); // 4.3转换 for (Integer i : noP1) &#123; // 4.4 根据编号找到 牌面 pokerMap String card = pokerMap.get(i); // 添加到对应的 牌面集合中 player1.add(card); &#125; for (Integer i : noP2) &#123; String card = pokerMap.get(i); player2.add(card); &#125; for (Integer i : noP3) &#123; String card = pokerMap.get(i); player3.add(card); &#125; for (Integer i : dipaiNo) &#123; String card = pokerMap.get(i); dipai.add(card); &#125; //4.5 查看 System.out.println(\"令狐冲：\"+player1); System.out.println(\"石破天：\"+player2); System.out.println(\"鸠摩智：\"+player3); System.out.println(\"底牌：\"+dipai); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://mangosTeeN96.github.io/categories/java/"}],"tags":[]},{"title":"Java_Collection集合、泛型","slug":"Java_Collection集合、泛型","date":"2019-05-19T05:31:45.000Z","updated":"2020-08-04T07:48:30.519Z","comments":true,"path":"2019/05/19/Java_Collection集合、泛型/","link":"","permalink":"http://mangosTeeN96.github.io/2019/05/19/Java_Collection集合、泛型/","excerpt":"","text":"第一章 Collection集合前面使用过集合ArrayList 集合：集合是java中提供的一种容器，可以用来存储多个数据。 集合和数组都是容器，它们的区别： 数组的长度是固定的。集合的长度是可变的。 数组中存储的是同一类型的元素，可以存储基本数据类型值。集合存储的都是对象。而且对象的类型可以不一致。在开发中一般当对象多的时候，使用集合进行存储。 JAVASE提供了满足各种需求的API，在使用这些API前，先了解其继承与接口操作架构，才能了解何时采用哪个类，以及类之间如何彼此合作，从而达到灵活应用。 集合按照其存储结构可以分为两大类，分别是单列集合java.util.Collection和双列集合java.util.Map 1.1 集合框架Collection： 单列集合类的根接口，用于存储一系列符合某种规则的元素。它有两个重要的子接口，分别是java.util.List和java.util.Set。 List的特点是元素有序、元素可重复。List接口的主要实现类有java.util.ArrayList和java.util.LinkedList。 Set的特点是元素无序，而且不可重复。Set接口的主要实现类有java.util.HashSet和java.util.TreeSet。 从上面的描述可以看出JDK中提供了丰富的集合类库，为了便于初学者进行系统地学习，接下来通过一张图来描述整个集合类的继承体系。 集合本身是一个工具，它存放在java.util包中。在Collection接口定义着单列集合框架中最最共性的内容。 1.2 Collection 常用功能Collection是所有单列集合的父接口，因此在Collection中定义了单列集合(List和Set)通用的一些方法，这些方法可用于操作所有的单列集合。方法如下： public boolean add(E e)： 把给定的对象添加到当前集合中 。 public void clear() :清空集合中所有的元素。 public boolean remove(E e): 把给定的对象在当前集合中删除。 public boolean contains(E e): 判断当前集合中是否包含给定的对象。 public boolean isEmpty(): 判断当前集合是否为空。 public int size(): 返回集合中元素的个数。 public Object[] toArray(): 把集合中的元素，存储到数组中。 方法演示： 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.ArrayList;import java.util.Collection;public class Demo1Collection &#123; public static void main(String[] args) &#123; // 创建集合对象 // 使用多态形式，接口指向实现类 Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); //打印coll为[]，重写了toString方法 // 使用方法 // 添加功能 boolean add(String s) coll.add(\"小李广\"); coll.add(\"扫地僧\"); coll.add(\"石破天\"); //无需接受返回值，返回值一般为true System.out.println(coll); // boolean contains(E e) 判断o是否在集合中存在 System.out.println(\"判断 扫地僧 是否在集合中\"+coll.contains(\"扫地僧\")); //boolean remove(E e) 删除在集合中的o元素 System.out.println(\"删除石破天：\"+coll.remove(\"石破天\")); System.out.println(\"操作之后集合中元素:\"+coll); // size() 集合中有几个元素 System.out.println(\"集合中有\"+coll.size()+\"个元素\"); // Object[] toArray()转换成一个Object数组 Object[] objects = coll.toArray(); // 遍历数组 for (int i = 0; i &lt; objects.length; i++) &#123; System.out.println(objects[i]); &#125; // void clear() 清空集合 coll.clear(); System.out.println(\"集合中内容为：\"+coll); // boolean isEmpty() 判断是否为空 System.out.println(coll.isEmpty()); &#125;&#125; tips: 有关Collection中的方法可不止上面这些，其他方法可以自行查看API学习。 第二章 Iterator迭代器2.1 Iterator接口在程序开发中，经常需要遍历集合中的所有元素。针对这种需求，JDK专门提供了一个接口java.util.Iterator。 Iterator接口也是Java集合中的一员，但它与Collection、Map接口有所不同，Collection接口与Map接口主要用于存储元素，而Iterator主要用于迭代访问（即遍历）Collection中的元素，因此Iterator对象也被称为迭代器。 迭代： 即Collection集合元素的通用获取方式。在取元素之前先要判断集合中有没有元素，如果有，就把这个元素取出来，继续在判断，如果还有就再取出出来。一直把集合中的所有元素全部取出。这种取出方式专业术语称为迭代。 获取迭代器： public Iterator iterator(): 获取集合对应的迭代器，用来遍历集合中的元素的。 Iterator接口的常用方法： public E next():返回迭代的下一个元素。 public boolean hasNext():如果仍有元素可以迭代，则返回 true。 迭代器的使用步骤(重点): 使用集合中的方法iterator()获取迭代器的实现类对象,使用Iterator接口接收(多态) 使用Iterator接口中的方法hasNext判断还有没有下一个元素 使用Iterator接口中的方法next取出集合中的下一个元素 12345678910111213141516171819public class IteratorDemo &#123; public static void main(String[] args) &#123; // 使用多态方式 创建对象 Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); // 添加元素到集合 coll.add(\"串串星人\"); coll.add(\"吐槽星人\"); coll.add(\"汪星人\"); //遍历 //使用迭代器 遍历 每个集合对象都有自己的迭代器 Iterator&lt;String&gt; it = coll.iterator(); // 泛型指的是 迭代出 元素的数据类型 while(it.hasNext())&#123; //判断是否有迭代元素 String s = it.next();//获取迭代出的元素 System.out.println(s); &#125; &#125;&#125; tips:：在进行集合元素取出时，如果集合中已经没有元素了，还继续使用迭代器的next方法，将会发生java.util.NoSuchElementException没有集合元素的错误。 迭代器的实现原理 Iterator迭代器对象在遍历集合时，内部采用指针的方式来跟踪集合中的元素，为了让初学者能更好地理解迭代器的工作原理，接下来通过一个图例来演示Iterator对象迭代元素的过程： 在调用Iterator的next方法之前，迭代器的索引位于第一个元素之前，不指向任何元素，当第一次调用迭代器的next方法后，迭代器的索引会向后移动一位，指向第一个元素并将该元素返回，当再次调用next方法时，迭代器的索引会指向第二个元素并将该元素返回，依此类推，直到hasNext方法返回false，表示到达了集合的末尾，终止对元素的遍历。 2.2 增强for增强for循环(也称for each循环)是JDK1.5以后出来的一个高级for循环，专门用来遍历数组和集合的。它的内部原理其实是个Iterator迭代器，所以在遍历的过程中，不能对集合中的元素进行增删操作。 格式： 123for(元素的数据类型 变量 : Collection集合or数组)&#123; //写操作代码&#125; 它用于遍历Collection和数组。通常只进行遍历元素，不要在遍历的过程中对集合元素进行增删操作。 练习1：遍历数组123456789public class NBForDemo1 &#123; public static void main(String[] args) &#123; int[] arr = &#123;3,5,6,87&#125;; //使用增强for遍历数组 for(int a : arr)&#123;//a代表数组中的每个元素 System.out.println(a); &#125; &#125;&#125; 练习2:遍历集合123456789101112public class NBFor &#123; public static void main(String[] args) &#123; Collection&lt;String&gt; coll = new ArrayList&lt;String&gt;(); coll.add(\"小河神\"); coll.add(\"老河神\"); coll.add(\"神婆\"); //使用增强for遍历 for(String s :coll)&#123;//接收变量s代表 代表被遍历到的集合元素 System.out.println(s); &#125; &#125;&#125; tips: 新for循环必须有被遍历的目标。目标只能是Collection或者是数组。新式for仅仅作为遍历操作出现。 第三章 泛型3.1 泛型概述集合中可以存放任意对象，只要把对象存储集合后，他们都会被提升成Object类型。当我们取出每一个对象，并且进行相应的操作时，必须采用类型转换。 创建集合对象,不使用泛型 好处:集合不使用泛型,默认的类型就是Object类型,可以存储任意类型的数据 弊端:不安全,会引发异常 12345678910111213141516171819202122 private static void show01() &#123; ArrayList list = new ArrayList(); list.add(\"abc\"); list.add(1); //使用迭代器遍历list集合 //获取迭代器 Iterator it = list.iterator(); //使用迭代器中的方法hasNext和next遍历集合 while(it.hasNext())&#123; //取出元素也是Object类型 Object obj = it.next(); System.out.println(obj); //想要使用String类特有的方法,length获取字符串的长度;不能使用 多态 Object obj = \"abc\"; //需要向下转型 //会抛出ClassCastException类型转换异常,不能把Integer类型转换为String类型 String s = (String)obj; System.out.println(s.length()); &#125; &#125;&#125; 程序在运行时发生了问题java.lang.ClassCastException。 由于集合中什么类型的元素都可以存储。导致取出时强转引发运行时ClassCastException。Collection虽然可以存储各种对象，但实际上通常Collection只存储同一类型对象。例如都是存储字符串对象。因此在JDK5之后，新增了泛型(Generic)语法，让你在设计API时可以指定类或方法支持泛型，这样我们使用API的时候也变得更为简洁，并得到了编译时期的语法检查。 泛型：可以在类或方法中预支地使用未知的类型。 tips:一般在创建对象时，将未知的类型确定具体的类型。当没有指定泛型时，默认类型为Object类型。 3.2 使用泛型的好处 创建集合对象,使用泛型 好处: 1.避免了类型转换的麻烦,存储的是什么类型,取出的就是什么类型2.把运行期异常(代码运行之后会抛出的异常),提升到了编译期(写代码的时候会报错) 弊端:泛型是什么类型,只能存储什么类型的数 1234567891011121314151617public class GenericDemo2 &#123; public static void main(String[] args) &#123; Collection&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(\"abc\"); list.add(\"itcast\"); // list.add(5);//当集合明确类型后，存放类型不一致就会编译报错 // 集合已经明确具体存放的元素类型，那么在使用迭代器的时候，迭代器也同样会知道具体遍历元素类型 Iterator&lt;String&gt; it = list.iterator(); while(it.hasNext())&#123; String str = it.next(); //当使用Iterator&lt;String&gt;控制元素类型后，就不需要强转了。获取到的元素直接就是String类型 System.out.println(str.length()); &#125; &#125;&#125; tips:泛型是数据类型的一部分，我们将类名与泛型合并一起看做数据类型。 3.3 泛型的定义与使用在集合中会大量使用到泛型 泛型，用来灵活地将数据类型应用到不同的类、方法、接口当中。将数据类型作为参数进行传递。 含有泛型的类定义格式： 1修饰符 class 类名&lt;代表泛型的变量&gt; &#123; &#125; 例如，API中的ArrayList集合： 123456class ArrayList&lt;E&gt;&#123; public boolean add(E e)&#123; &#125; public E get(int index)&#123; &#125; ....&#125; 使用泛型： 即什么时候确定泛型的数据类型 在创建对象的时候确定泛型的数据类型 例如，ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); 此时，变量E的值就是String类型,那么我们的类型就可以理解为： 123456class ArrayList&lt;String&gt;&#123; public boolean add(String e)&#123; &#125; public String get(int index)&#123; &#125; ...&#125; 自定义泛型类： 定义： 123456789101112public class MyGenericClass&lt;MVP&gt; &#123; //没有MVP类型，在这里代表 未知的一种数据类型 未来传递什么就是什么类型 private MVP mvp; public void setMVP(MVP mvp) &#123; this.mvp = mvp; &#125; public MVP getMVP() &#123; return mvp; &#125;&#125; 使用: 123456789101112131415public class GenericClassDemo &#123; public static void main(String[] args) &#123; // 创建一个泛型为String的类 MyGenericClass&lt;String&gt; my = new MyGenericClass&lt;String&gt;(); // 调用setMVP my.setMVP(\"大胡子登登\"); // 调用getMVP String mvp = my.getMVP(); System.out.println(mvp); //创建一个泛型为Integer的类 MyGenericClass&lt;Integer&gt; my2 = new MyGenericClass&lt;Integer&gt;(); my2.setMVP(123); Integer mvp2 = my2.getMVP(); &#125;&#125; 含有泛型的方法定义格式： 1修饰符 &lt;代表泛型的变量&gt; 返回值类型 方法名(参数)&#123; &#125; 例如， 1234567891011public class GenericMethod &#123; //定义一个含有泛型的方法 public &lt;M&gt; void method01(M m)&#123; System.out.println(m); &#125; //定义一个含有泛型的静态方法 public static &lt;S&gt; void method02(S s)&#123; System.out.println(s); &#125;&#125; 使用格式：调用方法时，确定泛型的类型 123456789101112131415161718192021public class Demo03GenericMethod &#123; public static void main(String[] args) &#123; //创建GenericMethod对象 GenericMethod gm = new GenericMethod(); /* 调用含有泛型的方法method01 传递什么类型,泛型就是什么类型 */ gm.method01(10); gm.method01(\"abc\"); gm.method01(8.8); gm.method01(true); gm.method02(\"静态方法,不建议创建对象使用\"); //静态方法,通过类名.方法名(参数)可以直接使用 GenericMethod.method02(\"静态方法\"); GenericMethod.method02(1); &#125;&#125; 含有泛型的接口定义格式： 1修饰符 interface接口名&lt;代表泛型的变量&gt; &#123; &#125; 例如， 12345public interface MyGenericInterface&lt;E&gt;&#123; public abstract void add(E e); public abstract E getE(); &#125; 使用格式： 定义类时确定泛型的类型 定义接口的实现类,实现接口,指定接口的泛型 实现类： 1234567891011public class MyImp1 implements MyGenericInterface&lt;String&gt; &#123; @Override public void add(String e) &#123; // 省略... &#125; @Override public String getE() &#123; return null; &#125;&#125; 此时，泛型E的值就是String类型，然后main程序按照string正常使用。 始终不确定泛型的类型，直到创建对象时，确定泛型的类型 接口使用什么泛型,实现类就使用什么泛型,类跟着接口走就相当于定义了一个含有泛型的类,创建对象的时候确定泛型的类型 实现类： 1234567891011public class MyImp2&lt;E&gt; implements MyGenericInterface&lt;E&gt; &#123; @Override public void add(E e) &#123; // 省略... &#125; @Override public E getE() &#123; return null; &#125;&#125; main，创建对象，确定泛型： 123456789/* * 使用 */public class GenericInterface &#123; public static void main(String[] args) &#123; MyImp2&lt;String&gt; my = new MyImp2&lt;String&gt;(); my.add(\"aa\"); &#125;&#125; 3.4 泛型通配符当使用泛型类或者接口时，传递的数据中，泛型类型不确定，可以通过通配符&lt;?&gt;表示。但是一旦使用泛型的通配符后，只能使用Object类中的共性方法，集合中元素自身方法无法使用。 通配符基本使用泛型的通配符：不知道使用什么类型来接收的时候,此时可以使用?,?表示未知通配符。 此时只能接受数据,不能往该集合中存储数据。 举例理解使用即可： 1234567891011121314151617public static void main(String[] args) &#123; Collection&lt;Intger&gt; list1 = new ArrayList&lt;Integer&gt;(); Collection&lt;String&gt; list2 = new ArrayList&lt;String&gt;(); getElement(list1); getElement(list2);&#125;public static void getElement((ArrayList&lt;?&gt; list)&#123; //使用迭代器遍历集合 Iterator&lt;?&gt; it = list.iterator(); while(it.hasNext())&#123; //it.next()方法,取出的元素是Object,可以接收任意的数据类型 Object o = it.next(); System.out.println(o); &#125;&#125;//？代表可以接收任意类型 tips:泛型不存在继承关系 Collection list = new ArrayList();这种是错误的。 通配符高级使用—受限泛型之前设置泛型的时候，实际上是可以任意设置的，只要是类就可以设置。但是在JAVA的泛型中可以指定一个泛型的上限和下限。 泛型的上限： 格式： 类型名称 &lt;? extends 类 &gt; 对象名称 意义： 只能接收该类型及其子类 泛型的下限： 格式： 类型名称 &lt;? super 类 &gt; 对象名称 意义： 只能接收该类型及其父类型 比如：现已知Object类，String 类，Number类，Integer类其中类与类之间的继承关系:Integer extends Number extends ObjectString extends Objec 123456789101112131415161718192021public static void main(String[] args) &#123; Collection&lt;Integer&gt; list1 = new ArrayList&lt;Integer&gt;(); Collection&lt;String&gt; list2 = new ArrayList&lt;String&gt;(); Collection&lt;Number&gt; list3 = new ArrayList&lt;Number&gt;(); Collection&lt;Object&gt; list4 = new ArrayList&lt;Object&gt;(); getElement(list1); getElement(list2);//报错 getElement(list3); getElement(list4);//报错 getElement2(list1);//报错 getElement2(list2);//报错 getElement2(list3); getElement2(list4); &#125;// 泛型的上限：此时的泛型?，必须是Number类型或者Number类型的子类public static void getElement1(Collection&lt;? extends Number&gt; coll)&#123;&#125;// 泛型的下限：此时的泛型?，必须是Number类型或者Number类型的父类public static void getElement2(Collection&lt;? super Number&gt; coll)&#123;&#125; 第四章 集合综合案例4.1 案例介绍按照斗地主的规则，完成洗牌发牌的动作。具体规则： 使用54张牌打乱顺序,三个玩家参与游戏，三人交替摸牌，每人17张牌，最后三张留作底牌。 4.2 案例分析 准备牌： 牌可以设计为一个ArrayList,每个字符串为一张牌。每张牌由花色数字两部分组成，我们可以使用花色集合与数字集合嵌套迭代完成每张牌的组装。牌由Collections类的shuffle方法进行随机排序。 发牌 将每个人以及底牌设计为ArrayList,将最后3张牌直接存放于底牌，剩余牌通过对3取模依次发牌。 看牌 直接打印每个集合。 4.3 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.itheima.demo04.Test;import java.util.ArrayList;import java.util.Collections;/* 斗地主综合案例: 1.准备牌 2.洗牌 3.发牌 4.看牌 */public class DouDiZhu &#123; public static void main(String[] args) &#123; //1.准备牌 //定义一个存储54张牌的ArrayList集合,泛型使用String ArrayList&lt;String&gt; poker = new ArrayList&lt;&gt;(); //定义两个数组,一个数组存储牌的花色,一个数组存储牌的序号 String[] colors = &#123;\"♠\",\"♥\",\"♣\",\"♦\"&#125;; String[] numbers = &#123;\"2\",\"A\",\"K\",\"Q\",\"J\",\"10\",\"9\",\"8\",\"7\",\"6\",\"5\",\"4\",\"3\"&#125;; //先把大王和小王存储到poker集合中 poker.add(\"大王\"); poker.add(\"小王\"); //循环嵌套遍历两个数组,组装52张牌 for(String number : numbers)&#123; for (String color : colors) &#123; //System.out.println(color+number); //把组装好的牌存储到poker集合中 poker.add(color+number); &#125; &#125; //System.out.println(poker); /* 2.洗牌 使用集合的工具类Collections中的方法 static void shuffle(List&lt;?&gt; list) 使用默认随机源对指定列表进行置换。 */ Collections.shuffle(poker); //System.out.println(poker); /* 3.发牌 */ //定义4个集合,存储玩家的牌和底牌 ArrayList&lt;String&gt; player01 = new ArrayList&lt;&gt;(); ArrayList&lt;String&gt; player02 = new ArrayList&lt;&gt;(); ArrayList&lt;String&gt; player03 = new ArrayList&lt;&gt;(); ArrayList&lt;String&gt; diPai = new ArrayList&lt;&gt;(); /* 遍历poker集合,获取每一张牌 使用poker集合的索引%3给3个玩家轮流发牌 剩余3张牌给底牌 注意: 先判断底牌(i&gt;=51),否则牌就发没了 */ for (int i = 0; i &lt; poker.size() ; i++) &#123; //获取每一张牌 String p = poker.get(i); //轮流发牌 if(i&gt;=51)&#123; //给底牌发牌 diPai.add(p); &#125;else if(i%3==0)&#123; //给玩家1发牌 player01.add(p); &#125;else if(i%3==1)&#123; //给玩家2发牌 player02.add(p); &#125;else if(i%3==2)&#123; //给玩家3发牌 player03.add(p); &#125; &#125; //4.看牌 System.out.println(\"刘德华:\"+player01); System.out.println(\"周润发:\"+player02); System.out.println(\"周星驰:\"+player03); System.out.println(\"底牌:\"+diPai); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://mangosTeeN96.github.io/categories/java/"}],"tags":[]},{"title":"Java_Object类、常用API","slug":"Java_Object类、常用API","date":"2019-05-16T22:00:06.000Z","updated":"2020-08-04T07:48:44.576Z","comments":true,"path":"2019/05/17/Java_Object类、常用API/","link":"","permalink":"http://mangosTeeN96.github.io/2019/05/17/Java_Object类、常用API/","excerpt":"","text":"API: API(Application Programming Interface)，应用程序编程接口Java API是一本程序员的字典是我们使用的类的说明文档 API帮助文档（中文版）：JDK_API_1_6_zh_CN.CHM 引用类: 一般步骤： 导包 import 包路径.类名称; 如果需要使用的目标类，和当前类位于同一个包下，则可以省略导包语句不写。只有java.lang包下的内容不需要导包（比如String），其他的包都需要import语句。 创建 类名称 对象名 = new 类名称(); 使用 对象名.成员方法名() 一、 Scanner类功能： 可以实现键盘输入数据，到程序当中 使用方法： 查看类 java.util.Scanner :该类需要import导入后使用。 查看构造方法 public Scanner(InputStream source) : 构造一个新的 Scanner ，它生成的值是从指定的输入流扫描的。 查看成员方法 public int nextInt() :将输入信息的下一个标记扫描为一个 int 值。 还有很多，比如next（），String值 使用Scanner类，完成接收键盘录入数据的操作，代码如下: 12345678910111213141516171819import java.util.Scanner;public class Demo01Scanner &#123; public static void main(String[] args) &#123; // 2. 创建 // 备注：System.in代表从键盘进行输入 Scanner sc = new Scanner(System.in); // 3. 获取键盘输入的int数字 int num = sc.nextInt(); System.out.println(\"输入的int数字是：\" + num); // 4. 获取键盘输入的字符串 String str = sc.next(); System.out.println(\"输入的字符串是：\" + str); &#125;&#125; 练习题： 键盘输入三个int数字，然后求出其中的最大值 123456789101112131415161718192021import java.util.Scanner;public class Demo03ScannerMax &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); System.out.println(\"请输入第一个数字：\"); int a = sc.nextInt(); System.out.println(\"请输入第二个数字：\"); int b = sc.nextInt(); System.out.println(\"请输入第三个数字：\"); int c = sc.nextInt(); // 首先得到前两个数字当中的最大值 int temp = a &gt; b ? a : b; int max = temp &gt; c ? temp : c; System.out.println(\"最大值是：\" + max); &#125;&#125; 二、匿名对象匿名对象：没有变量名的对象 格式: new 类名(参数列表); 应用场景: 创建匿名对象直接调用方法，没有变量名 匿名对象只能使用唯一的一次，下次再用不得不再创建一个新对象。一旦调用两次方法，就是创建了两个对象，造成浪费 匿名对象可以作为方法的参数和返回值 作为参数 1234567891011121314class Test &#123; public static void main(String[] args) &#123; // 普通方式 Scanner sc = new Scanner(System.in); input(sc); //匿名对象作为方法接收的参数 input(new Scanner(System.in)); &#125; public static void input(Scanner sc)&#123; System.out.println(sc); &#125; &#125; 作为返回值 123456789101112131415class Test2 &#123; public static void main(String[] args) &#123; // 普通方式 Scanner sc = getScanner(); &#125; public static Scanner getScanner()&#123; //普通方式 //Scanner sc = new Scanner(System.in); //return sc; //匿名对象作为方法返回值 return new Scanner(System.in); &#125;&#125; 三、Random类Random类：用来生成随机数字 使用步骤： 导包 import java.util.Random; idea可以自动生成 创建 Random r = new Random(); // 小括号当中留空即可 使用 获取一个随机的int数字（范围是int所有范围，有正负两种）： int num = r.nextInt() 获取一个随机的int数字（参数代表了范围，左闭右开区间）： int num = r.nextInt(3) 实际上代表的含义是：[0,3)，也就是0~2 练习： 猜数字小游戏游戏开始，随机生成一个1-100之间的整数 number 。玩家猜测一个数字 guessNumber ，会与 number 作比较，系统提示大了或者小了，直到玩家猜中，游戏结束。 代码： 123456789101112131415161718192021public static void main(String[] args) &#123; Random r = new Random(); int randomNum = r.nextInt(100) + 1; //[1:100] Scanner sc = new Scanner(System.in); while (true)&#123; System.out.println(\"请输入你猜测的数字：\"); int guessNum = sc.nextInt(); if (guessNum &gt; randomNum)&#123; System.out.println(\"太大了，请重试\"); &#125;else if (guessNum &lt; randomNum)&#123; System.out.println(\"太小了，请重试\"); &#125;else &#123; System.out.println(\"恭喜你，猜中啦\"); break; &#125; &#125; System.out.println(\"游戏结束\");&#125; 四、ArrayList类对象数组： 数组类型选用对象，例如： 123456789101112public static void main(String[] args) &#123; // 首先创建一个长度为3的数组，里面用来存放Person类型的对象 Person[] array = new Person[3]; Person one = new Person(\"迪丽热巴\", 18); // 将one当中的地址值赋值到数组的0号元素位置 array[0] = one; System.out.println(array[0]); // 地址值 System.out.println(array[0].getName()); // 迪丽热巴&#125; 而数组的长度是固定的，无法适应数据变化的需求 ArrayList类： 数组的长度不可以发生改变但是ArrayList集合的长度是可以随意变化的 4.1 查看类 java.util.ArrayList &lt;E&gt;:需要 import导入 &lt;E&gt; ，表示一种指定的数据类型，叫做泛型。 在出现 E 的地方，我们使用一种引用数据类型将其替换即可，表示我们将存储哪种引用类型的元素 ArrayList&lt; String&gt;，ArrayList&lt; Student&gt; 4.2 格式(查看构造方法)基本格式: ArrayList&lt; String&gt; list = new ArrayList&lt; String&gt;(); 在JDK 1.7后,右侧泛型的尖括号之内可以留空，但是&lt;&gt;仍然要写。 简化格式: ArrayList&lt; String&gt; list = new ArrayList&lt;&gt;(); 注意：对于ArrayList集合来说，未添加数据直接打印得到的不是地址值，而是内容。如果内容是空，得到的是空的中括号：[] 4.3 常用方法及遍历对于元素的操作,基本体现在——增、删、查。常用的方法有: public boolean add(E e)：向集合当中添加元素，参数的类型和泛型一致。返回值代表添加是否成功。备注：对于ArrayList集合来说，add添加动作一定是成功的，所以返回值可用可不用。但是对于其他集合（后面会有）来说，add添加动作不一定成功。 public E get(int index)：从集合当中获取元素，参数是索引编号，返回值就是对应位置的元素。 public E remove(int index)：从集合当中删除元素，参数是索引编号，返回值就是被删除掉的元素。 public int size()：获取集合的尺寸长度，返回值是集合中包含的元素个数 举例： 12345678910111213141516171819202122232425262728293031323334public static void main(String[] args) &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); System.out.println(list); // [] // 向集合中添加元素：add boolean success = list.add(\"柳岩\"); System.out.println(list); // [柳岩] System.out.println(\"添加的动作是否成功：\" + success); // true list.add(\"高圆圆\"); list.add(\"赵又廷\"); list.add(\"李小璐\"); list.add(\"贾乃亮\"); System.out.println(list); // [柳岩, 高圆圆, 赵又廷, 李小璐, 贾乃亮] // 从集合中获取元素：get。索引值从0开始 String name = list.get(2); System.out.println(\"第2号索引位置：\" + name); // 赵又廷 // 从集合中删除元素：remove。索引值从0开始。 String whoRemoved = list.remove(3); System.out.println(\"被删除的人是：\" + whoRemoved); // 李小璐 System.out.println(list); // [柳岩, 高圆圆, 赵又廷, 贾乃亮] // 获取集合的长度尺寸，也就是其中元素的个数 int size = list.size(); System.out.println(\"集合的长度是：\" + size); //遍历 for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(list.get(i)); &#125; //idea中，list.fori可以自动生成这个循环&#125; 4.4 存储基本数据类型ArrayList对象不能存储基本类型，只能存储引用类型的数据。类似 &lt; int&gt; 不能写，但是存储基本数据类型对应的包装类型是可以的。 基本类型 基本类型包装类 byte Byte short Short int Integer long Long float Float double Double char Character boolean Boolean 4.5 练习 生成6个1~33之间的随机整数,添加到集合,并遍历 12345678910111213141516171819public class Test01ArrayList &#123; public static void main(String[] args) &#123; // 创建Random 对象 Random random = new Random(); // 创建ArrayList 对象 ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); // 添加随机数到集合 for (int i = 0; i &lt; 6; i++) &#123; int r = random.nextInt(33) + 1; list.add(r); &#125; // 遍历集合输出 for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(list.get(i)); &#125; &#125; &#125; 自定义2个学生对象，添加到集合，并遍历 123456789101112131415161718public class Demo02ArrayListStudent &#123; public static void main(String[] args) &#123; ArrayList&lt;Student&gt; list = new ArrayList&lt;&gt;(); Student one = new Student(\"洪七公\", 20); Student two = new Student(\"欧阳锋\", 21); list.add(one); list.add(two); // 遍历集合 for (int i = 0; i &lt; list.size(); i++) &#123; Student stu = list.get(i); System.out.println(\"姓名：\" + stu.getName() + \"，年龄\" + stu.getAge()); &#125; &#125;&#125; 对象可以作为集合元素 定义以指定格式打印集合的方法(ArrayList类型作为参数)，使用{}扩起集合，使用@分隔每个元素。格式参照 {元素@元素@元素} 1234567891011121314151617181920212223242526public class Demo05ArrayListPrint &#123; public static void main(String[] args) &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"张三丰\"); list.add(\"宋远桥\"); list.add(\"张无忌\"); list.add(\"李连杰\"); System.out.println(list); printArrayList(list); &#125; public static void printArrayList(ArrayList&lt;String&gt; list)&#123; System.out.print(\"&#123;\"); for (int i = 0; i &lt; list.size(); i++) &#123; String name = list.get(i); if (i == list.size() - 1)&#123; System.out.println(name + \"&#125;\"); &#125;else&#123; System.out.print(name + \"@\"); &#125; &#125; &#125;&#125; 用一个大集合存入20个随机数字(1~100)，然后筛选其中的偶数元素，放到小集合当中。要求使用自定义的方法来实现筛选 1234567891011121314151617181920212223242526272829303132public class Demo04ArrayListReturn &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; bigList = new ArrayList&lt;&gt;(); Random r = new Random(); for (int i = 0; i &lt; 20; i++) &#123; int num = r.nextInt(100) + 1; // 1~100 bigList.add(num); &#125; ArrayList&lt;Integer&gt; smallList = getSmallList(bigList); System.out.println(\"偶数总共有多少个：\" + smallList.size()); for (int i = 0; i &lt; smallList.size(); i++) &#123; System.out.println(smallList.get(i)); &#125; &#125; // 这个方法，接收大集合参数，返回小集合结果 public static ArrayList&lt;Integer&gt; getSmallList(ArrayList&lt;Integer&gt; bigList) &#123; // 创建一个小集合，用来装偶数结果 ArrayList&lt;Integer&gt; smallList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; bigList.size(); i++) &#123; int num = bigList.get(i); if (num % 2 == 0) &#123; smallList.add(num); &#125; &#125; return smallList; &#125;&#125; ArrayList类型作为返回值 五、String类java.lang.String类代表字符串程序当中所有的双引号字符串，都是String类的对象。（就算没有new，也照样是。） 特点： 字符串的内容永不可变。 正是因为字符串不可改变，所以字符串是可以共享使用的。 字符串效果上相当于是char[ ]字符数组，但是底层原理是byte[]字节数组。 5.1 构造方法创建字符串的常见3+1种方式。 三种构造方法： public String()：创建一个空白字符串，不含有任何内容。 public String(char[] array)：根据字符数组的内容，来创建对应的字符串。 public String(byte[] array)：根据字节数组的内容，来创建对应的字符串。 代码： 12345678910 // 无参构造String str = new String();// 通过字符数组构造char chars[] = &#123;'a', 'b', 'c'&#125;; String str2 = new String(chars);// 通过字节数组构造byte bytes[] = &#123; 97, 98, 99 &#125;; String str3 = new String(bytes);//打印输出是'a','b','c' 一种直接创建： String str = &quot;Hello&quot;; // 右边直接用双引号 注意：直接写上双引号，就是字符串对象。 5.2 字符串的常量池 字符串常量池：程序当中直接写上的双引号字符串，就在字符串常量池中 对于基本类型来说，==是进行 数值 的比较 对于引用类型来说，==是进行 地址值 的比较 1234567891011public static void main(String[] args) &#123; String str1 = \"abc\"; String str2 = \"abc\"; char[] charArray = &#123;'a', 'b', 'c'&#125;; String str3 = new String(charArray); System.out.println(str1 == str2); // true System.out.println(str1 == str3); // false System.out.println(str2 == str3); // false&#125; 5.3 比较方法==是进行对象的地址值比较，如果确实需要字符串的内容比较，可以使用两个方法： public boolean equals(Object obj)：参数可以是任何对象，只有参数是一个字符串并且内容相同的才会给true；否则返回false。 注意事项： 任何对象都能用Object进行接收。 equals方法具有对称性，也就是a.equals(b)和b.equals(a)效果一样。 如果比较双方一个常量一个变量，推荐把常量字符串写在前面。推荐：”abc”.equals(str)不推荐：str.equals(“abc”) public boolean equalsIgnoreCase(String str)：忽略大小写，进行内容比较。 5.4 获取方法 String当中与获取相关的常用方法有： public int length()：获取字符串长度。 public String concat(String str)：将当前字符串和参数字符串拼接成为返回值新的字符串。 public char charAt(int index)：获取指定索引位置的单个字符。（索引从0开始。） public int indexOf(String str)：查找参数字符串在本字符串当中首次出现的索引位置，如果没有返回-1值。 12345678910111213141516171819202122public static void main(String[] args) &#123; // 获取字符串的长度 int length = \"asdasfeutrvauevbueyvb\".length(); // 拼接字符串 String str1 = \"Hello\"; String str2 = \"World\"; String str3 = str1.concat(str2); System.out.println(str3); // HelloWorld，新的字符串 // 获取指定索引位置的单个字符 char ch = \"Hello\".charAt(1); System.out.println(\"在1号索引位置的字符是：\" + ch); // 查找参数字符串在本来字符串当中出现的第一次索引位置 // 如果根本没有，返回-1值 String original = \"HelloWorldHelloWorld\"; int index = original.indexOf(\"llo\"); System.out.println(\"第一次索引值是：\" + index); // 2 System.out.println(\"HelloWorld\".indexOf(\"abc\")); // -1&#125; 5.5 截取方法字符串的截取方法： public String substring(int index)：截取从参数位置一直到字符串末尾，返回新字符串。 public String substring(int begin, int end)：截取从begin开始，一直到end结束，中间的字符串。[begin,end)，包含左边，不包含右边 123456String str1 = \"HelloWorld\";String str2 = str1.substring(5);System.out.println(str2); // World，新字符串String str3 = str1.substring(4, 7);System.out.println(str3); // oWo 5.6 转换方法String当中与转换相关的常用方法有： public char[] toCharArray()：将当前字符串拆分成为字符数组作为返回值。 public byte[] getBytes()：获得当前字符串底层的字节数组。 public String replace(CharSequence oldString, CharSequence newString)： 将所有出现的老字符串替换成为新的字符串，返回替换之后的结果新字符串。备注：CharSequence意思就是说可以接受字符串类型 1234567891011121314// 转换成为字符数组char[] chars = \"Hello\".toCharArray();System.out.println(chars[0]); // H// 转换成为字节数组byte[] bytes = \"abc\".getBytes();for (int i = 0; i &lt; bytes.length; i++) &#123; System.out.println(bytes[i]);&#125;// 字符串的内容替换String str1 = \"How do you do?\";String str2 = str1.replace(\"o\", \"*\");System.out.println(str2); // H*w d* y*u d*? 5.7 分割方法分割字符串的方法：public String[] split(String regex)：按照参数的规则，将字符串切分成为若干部分。 12345String str1 = \"aaa,bbb,ccc\";String[] array1 = str1.split(\",\");for (int i = 0; i &lt; array1.length; i++) &#123; System.out.println(array1[i]);&#125; 注意事项：split方法的参数其实是一个“正则表达式”，后面学习。此处注意：如果按照英文句点“.”进行切分，必须写”\\.”（两个反斜杠） 六、static关键字static关键字：它可以用来修饰的成员变量和成员方法，被修饰的成员是属于类的，而不是单单是属于某个对象的。也就是说，既然属于类，就可以不靠创建对象来调用了。 6.1 类变量（静态变量）（修饰成员变量）当static修饰成员变量时，该变量称为 类变量 该类的每个对象都共享同一个类变量的值 任何对象都可以更改该类变量的值 但也可以在不创建该类的对象的情况下对类变量进行操作。 举例： 每新来一个同学，id自动+1 学生类： 12345678910111213141516171819202122232425262728293031323334353637public class Student &#123; private int id; // 学号 private String name; // 姓名 private int age; // 年龄 static String room; // 所在教室 private static int idCounter = 0; // 学号计数器，每当new了一个新对象的时候，计数器++ public Student() &#123; this.id = ++idCounter; &#125; public Student(String name, int age) &#123; this.name = name; this.age = age; this.id = ++idCounter; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 代码： 1234567891011121314151617public class Demo01StaticField &#123; public static void main(String[] args) &#123; Student one = new Student(\"郭靖\", 19); one.room = \"101教室\";//后面会说，不推荐这么写 System.out.println(\"姓名：\" + one.getName() + \"，年龄：\" + one.getAge() + \"，教室：\" + one.room + \"，学号：\" + one.getId()); Student two = new Student(\"黄蓉\", 16); System.out.println(\"姓名：\" + two.getName() + \"，年龄：\" + two.getAge() + \"，教室：\" + two.room + \"，学号：\" + two.getId()); &#125;&#125; 输出： 姓名：郭靖，年龄：19，教室：101教室，学号：1姓名：黄蓉，年龄：16，教室：101教室，学号：2 6.2 静态方法（类方法）（修饰成员方法）一旦使用static修饰成员方法，那么这就成为了 静态方法。静态方法不属于对象，而是属于 类 的。 如果没有static关键字，那么必须首先创建对象，然后通过对象才能使用它。 如果有了static关键字，那么不需要创建对象，直接就能通过类名称来使用它。 无论是成员变量，还是成员方法。如果有了static，都推荐使用类名称进行调用。 静态变量：类名称.静态变量 静态方法：类名称.静态方法() 注意事项： 静态不能直接访问非静态原因：因为在内存当中是【先】有的静态内容，【后】有的非静态内容“先人不知道后人，但是后人知道先人。” 静态方法当中不能用this原因：this代表当前对象，通过谁调用的方法，谁就是当前对象 MyClass类： 1234567891011121314151617181920212223242526272829public class MyClass &#123; int num; // 成员变量 static int numStatic; // 静态变量 // 成员方法 public void method() &#123; System.out.println(\"这是一个成员方法。\"); // 成员方法可以访问成员变量 System.out.println(num); // 成员方法可以访问静态变量 System.out.println(numStatic); &#125; // 静态方法 public static void methodStatic() &#123; System.out.println(\"这是一个静态方法。\"); // 静态方法可以访问静态变量 System.out.println(numStatic); // 静态不能直接访问非静态【重点】// System.out.println(num); // 错误写法！ // 静态方法中不能使用this关键字。// System.out.println(this); // 错误写法！ &#125;&#125; 代码： 12345678910111213141516171819202122public class Demo02StaticMethod &#123; public static void main(String[] args) &#123; MyClass obj = new MyClass(); // 首先创建对象 // 然后才能使用没有static关键字的内容 obj.method(); // 对于静态方法来说，可以通过对象名进行调用，也可以直接通过类名称来调用。 obj.methodStatic(); // 正确，不推荐，这种写法在编译之后也会被javac翻译成为“类名称.静态方法名” MyClass.methodStatic(); // 正确，推荐 // 对于本类当中的静态方法，可以省略类名称 myMethod(); Demo02StaticMethod.myMethod(); // 完全等效 &#125; public static void myMethod() &#123; System.out.println(\"自己的方法！\"); &#125;&#125; 6.3静态代码块格式： public class 类名称 {&emsp;&emsp;&emsp;&emsp;static {&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;// 静态代码块的内容&emsp;&emsp;&emsp;&emsp;}} 特点： 当第一次用到本类时，静态代码块执行唯一的一次。 静态内容总是优先于非静态，所以静态代码块比构造方法先执行。 典型用途： 用来一次性地对静态成员变量进行赋值。 Person类： 123456789public class Person &#123; static &#123; System.out.println(\"静态代码块执行！\"); &#125; public Person() &#123; System.out.println(\"构造方法执行！\"); &#125;&#125; 代码： 1234public static void main(String[] args) &#123; Person one = new Person(); Person two = new Person();&#125; 输出结果： 静态代码块执行！构造方法执行！构造方法执行！ 七、Arrays类java.util.Arrays此类包含用来操作数组的各种方法，比如排序和搜索等。其所有方法均为静态方法，调用起来非常简单。 常用方法： public static String toString(数组)：将参数数组变成字符串（按照默认格式：[元素1, 元素2, 元素3…]） public static void sort(数组)：按照默认升序（从小到大）对 数组 的元素进行排序。 如果是数值，sort默认按照升序从小到大 如果是字符串，sort默认按照字母升序 如果是自定义的类型，那么这个自定义的类需要有Comparable或者Comparator接口的支持。（今后学习） 123String[] array2 = &#123;\"bbb\", \"aaa\", \"ccc\"&#125;;Arrays.sort(array2);System.out.println(Arrays.toString(array2)); // [aaa, bbb, ccc] 练习： 请使用Arrays相关的API，将一个随机字符串中的所有字符升序排列，并倒序打印。（涉及到倒序遍历） 1234567891011121314public static void main(String[] args) &#123; String str = \"asv76agfqwdfvasdfvjh\"; // 如何进行升序排列：sort // 必须是一个数组，才能用Arrays.sort方法 // String --&gt; 数组，用toCharArray char[] chars = str.toCharArray(); Arrays.sort(chars); // 对字符数组进行升序排列 // 需要倒序遍历(此处idea快捷键：chars.forr) for (int i = chars.length - 1; i &gt;= 0; i--) &#123; System.out.println(chars[i]); &#125;&#125; 八、Math类java.lang.Math 类包含用于执行基本数学运算的方法，如初等指数、对数、平方根和三角函数。类似这样的工具类，其所有方法均为静态方法，并且不会创建对象，调用起来非常简单。 基本运算方法： public static double abs(double num)：获取绝对值。有多种重载。 public static double ceil(double num)：向上取整。 public static double floor(double num)：向下取整。 public static long round(double num)：四舍五入。 Math.PI代表近似的圆周率常量（double） 1234567double d1 = Math.abs(‐5); //d1的值为5double d2 = Math.ceil(3.3); //d2的值为 4.0double d3 = Math.floor(3.3); //d3的值为3.0long d4 = Math.round(5.5); //d4的值为6.0 第二部分 第一章 Object类java.lang.Object类是Java语言中的根类，即所有类的父类。它中描述的所有方法子类都可以使用。在对象实例化的时候，最终找的父类就是Object。 如果一个类没有特别指定父类,那么默认则继承自Object类。例如： 123public class MyClass /*extends Object*/ &#123; // ...&#125; 根据JDK源代码及Object类的API文档，Object类当中包含的方法有11个。 1.1 toString方法 public String toString()：返回该对象的字符串表示： 类型+@+内存地址值 。 由于toString方法返回的结果是内存地址，而在开发中，经常需要按照对象的属性得到相应的字符串表现形式，因此也需要重写它。 覆盖重写如果不希望使用toString方法的默认行为，则可以对它进行覆盖重写。例如自定义的Person类： 1234567891011public class Person &#123; private String name; private int age; @Override public String toString() &#123; return \"Person&#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + '&#125;'; &#125; // 省略构造器与Getter Setter&#125; IDEA中，可以点击Code菜单中的Generate...，也可以使用快捷键^+N，点击toString()选项。选择需要包含的成员变量并确定。 小贴士： 在我们直接使用输出语句输出对象名的时候,其实通过该对象调用了其toString()方法。 1.2 equals方法 public boolean equals(Object obj)：指示其他某个对象是否与此对象“相等”。 equals方法源码: 123public boolean equals(Object obj) &#123; return (this == obj);&#125; 参数: Object obj:可以传递任意的对象 == 比较运算符,返回的是一个布尔值 true false 基本数据类型:比较的是值 引用数据类型:比价的是两个对象的地址值 12345678910public static void main(String[] args) &#123; Person p1 = new Person(\"迪丽热巴\",18); Person p2 = new Person(\"古力娜扎\",19); System.out.println(\"p1:\"+p1);//p1:com.itheima.demo01.Object.Person@58ceff1 System.out.println(\"p2:\"+p2);//p2:com.itheima.demo01.Object.Person@7c30a502 boolean b = p1.equals(p1); System.out.println(b); &#125; 默认地址比较如果没有覆盖重写equals方法，那么Object类中默认进行==运算符的对象地址比较，只要不是同一个对象，结果必然为false。 对象内容比较如果希望进行对象的内容比较，即所有或指定的部分成员变量相同就判定两个对象相同，则可以覆盖重写equals方法。 问题:隐含着一个多态多态的弊端:无法使用子类特有的内容(属性和方法)Object obj = p2 = new Person(“古力娜扎”,19);解决:可以使用向下转型(强转)把obj类型转换为Person IDEA中，可以快捷键^ + N，并选择equals() and hashCode()进行自动代码生成。 1234567891011121314151617181920import java.util.Objects;public class Person &#123; private String name; private int age; @Override public boolean equals(Object o) &#123; // 如果对象地址一样，则认为相同 if (this == o) return true; // 如果参数为空，或者类型信息不一样，则认为不同 if (o == null || getClass() != o.getClass()) return false; // 转换为当前类型 Person person = (Person) o; // 要求基本类型相等，并且将引用类型交给java.util.Objects类的equals静态方法取用结果 return age == person.age &amp;&amp; Objects.equals(name, person.name); &#125;&#125; tips：Object类当中的hashCode等其他方法，今后学习。 1.3 Objects类在IDEA自动重写equals代码中，使用到了java.util.Objects类 在JDK7添加了一个Objects工具类，它提供了一些方法来操作对象，它由一些静态的实用方法组成 这些方法是null-save（空指针安全的）或null-tolerant（容忍空指针的） 在比较两个对象的时候，Object的equals方法容易抛出空指针异常，而Objects类中的equals方法就优化了这个问题。方法如下： public static boolean equals(Object a, Object b):判断两个对象是否相等。 源码： 123public static boolean equals(Object a, Object b) &#123; return (a == b) || (a != null &amp;&amp; a.equals(b)); &#125; 第二章 日期时间类2.1 Date类 java.util.Date类 表示特定的瞬间，精确到毫秒 毫秒:千分之一秒 1000毫秒=1秒 特定的瞬间:一个时间点,一刹那时间2088-08-08 09:55:33:333 瞬间 毫秒值的作用:&emsp;可以对时间和日期进行计算 2099-01-03 到 2088-01-01 中间一共有多少天可以日期转换为毫秒进行计算,计算完毕,在把毫秒转换为日期 把日期转换为毫秒: 当前的日期:2088-01-01 时间原点(0毫秒):1970 年 1 月 1 日 00:00:00(英国格林威治) 就是计算当前日期到时间原点之间一共经历了多少毫秒 123public static void main(String[] args) &#123; System.out.println(System.currentTimeMillis());//获取当前系统时间到1970 年 1 月 1 日 00:00:00经历了多少毫秒&#125; 注意:中国属于东八区,会把时间增加8个小时–1970 年 1 月 1 日 08:00:00 把毫秒转换为日期: 1 天 = 24 × 60 × 60 = 86400 秒 = 86400 x 1000 = 86400000毫秒 构造方法 public Date()：分配Date对象并初始化此对象，以表示分配它的时间（精确到毫秒）。 public Date(long date)：分配Date对象并初始化此对象，以表示自从标准基准时间（称为“历元（epoch）”，即1970年1月1日00:00:00 GMT）以来的指定毫秒数。 tips: 由于我们处于东八区，所以我们的基准时间为1970年1月1日8时0分0秒。 简单来说：使用无参构造，可以自动设置当前系统时间的毫秒时刻；指定long类型的构造参数，可以自定义毫秒时刻。例如： 12345678910111213141516import java.util.Date;public class Demo01Date &#123; public static void main(String[] args) &#123; /* Date类的空参数构造方法 Date() 获取当前系统的日期和时间 */ System.out.println(new Date()); // Tue Jan 16 14:37:35 CST 2018 /* Date类的带参数构造方法 Date(long date) :传递毫秒值,把毫秒值转换为Date日期 */ System.out.println(new Date(0L)); // Thu Jan 01 08:00:00 CST 1970 &#125;&#125; tips:在使用println方法时，会自动调用Date类中的toString方法。Date类对Object类中的toString方法进行了覆盖重写，所以结果为指定格式的字符串。 常用成员方法Date类中的多数方法已经过时，常用的方法有： public long getTime() 把日期对象转换成对应的时间毫秒值相当于System.currentTimeMillis()方法 12345private static void demo03() &#123; Date date = new Date(); long time = date.getTime(); System.out.println(time);//3742777636267&#125; 2.2 DateFormat类java.text.DateFormat 是日期/时间格式化子类的抽象类，我们通过这个类可以帮我们完成日期和文本之间的转换,也就是可以在Date对象与String对象之间进行来回转换。 格式化：按照指定的格式，从Date对象转换为String对象。 解析：按照指定的格式，从String对象转换为Date对象。 构造方法DateFormat为抽象类，不能直接使用，需要常用的子类java.text.SimpleDateFormat。这个类需要一个模式（格式）来指定格式化或解析的标准。构造方法为： public SimpleDateFormat(String pattern)：用给定的模式和默认语言环境的日期格式符号构造SimpleDateFormat。 参数pattern是一个字符串，代表日期时间的自定义格式。 格式规则常用的格式规则为： 标识字母（区分大小写） 含义 y 年 M 月 d 日 H 时 m 分 s 秒 备注：更详细的格式规则，可以参考SimpleDateFormat类的API文档0。 创建SimpleDateFormat对象的代码如： 123456789import java.text.DateFormat;import java.text.SimpleDateFormat;public class Demo02SimpleDateFormat &#123; public static void main(String[] args) &#123; // 对应的日期格式如：2018-01-16 15:06:38 DateFormat format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); //字母不能改变，连接符号可以改变 &#125; &#125; 常用成员方法DateFormat类的常用方法有： public String format(Date date)：将Date对象格式化为字符串。 public Date parse(String source)：将字符串解析为Date对象。 format方法使用format方法的代码为： 123456789101112131415import java.text.DateFormat;import java.text.SimpleDateFormat;import java.util.Date;/* 把Date对象转换成String*/public class Demo03DateFormatMethod &#123; public static void main(String[] args) &#123; Date date = new Date(); // 创建日期格式化对象,在获取格式化对象时可以指定风格 DateFormat df = new SimpleDateFormat(\"yyyy年MM月dd日\"); String str = df.format(date); System.out.println(str); // 2008年1月23日 &#125;&#125; parse方法使用parse方法的代码为： 123456789101112131415import java.text.DateFormat;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;/* 把String转换成Date对象*/public class Demo04DateFormatMethod &#123; public static void main(String[] args) throws ParseException &#123; DateFormat df = new SimpleDateFormat(\"yyyy年MM月dd日\"); String str = \"2018年12月11日\"; Date date = df.parse(str); System.out.println(date); // Tue Dec 11 00:00:00 CST 2018 &#125;&#125; 2.3 练习请使用日期时间相关的API，计算出一个人已经出生了多少天。 思路： 使用Scanner类中的方法next,获取出生日期 使用DateFormat类中的方法parse,把字符串的出生日期,解析为Date格式的出生日期 把Date格式的出生日期转换为毫秒值 获取当前的日期,转换为毫秒值 使用当前日期的毫秒值-出生日期的毫秒值 把毫秒差值转换为天(s/1000/60/60/24) 代码实现： 123456789101112131415161718192021public static void function() throws Exception &#123; System.out.println(\"请输入出生日期 格式 YYYY-MM-dd\"); // 获取出生日期,键盘输入 String birthdayString = new Scanner(System.in).next(); // 将字符串日期,转成Date对象 // 创建SimpleDateFormat对象,写日期模式 SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd\"); // 调用方法parse,字符串转成日期对象 Date birthdayDate = sdf.parse(birthdayString); // 获取今天的日期对象 Date todayDate = new Date(); // 将两个日期转成毫秒值,Date类的方法getTime long birthdaySecond = birthdayDate.getTime(); long todaySecond = todayDate.getTime(); long secone = todaySecond-birthdaySecond; if (secone &lt; 0)&#123; System.out.println(\"还没出生呢\"); &#125; else &#123; System.out.println(secone/1000/60/60/24); &#125;&#125; 2.4 Calendar类java.util.Calendar是日历类，在Date后出现，替换掉了许多Date的方法。该类将所有可能用到的时间信息封装为静态成员变量，方便获取。 日历类就是方便获取各个时间属性的。 获取方式Calendar为抽象类，由于语言敏感性，Calendar类在创建对象时并非直接创建，而是通过静态方法创建，返回子类对象，如下： Calendar静态方法 public static Calendar getInstance()：使用默认时区和语言环境获得一个日历 例如： 1234567import java.util.Calendar;public class Demo06CalendarInit &#123; public static void main(String[] args) &#123; Calendar cal = Calendar.getInstance(); &#125; &#125; 常用成员方法根据Calendar类的API文档，常用方法有： public int get(int field)：返回给定日历字段的值。 public void set(int field, int value)：将给定的日历字段设置为给定值。 public abstract void add(int field, int amount)：根据日历的规则，为给定的日历字段添加或减去指定的时间量。 public Date getTime()：返回一个表示此Calendar时间值（从历元到现在的毫秒偏移量）的Date对象。 Calendar类中提供很多成员常量，代表给定的日历字段： 字段值 含义 YEAR 年 MONTH 月（从0开始，可以+1使用） DAY_OF_MONTH / DATE 月中的天（几号） HOUR 时（12小时制） HOUR_OF_DAY 时（24小时制） MINUTE 分 SECOND 秒 DAY_OF_WEEK 周中的天（周几，周日为1，可以-1使用） get/set方法get方法用来获取指定字段的值，set方法用来设置指定字段的值，代码使用演示： 123456789101112131415import java.util.Calendar;public class CalendarUtil &#123; public static void main(String[] args) &#123; // 创建Calendar对象 Calendar cal = Calendar.getInstance(); // 设置年 int year = cal.get(Calendar.YEAR); // 设置月 int month = cal.get(Calendar.MONTH) + 1; // 设置日 int dayOfMonth = cal.get(Calendar.DAY_OF_MONTH); System.out.print(year + \"年\" + month + \"月\" + dayOfMonth + \"日\");//2019年7月14日 &#125; &#125; 12345678910111213import java.util.Calendar;public class Demo07CalendarMethod &#123; public static void main(String[] args) &#123; Calendar cal = Calendar.getInstance(); cal.set(Calendar.YEAR, 2020); //年月日的输出int设置省略了 System.out.print(year + \"年\" + month + \"月\" + dayOfMonth + \"日\"); // 2020年1月17日 //同时设置年月日,可以使用set的重载方法 cal.set(8888,8,8); &#125;&#125; add方法add方法可以对指定日历字段的值进行加减操作，如果第二个参数为正数则加上偏移量，如果为负数则减去偏移量。代码如： 12345678910111213import java.util.Calendar;public class Demo08CalendarMethod &#123; public static void main(String[] args) &#123; Calendar cal = Calendar.getInstance(); System.out.print(year + \"年\" + month + \"月\" + dayOfMonth + \"日\"); // 2018年1月17日 // 使用add方法 cal.add(Calendar.DAY_OF_MONTH, 2); // 加2天 cal.add(Calendar.YEAR, -3); // 减3年 System.out.print(year + \"年\" + month + \"月\" + dayOfMonth + \"日\"); // 2015年1月18日; &#125;&#125; getTime方法Calendar中的getTime方法并不是获取毫秒时刻，而是拿到对应的Date对象。 日历转换为日期 12345678910import java.util.Calendar;import java.util.Date;public class Demo09CalendarMethod &#123; public static void main(String[] args) &#123; Calendar cal = Calendar.getInstance(); Date date = cal.getTime(); System.out.println(date); // Tue Jan 16 16:03:09 CST 2018 &#125;&#125; 小贴士： ​ 西方星期的开始为周日，中国为周一。 ​ 在Calendar类中，月份的表示是以0-11代表1-12月。 ​ 日期是有大小关系的，时间靠后，时间越大。 第三章 System类java.lang.System类中提供了大量的静态方法，可以获取与系统相关的信息或系统级操作，在System类的API文档中，常用的方法有： public static long currentTimeMillis()：返回以毫秒为单位的当前时间。 public static void arraycopy(Object src, int srcPos, Object dest, int destPos, int length)：将数组中指定的数据拷贝到另一个数组中。 3.1 currentTimeMillis方法实际上，currentTimeMillis方法就是 获取当前系统时间与1970年01月01日00:00点之间的毫秒差值 12345678import java.util.Date;public class SystemDemo &#123; public static void main(String[] args) &#123; //获取当前时间毫秒值 System.out.println(System.currentTimeMillis()); // 1516090531144 &#125;&#125; 练习验证for循环打印数字1-9999所需要使用的时间（毫秒） 12345678910public class SystemTest1 &#123; public static void main(String[] args) &#123; long start = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) &#123; System.out.println(i); &#125; long end = System.currentTimeMillis(); System.out.println(\"共耗时毫秒：\" + (end - start)); &#125;&#125; 3.2 arraycopy方法 public static void arraycopy(Object src, int srcPos, Object dest, int destPos, int length)：将数组中指定的数据拷贝到另一个数组中。 数组的拷贝动作是系统级的，性能很高。System.arraycopy方法具有5个参数，含义分别为： 参数序号 参数名称 参数类型 参数含义 1 src Object 源数组 2 srcPos int 源数组索引起始位置 3 dest Object 目标数组 4 destPos int 目标数组索引起始位置 5 length int 复制元素个数 练习将src数组中前3个元素，复制到dest数组的前3个位置上复制元素前：src数组元素[1,2,3,4,5]，dest数组元素[6,7,8,9,10]复制元素后：src数组元素[1,2,3,4,5]，dest数组元素[1,2,3,9,10] 12345678910111213import java.util.Arrays;public class Demo11SystemArrayCopy &#123; public static void main(String[] args) &#123; int[] src = new int[]&#123;1,2,3,4,5&#125;; int[] dest = new int[]&#123;6,7,8,9,10&#125;; System.arraycopy( src, 0, dest, 0, 3); /*代码运行后：两个数组中的元素发生了变化 src数组元素[1,2,3,4,5] dest数组元素[1,2,3,9,10] */ &#125;&#125; 第四章 StringBuilder类4.1 字符串拼接问题由于String类的对象内容不可改变，所以每当进行字符串拼接时，总是会在内存中创建一个新的对象。例如： 1234567public class StringDemo &#123; public static void main(String[] args) &#123; String s = \"Hello\"; s += \"World\"; System.out.println(s); &#125;&#125; 在API中对String类有这样的描述：字符串是常量，它们的值在创建后不能被更改。 根据这句话分析我们的代码，其实总共产生了三个字符串，即&quot;Hello&quot;、&quot;World&quot;和&quot;HelloWorld&quot;。引用变量s首先指向Hello对象，最终指向拼接出来的新字符串对象，即HelloWorld 。 由此可知，如果对字符串进行拼接操作，每次拼接，都会构建一个新的String对象，既耗时，又浪费空间。为了解决这一问题，可以使用java.lang.StringBuilder类。 4.2 StringBuilder概述StringBuilder又称为可变字符序列，它是一个类似于 String 的字符串缓冲区，通过某些方法调用可以改变该序列的长度和内容，可以提高字符串的效率。 原来StringBuilder是个字符串的缓冲区，即它是一个容器，容器中可以装很多字符串。并且能够对其中的字符串进行各种操作。 它的内部拥有一个数组用来存放字符串内容，进行字符串拼接时，直接在数组中加入新内容。StringBuilder会自动维护数组的扩容。原理如下图所示：(默认16字符空间，超过自动扩充) 4.3 构造方法根据StringBuilder的API文档，常用构造方法有2个： public StringBuilder()：构造一个空的StringBuilder容器，其初始容量为 16 个字符。 public StringBuilder(String str)：构造一个StringBuilder容器，并将字符串添加进去。 123456789public class StringBuilderDemo &#123; public static void main(String[] args) &#123; StringBuilder sb1 = new StringBuilder(); System.out.println(sb1); // (空白) // 使用带参构造 StringBuilder sb2 = new StringBuilder(\"itcast\"); System.out.println(sb2); // itcast &#125;&#125; 4.4 常用方法StringBuilder常用的方法有2个： public StringBuilder append(...)：添加任意类型数据的字符串形式，并返回当前对象自身。 public String toString()：将当前StringBuilder对象转换为String对象。 append方法append方法具有多种重载形式，可以接收任意类型的参数。任何数据作为参数都会将对应的字符串内容添加到StringBuilder中。例如： 1234567891011121314151617181920212223242526public class Demo02StringBuilder &#123; public static void main(String[] args) &#123; //创建对象 StringBuilder builder = new StringBuilder(); //public StringBuilder append(任意类型) StringBuilder builder2 = builder.append(\"hello\"); //对比一下 System.out.println(\"builder:\"+builder);//hello System.out.println(\"builder2:\"+builder2);//hello System.out.println(builder == builder2); //true，地址相同 // 可以添加 任何类型 // 使用append方法无需接收返回值 builder.append(\"hello\"); builder.append(\"world\"); builder.append(true); builder.append(100); // 在我们开发中，会遇到调用一个方法后，返回一个对象的情况。然后使用返回的对象继续调用方法。 // 这种时候，我们就可以把代码现在一起，如append方法一样，代码如下 //链式编程 builder.append(\"hello\").append(\"world\").append(true).append(100); System.out.println(\"builder:\"+builder); &#125;&#125; 备注：StringBuilder已经覆盖重写了Object当中的toString方法。 toString方法通过toString方法，StringBuilder对象将会转换为不可变的String对象。如： 123456789public class Demo16StringBuilder &#123; public static void main(String[] args) &#123; // 链式创建 StringBuilder sb = new StringBuilder(\"Hello\").append(\"World\").append(\"Java\"); // 调用方法 String str = sb.toString(); System.out.println(str); // HelloWorldJava &#125;&#125; 第五章 包装类（本部分前面提到过）Java提供了两个类型系统，基本类型与引用类型。 使用基本类型在于效率，然而很多情况，会创建对象使用，因为对象可以做更多的功能。 如果想要我们的基本类型像对象一样操作，就可以使用基本类型对应的包装类，如下： 基本类型 对应的包装类（位于java.lang包中） byte Byte short Short int Integer long Long float Float double Double char Character boolean Boolean 5.1 装箱与拆箱基本类型与对应的包装类对象之间，来回转换的过程称为”装箱“与”拆箱“： 装箱：从基本类型转换为对应的包装类对象。 拆箱：从包装类对象转换为对应的基本类型。 用Integer与 int为例：（看懂代码即可） 基本数值—&gt;包装对象 12Integer i = new Integer(4);//使用构造函数函数Integer iii = Integer.valueOf(4);//使用包装类中的valueOf方法 包装对象—-&gt;基本数值 1int num = i.intValue(); 5.2 自动装箱与自动拆箱由于我们经常要做基本类型与包装类之间的转换，从Java 5（JDK 1.5）开始，基本类型与包装类的装箱、拆箱动作可以自动完成。例如： 123Integer i = 4;//自动装箱。相当于Integer i = Integer.valueOf(4);i = i + 5;//等号右边：将i对象转成基本数值(自动拆箱) i.intValue() + 5;//加法运算完成后，再次装箱，把基本数值转成对象。 5.3 基本类型与字符串之间的转换基本类型转换为String 基本类型转换String总共有三种方式 基本类型直接与””相连接即可；如：34+””(简单常用) 包装类的静态方法toString(参数),不是Object类的toString() 重载static String toString(int i) 返回一个表示指定整数的 String 对象。 String类的静态方法valueOf(参数)static String valueOf(int i) 返回 int 参数的字符串表示形式 123456789int i1 = 100;String s1 = i1+\"\";System.out.println(s1+200);//100200String s2 = Integer.toString(100);System.out.println(s2+200);//100200String s3 = String.valueOf(100);System.out.println(s3+200);//10020 String转换成对应的基本类型除了Character类之外，其他所有包装类都具有parseXxx静态方法可以将字符串参数转换为对应的基本类型： public static byte parseByte(String s)：将字符串参数转换为对应的byte基本类型。 public static short parseShort(String s)：short基本类型。 public static int parseInt(String s)：int基本类型。 public static long parseLong(String s)：long基本类型。 public static float parseFloat(String s)：float基本类型。 public static double parseDouble(String s)：double基本类型。 public static boolean parseBoolean(String s)：boolean基本类型。 代码使用（仅以Integer类的静态方法parseXxx为例）如： 12345public class Demo18WrapperParse &#123; public static void main(String[] args) &#123; int num = Integer.parseInt(\"100\"); &#125;&#125; 注意:如果字符串参数的内容无法正确转换为对应的基本类型，则会抛出java.lang.NumberFormatException异常。","categories":[{"name":"java","slug":"java","permalink":"http://mangosTeeN96.github.io/categories/java/"}],"tags":[]},{"title":"Java_继承与多态","slug":"Java_继承与多态","date":"2019-05-09T03:16:06.000Z","updated":"2020-08-04T07:48:24.151Z","comments":true,"path":"2019/05/09/Java_继承与多态/","link":"","permalink":"http://mangosTeeN96.github.io/2019/05/09/Java_继承与多态/","excerpt":"","text":"一、继承多个类中存在相同属性和行为时，将这些内容抽取到单独一个类中，那么多个类无需再定义这些属性和行为，只要继承那一个类即可。其中，多个类可以称为子类，单独那一个类称为父类、超类(superclass)或者基类。 继承描述的是事物之间的所属关系，这种关系是: is-a 的关系。例如，兔子属于食草动物，食草动物属于动物。可见，父类更通用，子类更具体。我们通过继承，可以使多种事物之间形成一种关系体系。 定义： 继承:就是子类继承父类的属性和行为，使得子类对象具有与父类相同的属性、相同的行为。子类可以直接访问父类中的非私有的属性和行为。 1.1 格式123456public class 父类 &#123; ...&#125;public class 子类 extends 父类 &#123; ...&#125; 1.2 成员变量访问在父子类的继承关系当中，如果成员变量重名，则： 直接通过子类对象访问成员变量： 等号左边是谁，就优先用谁，没有则向上找。 - 间接通过成员方法访问成员变量： - 该方法属于谁，就优先用谁，没有则向上找 三种变量写法整理： 局部变量：&emsp;&emsp;&emsp; 直接写成员变量名 本类的成员变量： this.成员变量名 父类的成员变量： super.成员变量 父类： 123public class Fu &#123; int num = 10;&#125; 子类： 1234567891011public class Zi extends Fu &#123; int num = 20; public void method() &#123; int num = 30; System.out.println(num); // 30，局部变量 System.out.println(this.num); // 20，本类的成员变量 System.out.println(super.num); // 10，父类的成员变量 &#125;&#125; 1.3 成员方法 在父子类的继承关系当中，创建子类对象，访问成员方法的规则：创建的对象是谁，就优先用谁，如果没有则向上找。 注意事项：无论是成员方法还是成员变量，如果没有都是向上找父类，绝对不会向下找子类的 重写（覆盖重写）– 成员方法重名方法重写 :子类中出现与父类一模一样的方法时(返回值类型，方法名和参数列表都相同)会出现覆盖效果，也称为重写或者复写。声明不变，重新实现。 特点：创建的是子类对象，则优先用子类方法 注意事项： 必须保证父子类之间方法的名称相同，参数列表也相同。 @Override：写在方法前面，用来检测是不是有效的正确覆盖重写。 这个注解就算不写，只要满足要求，也是正确的方法覆盖重写。 子类方法的返回值必须【小于等于】父类方法的返回值范围。 小扩展提示：java.lang.Object类是所有类的公共最高父类（祖宗类），java.lang.String就是Object的子类。 子类方法的权限必须【大于等于】父类方法的权限修饰符。 小扩展提示：public &gt; protected &gt; (default) &gt; private备注：(default)不是关键字default，而是什么都不写，留空。 (其实多数情况这些范围权限都是相等的) 应用： 12345public class Phone &#123; public void show() &#123; System.out.println(\"显示号码\"); &#125;&#125; 12345678910public class NewPhone extends Phone &#123; @Override public void show() &#123; super.show(); // 把父类的show方法拿过来重复利用 // 自己子类再来添加更多内容 System.out.println(\"显示姓名\"); System.out.println(\"显示头像\"); &#125;&#125; 1.4构造方法继承关系中，父子类构造方法的访问特点： 子类构造方法当中有一个默认隐含的“super()”调用，所以一定是先调用的父类构造，后执行的子类构造。 子类构造可以通过super关键字来调用父类重载构造。 super的父类构造调用，必须是子类构造方法的第一个语句。不能一个子类构造调用多次super构造。 12345678public class Fu &#123; public Fu() &#123; System.out.println(\"父类无参构造\"); &#125; public Fu(int num) &#123; System.out.println(\"父类有参构造！\"); &#125;&#125; 123456789101112public class Zi extends Fu &#123; public Zi() &#123; super(); // 在调用父类无参构造方法// super(20); // 在调用父类重载的构造方法 System.out.println(\"子类构造方法！\"); &#125; public void method() &#123;// super(); // 错误写法！只有子类构造方法，才能调用父类构造方法。 &#125;&#125; 总结：子类必须调用父类构造方法，不写则赠送super()；写了则用写的指定的super调用，super只能有一个，还必须是第一个。 super关键字用法总结： 在子类的成员方法中，访问父类的成员变量。 在子类的成员方法中，访问父类的成员方法。 在子类的构造方法中，访问父类的构造方法。 this关键字用法总结： super关键字用来访问父类内容，而this关键字用来访问本类内容。用法也有三种： 在本类的成员方法中，访问本类的成员变量。 在本类的成员方法中，访问本类的另一个成员方法。 在本类的构造方法中，访问本类的另一个构造方法。 在第三种用法当中要注意：A. this(…)调用也必须是构造方法的第一个语句，唯一一个。B. super和this两种构造调用，不能同时使用 super与this的内存图: 1.5 继承的特点 java只支持单继承，不支持多继承。一个类只能有一个父类，不可以有多个父类。 Java支持多层继承(继承体系)。 子类和父类是一种相对的概念。 二、抽象类没有方法主体的方法称为抽象方法包含抽象方法的类就是抽象类 抽象方法概念图： 2.1 格式抽象类与抽象方法格式： 123456public abstract class Animal &#123; // 这是一个抽象方法，代表吃东西，但是具体吃什么（大括号的内容）不确定。 public abstract void eat();&#125; 2.2 使用使用抽象类和抽象方法： 不能直接创建new抽象类对象。 必须用一个子类来继承抽象父类。 子类必须覆盖重写抽象父类当中所有的抽象方法。覆盖重写（实现）：子类去掉抽象方法的abstract关键字，然后补上方法体大括号。 创建子类对象进行使用。 注意事项： 抽象类中，可以有构造方法，是供子类创建对象时，初始化父类成员使用的。理解:子类的构造方法中，有默认的super()，需要访问父类构造方法。 抽象类中，不一定包含抽象方法，但是有抽象方法的类必定是抽象类。理解:未包含抽象方法的抽象类，目的就是不想让调用者创建该类对象，通常用于某些特殊的类结构设计。 抽象类的子类，必须重写抽象父类中所有的抽象方法，除非该子类也是抽象类。理解:假设不重写所有抽象方法，则类中可能包含抽象方法。那么创建对象后，调用抽象的方法，没有意义。 2.3 案例案例分析： 用户父类: 123456789101112131415161718192021222324252627282930public class User &#123; private String name; // 姓名 private int money; // 余额，也就是当前用户拥有的钱数 public User() &#123; &#125; public User(String name, int money) &#123; this.name = name; this.money = money; &#125; // 展示一下当前用户有多少钱 public void show() &#123; System.out.println(\"我叫：\" + name + \"，我有多少钱：\" + money); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getMoney() &#123; return money; &#125; public void setMoney(int money) &#123; this.money = money; &#125;&#125; 群主子类： 123456789101112131415161718192021222324252627282930313233343536373839public class Manager extends User &#123; public Manager() &#123; &#125; public Manager(String name, int money) &#123; super(name, money); &#125; public ArrayList&lt;Integer&gt; send(int totalMoney, int count) &#123; // 首先需要一个集合，用来存储若干个红包的金额 ArrayList&lt;Integer&gt; redList = new ArrayList&lt;&gt;(); // 看一下群主自己有多少钱 int leftMoney = super.getMoney(); // 群主当前余额 if (totalMoney &gt; leftMoney) &#123; System.out.println(\"余额不足\"); return redList; // 返回空集合 &#125; // 扣钱，其实就是重新设置余额 super.setMoney(leftMoney - totalMoney); // 发红包需要平均拆分成为count份 int avg = totalMoney / count; int mod = totalMoney % count; // 余数，也就是甩下的零头 // 除不开的零头，包在最后一个红包当中 // 下面把红包一个一个放到集合当中 for (int i = 0; i &lt; count - 1; i++) &#123; redList.add(avg); &#125; // 最后一个红包 int last = avg + mod; redList.add(last); return redList; &#125;&#125; 群成员子类： 1234567891011121314151617181920public class Member extends User &#123; public Member() &#123; &#125; public Member(String name, int money) &#123; super(name, money); &#125; public void receive(ArrayList&lt;Integer&gt; list) &#123; // 从多个红包当中随便抽取一个，给我自己。 // 随机获取一个集合当中的索引编号 int index = new Random().nextInt(list.size()); // 根据索引，从集合当中删除，并且得到被删除的红包，给我自己 int delta = list.remove(index); // 当前成员自己本来有多少钱： int money = super.getMoney(); // 加法，并且重新设置回去 super.setMoney(money + delta); &#125;&#125; 发红包： 123456789101112131415161718192021222324252627282930public class MainRedPacket &#123; public static void main(String[] args) &#123; Manager manager = new Manager(\"群主\", 100); Member one = new Member(\"成员A\", 0); Member two = new Member(\"成员B\", 0); Member three = new Member(\"成员C\", 0); manager.show(); // 100 one.show(); // 0 two.show(); // 0 three.show(); // 0 System.out.println(\"===============\"); // 群主总共发20块钱，分成3个红包 ArrayList&lt;Integer&gt; redList = manager.send(20, 3); // 三个普通成员收红包 one.receive(redList); two.receive(redList); three.receive(redList); manager.show(); // 100-20=80 // 6、6、8，随机分给三个人 one.show(); two.show(); three.show(); &#125;&#125; 三、接口接口就是多个类的公共规范。 接口，是Java语言中一种引用类型，是方法的集合。如果说类的内部封装了成员变量、构造方法和成员方法，那么，接口的内部主要就是封装了方法，包含抽象方法(JDK 7及以前)，默认方法和静态方法(JDK 8)，私有方法 (JDK 9)。 3.1 格式 public interface 接口名称 {&emsp;&emsp;&emsp;&emsp;// 抽象方法&emsp;&emsp;&emsp;&emsp;// 默认方法&emsp;&emsp;&emsp;&emsp;// 静态方法&emsp;&emsp;&emsp;&emsp;// 私有方法} 3.2 实现（接口的使用）实现格式： public class 实现类名称 implements 接口名称 {&emsp;&emsp;&emsp;&emsp;// …} 接口不能直接使用，必须有一个“实现类”来“实现”该接口。 接口的实现类必须覆盖重写（实现）接口中所有的抽象方法。实现：去掉abstract关键字，加上方法体大括号。 创建实现类的对象，进行使用。 接口 MyInterfaceAbstract 1234public interface MyInterfaceAbstract &#123; // 这是一个抽象方法 public abstract void methodAbs()&#125; 实现类 MyInterfaceAbstractImpl 123456public class MyInterfaceAbstractImpl implements MyInterfaceAbstract &#123; @Override public void methodAbs() &#123; System.out.println(\"这是一个方法！\"); &#125;&#125; 接口实现 1234567891011public class Demo01Interface &#123; public static void main(String[] args) &#123; // 错误写法！不能直接new接口对象使用。// MyInterfaceAbstract inter = new MyInterfaceAbstract(); // 创建实现类的对象使用 MyInterfaceAbstractImpl impl = new MyInterfaceAbstractImpl(); impl.methodAbs() &#125;&#125; 注意事项： 如果实现类并没有覆盖重写接口中所有的抽象方法，那么这个实现类自己就必须是抽象类。 3.3 内部封装的方法抽象方法格式： public abstract 返回值类型 方法名称(参数列表); 注意事项： 接口当中的抽象方法，修饰符必须是两个固定的关键字：public abstract 这两个关键字修饰符，可以选择性地省略。（刚学，不推荐省略） 方法的三要素，可以随意定义 默认方法可以继承，可以重写，二选一，但是只能通过实现类的对象来调用。 格式： public default 返回值类型 方法名称(参数列表) {&emsp;&emsp;&emsp;&emsp;方法体} 备注：接口当中的默认方法，可以解决接口升级的问题 接口 1234567891011121314public interface MyInterfaceDefault &#123; // 抽象方法 public abstract void methodAbs(); // 新添加了一个抽象方法// public abstract void methodAbs2(); // 新添加的方法，改成默认方法 public default void methodDefault() &#123; System.out.println(\"这是新添加的默认方法\"); &#125;&#125; 实现类A（未重写） 123456public class MyInterfaceDefaultA implements MyInterfaceDefault &#123; @Override public void methodAbs() &#123; System.out.println(\"实现了抽象方法，AAA\"); &#125;&#125; 实现类B（重写） 1234567891011public class MyInterfaceDefaultB implements MyInterfaceDefault &#123; @Override public void methodAbs() &#123; System.out.println(\"实现了抽象方法，BBB\"); &#125; @Override public void methodDefault() &#123; System.out.println(\"实现类B覆盖重写了接口的默认方法\"); &#125;&#125; 主代码 1234567891011121314151617public class Demo02Interface &#123; public static void main(String[] args) &#123; // 创建了实现类对象 MyInterfaceDefaultA a = new MyInterfaceDefaultA(); a.methodAbs(); // 调用抽象方法，实际运行的是右侧实现类。 // 调用默认方法，如果实现类当中没有，会向上找接口 a.methodDefault(); // 这是新添加的默认方法 System.out.println(\"==========\"); MyInterfaceDefaultB b = new MyInterfaceDefaultB(); b.methodAbs(); b.methodDefault(); // 实现类B覆盖重写了接口的默认方法 &#125;&#125; 静态方法格式： public static 返回值类型 方法名称(参数列表) {&emsp;&emsp;&emsp;&emsp;方法体} 只能使用接口名调用(直接在主代码中调用) 不可以通过实现类的类名或者实现类的对象调用 调用格式： 接口名称.静态方法名(参数); 私有方法问题描述：我们需要抽取一个共有方法，用来解决两个默认方法之间重复代码的问题。但是这个共有方法不应该让实现类使用，应该是私有化的。 普通私有方法 解决多个默认方法之间重复代码问题格式： private 返回值类型 方法名称(参数列表) {&emsp;&emsp;&emsp;&emsp;方法体} 12345678910111213141516171819public interface MyInterfacePrivateA &#123; public default void methodDefault1() &#123; System.out.println(\"默认方法1\"); methodCommon(); &#125; public default void methodDefault2() &#123; System.out.println(\"默认方法2\"); methodCommon(); &#125; private void methodCommon() &#123; System.out.println(\"AAA\"); System.out.println(\"BBB\"); System.out.println(\"CCC\"); &#125;&#125; 静态私有方法 解决多个静态方法之间重复代码问题格式： private static 返回值类型 方法名称(参数列表) {&emsp;&emsp;&emsp;&emsp;方法体} 3.4 常量接口当中也可以定义“成员变量”，但是必须使用public static final三个关键字进行修饰 从效果上看，这其实就是接口的常量 格式： public static final 数据类型 常量名称 = 数据值; 接口 123456public interface MyInterfaceConst &#123; // 这其实就是一个常量，一旦赋值，不可以修改 public static final int NUM_OF_MY_CLASS = 12;&#125; 主代码 12345678public class Demo05Interface &#123; public static void main(String[] args) &#123; // 访问接口当中的常量 System.out.println(MyInterfaceConst.NUM_OF_MY_CLASS); &#125;&#125; 一旦使用final关键字进行修饰，说明不可改变。 注意事项： 接口当中的常量，可以省略public static final不写也一样。 接口当中的常量，必须赋值，不能不赋值。 接口中常量的名称，使用完全大写的字母，用下划线进行分隔。（推荐命名规则） 3.5 接口使用注意事项 接口是没有静态代码块或者构造方法的。 一个类的直接父类是唯一的，但是一个类可以同时实现多个接口。格式： public class MyInterfaceImpl implements MyInterfaceA, MyInterfaceB {&emsp;&emsp;&emsp;&emsp;// 覆盖重写所有抽象方法} 如果实现类所实现的多个接口当中，存在重复的抽象方法，那么只需要覆盖重写一次即可。 如果实现类没有覆盖重写所有接口当中的所有抽象方法，那么实现类就必须是一个抽象类。 如果实现类锁实现的多个接口当中，存在重复的默认方法，那么实现类一定要对冲突的默认方法进行覆盖重写。 一个类如果它的直接父类当中的方法，和接口当中的默认方法产生了冲突（重名），优先用父类当中的方法。 接口A： 1234567891011public interface MyInterfaceA &#123; public abstract void methodA(); public abstract void methodabs(); public default void methodDefault()&#123; System.out.println(\"默认方法AAA\"); &#125;&#125; 接口B： 12345678910public interface MyInterfaceB &#123; public abstract void methodB(); public abstract void methodabs(); public default void methodDefault()&#123; System.out.println(\"默认方法BBB\"); &#125;&#125; 实现类： 12345678910111213141516171819202122public class MyInterfaceImpl /*extends Object*/ implements MyInterfaceA, MyInterfaceB &#123; @Override public void methodA() &#123; System.out.println(\"覆盖重写了A方法\"); &#125; @Override public void methodB() &#123; System.out.println(\"覆盖重写了B方法\"); &#125; @Override public void methodAbs() &#123; System.out.println(\"覆盖重写了AB接口都有的抽象方法\"); &#125; @Override public void methodDefault() &#123; System.out.println(\"对多个接口当中冲突的默认方法进行了覆盖重写\"); &#125;&#125; 3.6 接口的多继承 一个接口能继承另一个或者多个接口，这和类之间的继承比较相似 接口的继承使用 extends 关键字，子接口继承父接口的方法 如果父接口中的默认方法有重名的，那么子接口需要重写一次 四、多态多态是继封装、继承之后，面向对象的第三大特性。 多态: 是指同一行为，具有多个不同表现形式。 前提： 继承或者实现 方法的重写(意义体现:不重写，无意义) 父类引用指向子类对象 4.1 格式 父类名称 对象名 = new 子类名称(); 或者： 接口名称 对象名 = new 实现类名称(); 当使用多态方式调用方法时，首先检查父类中是否有该方法 如果没有，则编译错误 如果有，执行的是子类重写后方法 父类： 123public abstract class Animal &#123; public abstract void eat();&#125; 子类： 12345class Cat extends Animal &#123; public void eat() &#123; System.out.println(\"吃鱼\"); &#125;&#125; 测试类 12345678public class Test &#123; public static void main(String[] args) &#123; // 多态形式，创建对象 Animal a = new Cat(); // 调用的是 Cat 的 eat a.eat(); &#125; &#125; 4.2 成员变量多态中成员变量的使用特点，与之前的笔记中一样。 访问成员变量的两种方式(Fu obj = new Zi())： 直接通过对象名称（obj.num)访问成员变量：看等号左边是谁，优先用谁，没有则向上找。(成员变量不能覆盖重写) 间接通过成员方法访问成员变量：看该方法属于谁，优先用谁，没有则向上找。 4.3 成员方法多态中，成员方法的访问规则(也和以前一样)：&emsp;&emsp;&emsp;看new的是谁，就优先用谁，没有则向上找。 特殊之处：编译看左边，运行看右边 对比一下： 成员变量：编译看左边，运行还看左边。 成员方法：编译看左边，运行看右边 4.4 使用多态的好处 多态的好处，体现在，可以使程序编写的更简单，并有良好的扩展。 4.5 引用类型转型多态的转型分为向上转型与向下转型两种: 向上转型 当父类引用指向一个子类对象(接口、实现类)时，便是向上转型。 多态本身是子类类型向父类类型向上转换的过程，这个过程是默认的。 格式（即多态）： 父类类型 变量名 = new 子类类型();如： Animal animal = new Cat(); 向上转型一定是安全的，没有问题的，正确的 但是也有一个弊端：对象一旦向上转型为父类，那么就无法调用子类原本特有的内容。 解决方案：用对象的向下转型【还原】 向下转型 一个已经向上转型的子类对象（实现类），将父类（接口）引用转为子类引用（还原），可以使用强制类型转换的格式，便是向下转型 格式： 子类类型 变量名 = (子类类型) 父类变量名;如：Cat cat = (Cat) animal instanceof关键字如何才能知道一个父类引用的对象，本来是什么子类？ 格式： 对象 instanceof 类名称 这将会得到一个boolean值结果，也就是判断前面的对象能不能当做后面类型的实例 1234567891011121314151617public static void main(String[] args) &#123; Animal animal = new Dog(); // 本来是一只狗 animal.eat(); // 狗吃SHIT // 如果希望掉用子类特有方法，需要向下转型 // 判断一下父类引用animal本来是不是Dog if (animal instanceof Dog) &#123; Dog dog = (Dog) animal; dog.watchHouse(); &#125; // 判断一下animal本来是不是Cat if (animal instanceof Cat) &#123; Cat cat = (Cat) animal; cat.catchMouse(); &#125;&#125; 4.5 接口多态综合案例笔记本电脑(laptop)通常具备使用USB设备的功能。在生产时，笔记本都预留了可以插入USB设备的USB接口， 但具体是什么USB设备，笔记本厂商并不关心，只要符合USB规格的设备都可以。 定义USB接口，具备最基本的开启功能和关闭功能。鼠标和键盘要想能在电脑上使用，那么鼠标和键盘也必须遵守 USB规范，实现USB接口，否则鼠标和键盘的生产出来也无法使用。 分析：进行描述笔记本类，实现笔记本使用USB鼠标、USB键盘 USB接口，包含开启功能、关闭功能 笔记本类，包含运行功能、关机功能、使用USB设备功能 鼠标类，要实现USB接口，并具备点击的方法 键盘类，要实现USB接口，具备敲击的方法 USB: 1234567public interface USB &#123; public abstract void open(); // 打开设备 public abstract void close(); // 关闭设备&#125; 笔记本： 123456789101112131415161718192021222324public class Computer &#123; public void powerOn() &#123; System.out.println(\"笔记本电脑开机\"); &#125; public void powerOff() &#123; System.out.println(\"笔记本电脑关机\"); &#125; // 使用USB设备的方法，使用接口作为方法的参数 public void useDevice(USB usb) &#123; usb.open(); // 打开设备 if (usb instanceof Mouse) &#123; // 一定要先判断 Mouse mouse = (Mouse) usb; // 向下转型 mouse.click(); &#125; else if (usb instanceof Keyboard) &#123; // 先判断 Keyboard keyboard = (Keyboard) usb; // 向下转型 keyboard.type(); &#125; usb.close(); // 关闭设备 &#125;&#125; 鼠标： 12345678910111213141516// 鼠标就是一个USB设备public class Mouse implements USB &#123; @Override public void open() &#123; System.out.println(\"打开鼠标\"); &#125; @Override public void close() &#123; System.out.println(\"关闭鼠标\"); &#125; public void click() &#123; System.out.println(\"鼠标点击\"); &#125;&#125; 键盘： 12345678910111213141516// 键盘就是一个USB设备public class Keyboard implements USB &#123; @Override public void open() &#123; System.out.println(\"打开键盘\"); &#125; @Override public void close() &#123; System.out.println(\"关闭键盘\"); &#125; public void type() &#123; System.out.println(\"键盘输入\"); &#125;&#125; Main代码: 123456789101112131415161718192021222324252627public class DemoMain &#123; public static void main(String[] args) &#123; // 首先创建一个笔记本电脑 Computer computer = new Computer(); computer.powerOn(); // 准备一个鼠标，供电脑使用// Mouse mouse = new Mouse(); // 首先进行向上转型 USB usbMouse = new Mouse(); // 多态写法 // 参数是USB类型，我正好传递进去的就是USB鼠标 computer.useDevice(usbMouse); // 创建一个USB键盘 Keyboard keyboard = new Keyboard(); // 没有使用多态写法 // 方法参数是USB类型，传递进去的是实现类对象 computer.useDevice(keyboard); // 正确写法！也发生了向上转型 // 使用子类对象，匿名对象，也可以// computer.useDevice(new Keyboard()); // 也是正确写法 computer.powerOff(); System.out.println(\"==================\"); &#125;&#125; 五、final关键字final: 不可改变。可以用于修饰类、方法和变量 类:被修饰的类，不能被继承 方法:被修饰的方法，不能被重写 变量:被修饰的变量，不能被重新赋值 5.1 修饰类格式： public final class 类名{&emsp;&emsp;&emsp;&emsp;//} 当前这个类不能有任何的子类 注意：一个类如果是final的，那么其中所有的成员方法都无法进行覆盖重写（因为没子类） 5.2 修饰方法格式： 修饰符 final 返回值类型 方法名(参数列表){&emsp;&emsp;&emsp;&emsp;//方法体} 例如：public final void method(){//} 当final关键字用来修饰一个方法的时候，这个方法就是最终方法，也就是不能被覆盖重写。 注意事项： 对于类、方法来说，abstract关键字和final关键字不能同时使用，因为矛盾。 5.3 局部变量 基本类型的局部变量，被final修饰后，只能赋值一次，不能再更改 引用类型的局部变量，被final修饰后，只能指向一个对象，地址不能再更改。但是不影响对象内部的成员变量值的修改 123456789101112131415161718192021222324252627public static void main(String[] args) &#123; // “一次赋值，终生不变” final int num2 = 200; System.out.println(num2); // 200// num2 = 250; // 错误写法！不能改变！ // 正确写法！只要保证有唯一一次赋值即可 final int num3; num3 = 30; // 对于引用类型来说，不可变说的是变量当中的地址值不可改变 //未使用final Student stu1 = new Student(\"赵丽颖\"); System.out.println(stu1.getName()); // 赵丽颖 stu1 = new Student(\"霍建华\"); System.out.println(stu1.getName()); // 霍建华 //使用final final Student stu2 = new Student(\"高圆圆\"); // 错误写法！final的引用类型变量，其中的地址不可改变// stu2 = new Student(\"赵又廷\"); System.out.println(stu2.getName()); // 高圆圆 stu2.setName(\"高圆圆圆圆圆圆\"); System.out.println(stu2.getName()); // 高圆圆圆圆圆圆 &#125; 5.4 成员变量对于成员变量来说，如果使用final关键字修饰，那么这个变量也照样是不可变。 由于成员变量具有默认值，所以用了final之后必须手动赋值，用了final不会再给默认值了。 对于final的成员变量，要么使用直接赋值，要么通过构造方法赋值。二者选其一。 必须保证类当中所有重载的构造方法，都最终会对final的成员变量进行赋值 1234567891011121314151617181920public class Person &#123; private final String name/* = \"鹿晗\"*/;//直接赋值 public Person() &#123; name = \"关晓彤\"; //构造方法赋值 &#125; public Person(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125;// public void setName(String name) &#123;// this.name = name;// &#125;&#125; 六、内部类将一个类A定义在另一个类B里面，里面的那个类A就称为内部类，B则称为外部类。 分为：成员内部类、局部内部类（包含匿名内部类) 6.1 成员内部类格式 修饰符 class 外部类名称 {&emsp;&emsp;&emsp;&emsp;修饰符 class 内部类名称 {&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;// …&emsp;&emsp;&emsp;&emsp;}&emsp;&emsp;&emsp;&emsp;// …} 访问特点 内部类可以直接访问外部类的成员，包括私有成员。 外部类要访问内部类的成员，必须要建立内部类的对象。 使用成员内部类的方法： 间接方式：在外部类的方法当中，使用内部类；然后main只是调用外部类的方法。 直接方式： 外部类名称.内部类名称 对象名 = new 外部类名称().new 内部类名称(); 类： 1234567891011121314151617181920212223242526272829public class Body &#123; // 外部类 public class Heart &#123; // 成员内部类 // 内部类的方法 public void beat() &#123; System.out.println(\"心脏跳动：蹦蹦蹦！\"); System.out.println(\"我叫：\" + name); // 正确写法！ &#125; &#125; // 外部类的成员变量 private String name; // 外部类的方法 public void methodBody() &#123; System.out.println(\"外部类的方法\"); new Heart().beat(); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; main 代码： 1234567891011121314public class Demo01InnerClass &#123; public static void main(String[] args) &#123; Body body = new Body(); // 外部类的对象 // 通过外部类的对象，调用外部类的方法，里面间接在使用内部类Heart body.methodBody(); System.out.println(\"=====================\"); // 按照公式写： Body.Heart heart = new Body().new Heart(); heart.beat(); &#125;&#125; 同名变量访问格式： 外部类名称.this.外部类成员变量名 格式举例： 123456789101112131415161718public class Outer &#123; int num = 10; // 外部类的成员变量 public class Inner /*extends Object*/ &#123; int num = 20; // 内部类的成员变量 public void methodInner() &#123; int num = 30; // 内部类方法的局部变量 System.out.println(num); // 局部变量，就近原则 System.out.println(this.num); // 内部类的成员变量 System.out.println(Outer.this.num); // 外部类的成员变量 &#125; &#125;&#125; 6.2 局部内部类如果一个类是定义在一个方法内部的，那么这就是一个局部内部类 “局部”：只有当前所属的方法才能使用它，出了这个方法外面就不能用了 格式 修饰符 class 外部类名称 {&emsp;&emsp;&emsp;&emsp;修饰符 返回值类型 外部类方法名称(参数列表) {&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;class 局部内部类名称 {&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;// …&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;}&emsp;&emsp;&emsp;&emsp;}} 类： 123456789101112131415class Outer &#123; public void methodOuter() &#123; class Inner &#123; // 局部内部类 int num = 10; public void methodInner() &#123; System.out.println(num); // 10 &#125; &#125; Inner inner = new Inner(); inner.methodInner(); &#125;&#125; main代码： 12345678public class DemoMain &#123; public static void main(String[] args) &#123; Outer obj = new Outer(); obj.methodOuter(); &#125;&#125; 权限修饰符定义一个类的时候，权限修饰符规则： 外部类：public / (default) 成员内部类：public / protected / (default) / private 局部内部类：什么都不能写 final问题局部内部类，如果希望访问所在方法的局部变量，那么这个局部变量必须是有效final的。 备注：从Java 8+开始，只要局部变量事实不变，那么final关键字可以省略。 原因： new出来的对象在堆内存当中。 局部变量是跟着方法走的，在栈内存当中。 方法运行结束之后，立刻出栈，局部变量就会立刻消失。 但是new出来的对象会在堆当中持续存在，直到垃圾回收消失。 比如： 12345678910111213public class MyOuter &#123; public void methodOuter() &#123; int num = 10; // 所在方法的局部变量 class MyInner &#123; public void methodInner() &#123; System.out.println(num); &#125; &#125; &#125;&#125; 6.3 匿名内部类 匿名内部类：是内部类的简化写法。本质：带具体实现的 父类（父接口） 匿名的 子类对象。 开发中，最常用到的内部类就是匿名内部类 缘由： 以接口举例，当你使用一个接口时，似乎得做如下几步操作， 定义实现类 重写接口中的方法 创建子类对象 调用重写后的方法 匿名内部类是对此的简化 如果接口的实现类（或者是父类的子类）只需要使用唯一的一次比如多态情况MyInterface obj = new MyInterfaceImpl();那么这种情况下就可以省略掉该类的定义，而改为使用匿名内部类 格式 接口名称 对象名 = new 接口名称() {&emsp;&emsp;&emsp;&emsp;// 覆盖重写所有抽象方法}; 有点类似把实现类的内容拿出来了，把实现类的名字匿了 注意事项 匿名内部类，在创建对象的时候，只能使用唯一一次。如果希望多次创建对象，而且类的内容一样的话，要么重复写两遍，要么就需要使用单独定义的实现类了。 匿名对象，在调用方法的时候，只能调用唯一一次。如果希望同一个对象，调用多次方法，要么重复写两遍，要么必须给对象起个名字。 匿名内部类是省略了实现类/子类名称，但是匿名对象是省略了对象名称强调：匿名内部类和匿名对象不是一回事！！！ 6.4 类作为成员变量英雄 123456789101112131415161718192021public class Hero &#123; private String name; // 英雄的名字 private int age; // 英雄的年龄 private Weapon weapon; // 英雄的武器 public Hero() &#123; &#125; public Hero(String name, int age, Weapon weapon) &#123; this.name = name; this.age = age; this.weapon = weapon; &#125; public void attack() &#123; System.out.println(\"年龄为\" + age + \"的\" + name + \"用\" + weapon.getCode() + \"攻击敌方。\"); &#125; // getter、setter省略&#125; 武器 12345678910111213public class Weapon &#123; private String code; // 武器的代号 public Weapon() &#123; &#125; public Weapon(String code) &#123; this.code = code; &#125; // getter、setter省略&#125; main 12345678910111213141516171819public class DemoMain &#123; public static void main(String[] args) &#123; // 创建一个英雄角色 Hero hero = new Hero(); // 为英雄起一个名字，并且设置年龄 hero.setName(\"盖伦\"); hero.setAge(20); // 创建一个武器对象 Weapon weapon = new Weapon(\"AK-47\"); // 为英雄配备武器 hero.setWeapon(weapon); // 年龄为20的盖伦用多兰剑攻击敌方。 hero.attack(); &#125;&#125; 6.5 接口作为成员变量英雄 1234567891011121314151617181920public class Hero &#123; private String name; // 英雄的名称 private Skill skill; // 英雄的技能 public Hero() &#123; &#125; public Hero(String name, Skill skill) &#123; this.name = name; this.skill = skill; &#125; public void attack() &#123; System.out.println(\"我叫\" + name + \"，开始施放技能：\"); skill.use(); // 调用接口中的抽象方法 System.out.println(\"施放技能完成。\"); &#125; // getter、setter省略&#125; 技能 12345public interface Skill &#123; void use(); // 释放技能的抽象方法&#125; main 123456789101112131415161718192021222324252627282930public class DemoGame &#123; public static void main(String[] args) &#123; Hero hero = new Hero(); hero.setName(\"艾希\"); // 设置英雄的名称 // 设置英雄技能// hero.setSkill(new SkillImpl()); // 使用单独定义的实现类 // 还可以改成使用匿名内部类// Skill skill = new Skill() &#123;// @Override// public void use() &#123;// System.out.println(\"Pia~pia~pia~\");// &#125;// &#125;;// hero.setSkill(skill); // 进一步简化，同时使用匿名内部类和匿名对象 hero.setSkill(new Skill() &#123; @Override public void use() &#123; System.out.println(\"Biu~Pia~Biu~Pia~\"); &#125; &#125;); hero.attack(); &#125;&#125; 接口还可以做方法的参数和返回值 6.6 案例 发红包（待整理）","categories":[{"name":"java","slug":"java","permalink":"http://mangosTeeN96.github.io/categories/java/"}],"tags":[]},{"title":"Java基础","slug":"Java基础","date":"2019-04-29T05:26:32.000Z","updated":"2020-08-04T07:18:38.607Z","comments":true,"path":"2019/04/29/Java基础/","link":"","permalink":"http://mangosTeeN96.github.io/2019/04/29/Java基础/","excerpt":"","text":"第一章 入门1.1 HelloWorld入门程序Java程序开发三步骤:编写、编译、运行。 编写Java源程序 创建HelloWorld.java文件，代码如下： 12345public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println(\"Hello World!\"); &#125;&#125; 编译Java源文件 在DOS命令行中，进入Java源文件的目录，使用 javac 命令进行编译。命令: javac Java源文件名.后缀名 举例: 1javac HelloWorld.java 译成功后，产生一个新的文件 HelloWorld.class ，该文件就是编译后的文件，是Java的可运行文件，称为字节码文件，有了字节码文件，就可以运行程序了。 运行Java程序 在DOS命令行中，进入Java源文件的目录，使用 java 命令进行运行。命令: java 类名字 举例： 1java HelloWolrd 入门程序说明 main方法： 称为主方法。写法是固定格式不可以更改。main方法是程序的入口点或起始点，无论我们编写多少程序，JVM在运行的时候，都会从main方法这里开始执行。 注释： 单行注释以 //开头 换行结束多行注释以 /*开头 以*/结束 关键字： 是指在程序中，Java已经定义好的单词，具有特殊含义。HelloWorld案例中，出现的关键字有 public 、 class 、 static 、 void 等，这些单词已经被 Java定义好，全部都是小写字母。 标识符： 是指在程序中，我们自己定义内容。比如类的名字、方法的名字和变量的名字等等，都是标识符。 HelloWorld案例中，出现的标识符有类名字 HelloWorld 。 命名规则： 硬性要求标识符可以包含 英文字母26个(区分大小写) 、 0-9数字 、 $(美元符号) 和 _(下划线) 。标识符不能以数字开头。标识符不能是关键字。软性要求类名规范:首字母大写，后面每个单词首字母大写(大驼峰式)。方法名规范: 首字母小写，后面每个单词首字母大写(小驼峰式)。变量名规范:全部小写 1.2 常量变量常量 类型 含义 数据举例 整数常量 所有的整数 0，1， 567， -9 小数常量 所有的小数 0.0， -0.1， 2.55 字符常量 单引号引起来,只能写一个字符,必须有内容 ‘a’，’’， ‘好’ 字符串常量 双引号引起来,可以写多个字符,也可以不写 “A” ，”Hello” ，”你好” ，”” 布尔常量 只有两个值 true ， false 空常量 只有一个值 null 变量 Java的数据类型分为两大类: 基本数据类型:包括 整数、浮点数、字符、布尔。 引用数据类型:包括 类 、 数组 、 接口 。 数据类型 关键字 内存占用 取值范围 字节型 byte 1个字节 -128~127 短整型 short 2个字节 -32768~32767 整型 int(默认) 4个字节 -231次方~2的31次方-1 长整型 long 8个字节 -2的63次方~2的63次方-1 单精度浮点数 float 4个字节 1.4013E-45~3.4028E+38 双精度浮点数 double(默认) 8个字节 4.9E-324~1.7977E+308 字符型 char 2个字节 0-65535 布尔类型 boolean 1个字节 true，false 变量定义 格式： 数据类型 变量名 = 数据值; 1.3 数据类型转换、运算符Java程序中要求参与的计算的数据，必须要保证数据类型的一致性（比如进行加法运算），如果数据类型不一致将发生类型的转换。 自动转换将 取值范围小的类型 自动提升为 取值范围大的类型 。 1byte、short、char‐‐&gt;int‐‐&gt;long‐‐&gt;float‐‐&gt;double 强制转换 将 取值范围大的类型 强制转换成 取值范围小的类型 。 自动转换是Java自动执行的，而强制转换需要我们自己手动执行。 转换格式： 数据类型 变量名 = (数据类型)被转数据值; 注意： 浮点转成整数，直接取消小数点，可能造成数据损失精度。 int 强制转成 short 砍掉2个字节，可能造成数据丢失。 ASCII编码表 字符 数值 0 48 9 57 A 65 Z 90 a 97 z 122 1234567public static void main(String[] args) &#123; //字符类型变量 char c = 'a'; int i = 1; //字符类型和int类型计算 System.out.println(c+i);//输出结果是98 &#125; 运算符算数运算符 + 加法运算，字符串连接运算 - 减法运算 * 乘法运算 / 除法运算 % 取模运算，两个数字相除取余数 ++ 、 – 自增自减运算 注意：变量在独立运算时， 前++ 和 后++ 没有区别 ；和其他变量放在一起， 前++ 和 后++ 就产生了不同（+1后赋值、赋值后+1）。 三元运算符 格式： 数据类型 变量名 = 布尔类型表达式?结果1:结果2 计算方式:布尔类型表达式结果是true，三元运算符整体结果为结果1，赋值给变量。布尔类型表达式结果是false，三元运算符整体结果为结果2，赋值给变量。 123456public static void main(String[] args) &#123; int i = (1==2 ? 100 : 200); System.out.println(i);//200 int j = (3&lt;=4 ? 500 : 600); System.out.println(j);//500&#125; 第二章 判断、选择、循环语句2.1 判断语句 if 123if(关系表达式)&#123; 语句体;&#125; if…else 12345if(关系表达式) &#123; 语句体1;&#125;else &#123; 语句体2;&#125; if…else if…else 12345678910if (判断条件1) &#123; 执行语句1;&#125; else if (判断条件2) &#123; 执行语句2;&#125;...&#125;else if (判断条件n) &#123; 执行语句n; &#125; else &#123; 执行语句n+1; &#125; 注意：在某些简单的应用中，if语句是可以和三元运算符互换使用的。 1234567891011public static void main(String[] args) &#123; int a = 10; int b = 20; //定义变量，保存a和b的较大值 int c; if(a &gt; b) &#123; c = a; &#125; else &#123; c = b; &#125; //上述功能可以改写为三元运算符形式 c = a &gt; b ? a:b; &#125; 2.2 选择语句 switch 123456789101112switch(表达式) &#123; case 常量值1: 语句体1; break; case 常量值2: 语句体2; break; ... default: 语句体n+1; break;&#125; switch语句中，表达式的数据类型，可以是byte，short，int，char，enum(枚举)，JDK7后可以接收字符串 注意：case的穿透性在switch语句中，如果case的后面不写break，将出现穿透现象，也就是不会在判断下一个case的值，直接向后运行，直到遇到break，或者整体switch结束。 2.3 循环语句 for循环 for(初始化表达式1; 布尔表达式2; 步进表达式4){ 循环体3} 执行顺序:1234&gt;234&gt;234…2不满足为止。 while循环 初始化表达式1 while(布尔表达式2){&emsp;&emsp;&emsp;循环体3&emsp;&emsp;&emsp;步进表达式4} 执行顺序:1234&gt;234&gt;234…2不满足为止。 do…while循环 初始化表达式1 do{&emsp;&emsp;&emsp;循环体3&emsp;&emsp;&emsp;步进表达式4}while(布尔表达式2); 执行顺序:134&gt;234&gt;234…2不满足为止。 for 和 while 的小区别: 控制条件语句所控制的那个变量，在for循环结束后，就不能再被访问到了，而while循环结束还可以继 续使用，如果你想继续使用，就用while，否则推荐使用for。原因是for循环结束，该变量就从内存中消 失，能够提高内存的使用效率。 在已知循环次数的时候使用推荐使用for，循环次数未知的时推荐使用while。 2.4跳出语句break使用场景:终止switch或者循环 在选择结构switch语句中 在循环语句中 离开使用场景的存在是没有意义的 continue 使用场景:结束本次循环，继续下一次的循环 嵌套循环 所谓嵌套循环，是指一个循环的循环体是另一个循环。比如for循环里面还有一个for循环，就是嵌套循环。总共的循环次数=外循环次数*内循环次数 第三章 方法方法: 就是将一个功能抽取出来，把代码单独定义在一个大括号内，形成一个单独的功能。 当我们需要这个功能的时候，就可以去调用。这样即实现了代码的复用性，也解决了代码冗余的现象。 3.1 定义 修饰符 返回值类型 方法名 (参数列表){&emsp;&emsp;&emsp;&emsp;代码…&emsp;&emsp;&emsp;&emsp;return 返回值;} 定义格式解释: 修饰符: 目前固定写法 public static 返回值类型: 没有返回值时为&ensp;void 方法名:满足标识符的规范，用来调用方法。 参数列表: 参数 return:方法结束。返回值类型是void，方法大括号内的return可以不写，有返回值时返回给调用者。 举例： 123 public static void methodName() &#123; System.out.println(\"这是一个方法\");&#125; 方法定义注意事项: 方法必须定义在一类中方法外 方法不能定义在另一个方法的里面 3.2 方法的调用12345678 public static void main(String[] args) &#123; //调用定义的方法method method();&#125;//定义方法，被main方法调用 public static void method() &#123; System.out.println(\"自己定义的方法，需要被main调用运行\"); &#125; 上面方法为直接调用，有参数时括号内写入参数 还可以输出语句调用: 在输出语句中调用方法， System.out.println(方法名()) 。 不能用输出语句调用 void 类型的方法 3.3 方法重载 方法重载：指在同一个类中，允许存在一个以上的同名方法，只要它们的参数列表不同即可，与修饰符和返 回值类型无关。 参数列表不同：个数不同，数据类型不同，顺序不同。 重载方法调用：JVM通过方法的参数列表，调用不同的方法。 重载练习比较两个数据是否相等。参数类型分别为两个 byte 类型，两个 short 类型，两个 int 类型，两个 long 类型，并在 main 方法中进行测试。 123456789101112131415161718192021222324252627282930313233343536373839public class Method_Demo6 &#123; public static void main(String[] args) &#123; //定义不同数据类型的变量 byte a = 10; byte b = 20; short c = 10; short d = 20; int e = 10; int f = 10; long g = 10; long h = 20; // 调用 System.out.println(compare(a, b)); System.out.println(compare(c, d)); System.out.println(compare(e, f)); System.out.println(compare(g, h)); &#125; // 两个byte类型的 public static boolean compare(byte a, byte b) &#123; System.out.println(\"byte\"); return a == b; &#125; // 两个short类型的 public static boolean compare(short a, short b) &#123; System.out.println(\"short\"); return a == b; &#125; // 两个int类型的 public static boolean compare(int a, int b) &#123; System.out.println(\"int\"); return a == b; &#125; // 两个long类型的 public static boolean compare(long a, long b) &#123; System.out.println(\"long\"); return a == b; &#125;&#125; 3.4 权限修饰符public:公共的protected:受保护的default:默认的（不写）private:私有的 public protected default(空的) private 同一类中 √ √ √ √ 同一包中(子类与无关类) √ √ √ 不同包的子类 √ √ 不同包中的无关类 √ 第四章 数组数组: 数组就是存储数据长度固定的容器，保证多个数据的数据类型要一致。 数组的特点： 数组是一种引用数据类型 数组当中的多个数据，类型必须统一 数组的长度在程序运行期间不可改变 4.1 定义数组的初始化：在内存当中创建一个数组，并且向其中赋予一些默认值。 两种常见的初始化方式： 动态初始化（指定长度） 静态初始化（指定内容） 动态初始化数组 格式： 数据类型[] 数组名称 = new 数据类型[数组长度]; 解析含义： 数据类型：数组当中数据的统一类型[]：代表我是一个数组new：代表创建数组的动作数组长度：指定长度 举例： 1int[] arr = new int[3]; 静态初始化 标准格式： 数据类型[] 数组名称 = new 数据类型[] { 元素1, 元素2, … }; 省略格式： 数据类型[] 数组名称 = { 元素1, 元素2, … } 举例： 123int[] arrA = new int[]&#123;1,2,3,4,5&#125;;int[] arrB = &#123;1,2,3,4,5&#125;; 注意： 静态初始化没有直接指定长度，但是仍然会自动推算得到长度 静态初始化标准格式、动态初始化，可以拆分成为两个步骤 静态初始化省略格式不能拆分成为两个步骤 12int[] arrayB;arrayB = new int[] &#123; 11, 21, 31 &#125;; 4.2 数组的访问索引：从0开始，通过数组的索引访问到数组中的元素格式： 数组名[索引] 数组长度获得数组长度语句：数组名.length数组的最大索引值为：数组名.length-1 索引访问数组中的元素: 数组名[索引]=数值，为数组中的元素赋值 变量=数组名[索引]，获取出数组中的元素 4.3 数组内存原理Java虚拟机的内存划分 一个数组内存图 两个独立数组内存图 两个变量指向同一个数组内存图 4.4 数组遍历123456public static void main(String[] args) &#123; int[] arr = &#123; 1, 2, 3, 4, 5 &#125;; for (int i = 0; i &lt; arr.length; i++) &#123; System.out.println(arr[i]); &#125;&#125; 4.5 数组获得最大值元素123456789101112131415public static void main(String[] args) &#123; int[] arr = &#123; 5, 15, 2000, 10000, 100, 4000 &#125;; //定义变量，保存数组中0索引的元素 int max = arr[0]; //遍历数组，取出每个元素 for (int i = 0; i &lt; arr.length; i++)&#123; //遍历到的元素和变量max比较 //如果数组元素大于max if (arr[i] &gt; max) &#123; //max记录住大值 max = arr[i]; &#125; &#125; System.out.println(\"数组最大值是: \" + max); &#125; 4.6 数组反转数组中的元素颠倒顺序，例如原始数组为1,2,3,4,5，反转后的数组为5,4,3,2,1 实现思想：数组最远端的元素互换位置。 实现反转，就需要将数组最远端元素位置交换 定义两个变量，保存数组的最小索引和最大索引 两个索引上的元素交换位置 最小索引++，最大索引–，再次交换位置 最小索引超过了最大索引，数组反转操作结束 12345678910111213141516public static void main(String[] args) &#123; int[] arr = &#123; 1, 2, 3, 4, 5 &#125;; /* 循环中定义变量min=0最小索引 max=arr.length‐1最大索引 min++,max‐‐ */ for (int min = 0, max = arr.length ‐ 1; min &lt;= max; min++, max‐‐) &#123; //利用第三方变量完成数组中的元素交换 int temp = arr[min]; arr[min] = arr[max]; arr[max] = temp; &#125; // 反转后，遍历数组 for (int i = 0; i &lt; arr.length; i++) &#123; System.out.println(arr[i]); &#125;&#125; 4.7 数组作为方法参数和返回值 数组作为方法参数传递，传递的参数是数组内存的地址 数组作为方法的返回值，返回的是数组的内存地址 方法的参数为基本类型时，传递的是数据值。为引用类型时，传递的是地址值。 第五章 类与对象类与对象的关系 类是对一类事物的描述，是抽象的。 对象是一类事物的实例，是具体的。 类是对象的模板，对象是类的实体。 5.1 类的定义格式： public class ClassName {&emsp;&emsp;&emsp;&emsp;//成员变量(属性)&emsp;&emsp;&emsp;&emsp;//成员方法(行为)} 成员变量:和以前定义变量几乎是一样的。只不过位置发生了改变。在类中，方法外。 成员方法:和以前定义方法几乎是一样的。只不过把static去掉。 举例： 1234567891011121314 public class Student &#123; //成员变量 String name;//姓名 int age;//年龄 //成员方法 //学习的方法 public void study() &#123; System.out.println(\"好好学习，天天向上\"); &#125; //吃饭的方法 public void eat() &#123; System.out.println(\"学习饿了要吃饭\"); &#125;&#125; 5.2 对象的使用格式： 导包 import 包名称.类名称； （属于同一个包可以不写） 创建对象 类名 对象名 = new 类名(); 使用对象访问类中的成员 对象名.成员变量;对象名.成员方法(); 成员变量的默认值 数据类型 默认值 基本类型 整数(byte，short，int，long) 0 浮点数(float，double) 0.0 字符(char) ‘\\u0000’ 布尔(boolean) false 引用类型 数组，类，接口 null 类与对象举例： 定义手机类: 123456789101112131415public class Phone &#123; // 成员变量 String brand; //品牌 int price; //价格 String color; //颜色 // 成员方法 //打电话 public void call(String name) &#123; System.out.println(\"给\"+name+\"打电话\"); &#125; //发短信 public void sendMessage() &#123; System.out.println(\"群发短信\"); &#125;&#125; 定义测试类: 1234567891011121314151617181920212223242526public class Test02Phone &#123; public static void main(String[] args) &#123; //创建对象 Phone p = new Phone(); //输出成员变量值 System.out.println(\"品牌:\"+p.brand);//null System.out.println(\"价格:\"+p.price);//0 System.out.println(\"颜色:\"+p.color);//null System.out.println(\"‐‐‐‐‐‐‐‐‐‐‐‐\"); //给成员变量赋值 p.brand = \"锤子\"; p.price = 2999; p.color = \"棕色\"; //再次输出成员变量值 System.out.println(\"品牌:\"+p.brand);//锤子 System.out.println(\"价格:\"+p.price);//2999 System.out.println(\"颜色:\"+p.color);//棕色 System.out.println(\"‐‐‐‐‐‐‐‐‐‐‐‐\"); //调用成员方法 p.call(\"紫霞\"); p.sendMessage(); &#125; &#125; 成员变量和局部变量区别 在类中的位置不同 成员变量:类中，方法外 局部变量:方法中或者方法声明上(形式参数) 作用范围不一样 成员变量:类中 局部变量:方法中 初始化值的不同 成员变量:有默认值 局部变量:没有默认值。必须先定义，赋值，最后使用 在内存中的位置不同 成员变量:堆内存 局部变量:栈内存 生命周期不同 成员变量:随着对象的创建而存在，随着对象的消失而消失 局部变量:随着方法的调用而存在，随着方法的调用完毕而消失 第六章 封装封装 封装可以被认为是一个保护屏障，防止该类的代码和数据被其他类随意访问。要访问该类的数据，必须通过指定的方式。适当的封装可以让代码更容易理解与维护，也加强了代码的安全性。原则：将属性隐藏起来，若需要访问某个属性，提供公共方法对其访问。 方法就是一种封装 关键字private也是 6.1 封装步骤 使用 private 关键字来修饰成员变量。 对需要访问的成员变量，提供对应的一对getXxx方法 、setXxx方法。 6.2 封装的操作——private关键字private的含义 private是一个权限修饰符，代表最小权限。 可以修饰成员变量和成员方法。 被private修饰后的成员变量和成员方法，只在本类中才能访问。 使用格式 private 数据类型 变量名 ; 使用 private 修饰成员变量，代码如下: 1234public class Student &#123; private String name; private int age;&#125; 提供 getXxx 方法 / setXxx 方法，可以访问成员变量 代码如下: 123456789101112131415161718public class Student &#123; private String name; private int age; public void setName(String n) &#123; name = n; &#125; public String getName() &#123; return name; &#125; public void setAge(int a) &#123; age = a; &#125; public int getAge() &#123; return age; &#125; &#125; set方法，用于向age设置数据 get方法，用于获取age的数据 可以用set约束设置的数据 注意： 对于基本类型中的boolean值，getter方法要写成isxxx，而setxxx规则不变 第七章 封装优化7.1 this关键字上一章中，setXxx 方法中形参名字并不符合见名知意的规定如果修改与成员变量名一致，代码如下: 1234567891011public class Student &#123; private String name; private int age; public void setName(String name) &#123; name = name; &#125; public void setAge(int age) &#123; age = age; &#125; &#125; 当方法的局部变量和类的成员变量重名的时候，根据就近原则，优先使用局部变量如果需要访问本类当中的成员变量，需要使用this关键字通过谁调用的方法，谁就是this 格式： this.成员变量名; 使用 this 修饰方法中的变量，解决成员变量被隐藏的问题，代码如下: 12345678910public class Person &#123; String name; // 我自己的名字 // 参数name是对方的名字 // 成员变量name是自己的名字 public void sayHello(String name) &#123; System.out.println(name + \"，你好。我是\" + this.name); System.out.println(this); &#125;&#125; 12345678910public class Demo01Person &#123; public static void main(String[] args) &#123; Person person = new Person(); // 设置我自己的名字 person.name = \"王健林\"; person.sayHello(\"王思聪\"); System.out.println(person); // 地址值 &#125;&#125; 输出结果： 王思聪，你好。我是王健林cn.itcast.day06.demo04.Person@7852e922cn.itcast.day06.demo04.Person@7852e922 7.2 构造方法构造方法是专门用来创建对象的方法，当我们通过关键字new来创建对象时，其实就是在调用构造方法。格式： public 类名称(参数类型 参数名称) {&emsp;&emsp;&emsp;&emsp;方法体} 注意事项： 构造方法的名称必须和所在的类名称完全一样，就连大小写也要一样 构造方法不要写返回值类型，连void都不写 构造方法不能return一个具体的返回值 如果没有编写任何构造方法，那么编译器将会默认赠送一个构造方法，没有参数、方法体什么事情都不做。public Student() {} 一旦编写了至少一个构造方法，那么编译器将不再赠送。 构造方法也是可以进行重载的。 使用构造方法后，代码如下: 12345678910111213public class Student &#123; private String name; private int age; // 无参数构造方法 public Student() &#123;&#125; // 有参数构造方法 public Student(String name,int age) &#123; this.name = name; this.age = age; &#125;&#125; 全参数构造方法，方便我们在创建对象的时候把数据直接通过参数的形式设置进来，省去多次调用setget方法 但是当修改对象内容时set方法还是有用的。 获取数据时还是要用get方法 要写全参数构造方法时，需要把无参数也写上，因为系统不会赠送了。 7.3 标准代码——JavaBean一个标准的类通常要拥有下面四个组成部分： 所有的成员变量都要使用private关键字修饰 为每一个成员变量编写一对儿Getter/Setter方法 编写一个无参数的构造方法 编写一个全参数的构造方法 这样标准的类也叫做Java Bean 编写符合 JavaBean 规范的类，以学生类为例，标准代码如下: 12345678910111213141516171819202122232425262728public class Student &#123; //成员变量 private String name; // 姓名 private int age; // 年龄 //构造方法 public Student() &#123; &#125; public Student(String name, int age) &#123; this.name = name; this.age = age; &#125; 成员方法 public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setAge(int age) &#123; this.age = age; &#125; public int getAge() &#123; return age; &#125;&#125; 测试类，代码如下： 1234567891011121314public class TestStudent &#123; public static void main(String[] args) &#123; //无参构造使用 Student s= new Student(); s.setName(\"柳岩\"); s.setAge(18); System.out.println(s.getName()+\"‐‐‐\"+s.getAge()); //带参构造使用 Student s2= new Student(\"赵丽颖\",18); System.out.println(s2.getName()+\"‐‐‐\"+s2.getAge()); &#125; &#125;","categories":[{"name":"java","slug":"java","permalink":"http://mangosTeeN96.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://mangosTeeN96.github.io/tags/java/"}]},{"title":"hexo个人博客搭建","slug":"hexo个人博客搭建","date":"2019-04-28T04:47:04.000Z","updated":"2020-08-04T07:18:16.040Z","comments":true,"path":"2019/04/28/hexo个人博客搭建/","link":"","permalink":"http://mangosTeeN96.github.io/2019/04/28/hexo个人博客搭建/","excerpt":"","text":"搭建流程&emsp;&emsp;1. 安装node.js 打开nodejs.org下载安装包，直接点开安装包安装。 查看安装版本 node -v npm -v &emsp;&emsp;2. 安装hexo框架（以下若权限不足sudo） npm install -g hexo-cli hexo -v 查看hexo版本 &emsp;&emsp;3. 建立blog空文件夹（在用户文件夹中建立即可（位置随意）） mkdir blog 后续如果出现什么问题，把blog文件夹删除重新来即可。 cd blog &emsp;&emsp;4. 初始化博客 sudo hexo init &emsp;&emsp;5. 启动博客 hexo s 浏览器打开localhost:4000，可以看到默认创建的博客 &emsp;&emsp;6. 创建自己的博客 sudo hexo new &quot;测试&quot; cd source/_posts/ 编辑测试.md即可更改博客内容（markdown） cd ../..退回到blog目录下 &emsp;&emsp;7. 本地查看博客总结 hexo clean 清理一下 hexo g 生成一下 hexo s 启动一下 &emsp;&emsp;8. 建repository（为了博客部署到github上公开使用） 登陆自己的github账户，右上角+点开 New repositoryrepository name 必须是 ：昵称（前面的Owner）.github.io 点击greate，出现一个空仓库，保留页面 &emsp;&emsp;9. 安装部署插件 sudo npm install --save hexo-deployer-git 更改_config.yml文件 sudo vim _config.yml 到达文件最底部更改增加如下： 1234deploy: type: git repo: https://github.com/mangosTeeN96/mangosTeeN96.github.io.git branch: master 其中repo地址为刚刚创建的仓库页面的地址（注意冒号后面的空格） &emsp;&emsp;10. 部署到远端 hexo d 中途需要输入GitHub的账户密码 此时访问 mangosteen96.github.io 即可看到自己的博客 到此博客的基本部署就完成了 &emsp;&emsp;11. 更换博客主题 以yilia主题为例 sudo git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia 此时themes文件夹中出现yilia文件夹，更改站点配置文件 找到theme：xxx 改为theme：yilia hexo clean hexo g hexo s 4000端口即可看到更改 hexo d 推到远端，mangosteen96.github.io 可以看到（主题更换可能要等一下下） Hexo博客导入图片方法1 站点配置文件_config.yml 里的post_asset_folder:这个选项设置为true npm install hexo-asset-image --save 安装一个可以上传本地图片的插件 安装插件后hexo new “xxxx”来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 把图片复制到xxxx这个文件夹中，在xxxx.md中按照markdown的格式引入图片(此处为了不被识别为图片就先这么写了)： 感叹号+[]括号内可输入替代文字+(xxxx/图片名.jpg) 最后检查一下，hexo g生成页面后，进入public\\2017\\02\\26\\index.html文件中查看，html标签内的语句是img src=”2017/02/26/xxxx/图片名.jpg”，必须要有日期。 其它方法 本地source中建立img文件夹&lt;&gt; 内 img src=”img/图片名.jpg（此方法未详细试验） 图床 所遇问题 由于hexo3版本后对很多插件支持有问题，hexo-asset-image插件在处理链接时出现路径错误，没有年月，无法显示图片。可直接安装已经修改过得插件npm install https://github.com/7ym0n/hexo-asset-image --save 由于title中有一些符号（比如（）、–等）用hexo new命令创建博客时，出现文件名称与文章title不符的情况在博客中没有图片时，并不产生影响，但当要插入图片时，在路径正确的情况下，依然显示不出图片解决办法暂时只是把 1.文件夹名称、2.md文件名称、3.title 这三者统一 其他配置修改主题颜色打开hexo/themes/next/source/css/_variables/base.styl找到Colors代码段，如下： 123456789101112131415161718// Colors// colors for use across theme.// -------------------------------------------------- $whitesmoke = #f5f5f5 $gainsboro = #eee //这个是边栏头像外框的颜色， $gray-lighter = #ddd //文章中插入图片边框颜色 $grey-light = #ccc //文章之间分割线、下划线颜色 $grey = #bbb //页面选中圆点颜色 $grey-dark = #999 $grey-dim = #666 //侧边栏目录字体颜色 $black-light = #555 //修改文章字体颜色 $black-dim = #333 $black-deep = #495a80 //修改主题的颜色，这里我已经改成老蓝色了。 $red = #ff2a2a $blue-bright = #87daff $blue = #0684bd $blue-deep = #262a30 $orange = #F39D01 //浏览文章时，目录选中的颜色","categories":[{"name":"hexo","slug":"hexo","permalink":"http://mangosTeeN96.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://mangosTeeN96.github.io/tags/hexo/"}]}]}